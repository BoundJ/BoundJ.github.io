<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Verdin小站">
<meta property="og:url" content="http://verdin.cn/index.html">
<meta property="og:site_name" content="Verdin小站">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Verdin小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://verdin.cn/"/>





  <title> Verdin小站 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?de255985a34f4b5d76b6cd2f11b8b565";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Verdin小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Why-FasterRCNN/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Why-FasterRCNN/" itemprop="url">
                  Why FasterRCNN !
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:16:33+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Why-FasterRCNN/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Why-FasterRCNN/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Tallk-about-Caffe-Layers/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Tallk-about-Caffe-Layers/" itemprop="url">
                  Tallk about Caffe Layers
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:15:35+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Tallk-about-Caffe-Layers/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Tallk-about-Caffe-Layers/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/What-is-Deep-Forest/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/What-is-Deep-Forest/" itemprop="url">
                  What is Deep Forest
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:14:57+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/What-is-Deep-Forest/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/What-is-Deep-Forest/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>整个算法看起来不是很复杂。</p>
<ol>
<li>类似以前Stacking的做法，即每一层都用label进行训练，训练完了再叠一层继续训练。加了Complete Random Forest很有意思，个人理解是生成了一些看似无关，但对将来的预测有好处的特征。如果实验里面能做些ablation analysis就好了。</li>
<li>用了一些shortcut-connection，把几层前的数据拿过来连上上一层的输出一起作为这一层Forest的输入。</li>
<li>Multi-Grained Scanning这部分非常像1D和2D convolution。另外实验还只是在小规模数据集上做的，期待CIFAR甚至是ImageNet的结果。深度学习这里也有一直在提但是一直效果不怎么好的Layer-by-Layer训练的思路，如果这个思路能在大数据集上做好，那确实是大突破了。</li>
</ol>
<p>作者：<a href="https://www.zhihu.com/question/56474891/answer/149427631" target="_blank" rel="external">田渊栋</a></p>
<p>先说我的结论：相比前两天引起了广泛讨论的ICLR best paper，这个paper其实更没有什么讨论的意义。当然作为一个research来说，paper还是可以中的，尤其是对于IJCAI。但是我完全不看好这个paper会有什么长远的影响力，以及有人说的可以启发大量后续研究。下面分别从这个idea，实现方法，以及实验结果三个方面分析。</p>
<ol>
<li><strong>Idea：</strong>不用多说，通过stacking weak learner来提升模型性能的想法已经非常常见。然而这样一个idea一定不会work，原罪就在于<strong>tree based model无法进行fine-tune</strong>。这会带来两个非常严重的问题：</li>
</ol>
<ul>
<li><p>A. 无法进行end to end learning，这会极大程度上影响到模型最终的结果。会使depth完全发挥不出威力。</p>
</li>
<li><p>B. 无法进行feature transfer，CNN最最最重要成功的秘诀就在于可以在ImageNet这样海量的数据上进行pretrain，然后再把学习到的(approximately) general feature 通过finetune transfer到其他任务中去。如果BP都没法做，这个就完全无从谈起了。</p>
</li>
<li><p>换句话说，如果这样的Idea能在大数据上work，那么其实相当于否定了BP存在的意义。以后大家都一层一层加就是了嘛。当然这样的好事是不存在的。</p>
</li>
<li><p>如何把tree based model可以做到e2e训练，以及拓展开来如何更高效地把更高效的base learner引入神经网络这又是另外一个故事。我们在这方面也做了一些尝试，但是所有的这一切的基础都是可以bp。</p>
</li>
</ul>
<ol>
<li><p><strong>Method：</strong>这里使用了一个stacking random forest的方法来实现上述idea。从创新性上而言，在<strong>Kaggle</strong>比赛中不同种类模型之间的Stacking和Concatenation早就不是什么新想法。所以从实现层面上而言，仍旧乏善可陈。而且中间层只是把最终分类的结果concat在一起，都不是把每个tree生成的leaf对应的feature。个人觉得这样会严重影响stack的性能，好歹之前FB还是把GBDT的每个leaf当成一个feature才去train的logisitic regression。</p>
</li>
<li><p><strong>Experiment：</strong>这是本文槽点最多的部分。看到还在跑MNIST和ORL就知道这完全是做ML人的玩具。不熟悉别的应用，单就Vision而言，这个结果比ELM其实还没说服力，而且我相信会有更简单的模型同样可以达到类似的结果。比如随便开开脑洞train个SVM中间加个non-linear transformation什么的。现在在CVPR大家都知道Cifar都不能算是有信服力的数据集，更何况MNIST和ORL这种。</p>
</li>
</ol>
<p>另外，比较的网络结构也都是拍拍脑袋想出来的，唯一比了一个经典结构LeNet5还没比过。不过基于上述第一点的看法，我完全不相信这样的算法能在稍微大一些的数据集上取得还不错的结果。另外我觉得非常不合适的claim：</p>
<ol>
<li><p>Table1中画了很多问号，显得CNN要调整的参数有非常多。然而实际上，绝大部分参数都是有默认的设置的。剩下的参数也可以快速通过简单的试错得到一个还不错的初始值。对于这个问题，我的观点一直是每天在抱怨CNN调参困难，在用grid search的人，其实还没理解CNN。</p>
</li>
<li><p>作者不停在claim说gcForest在小数据好，无需调参。然而这只是在不停强调一个low capacity model的好处，这个事情的另外一面在于low capacity model会很快饱和，喂进去再多数据也不会有性能增长。更进一步说，我丝毫不会奇怪tree based model在同等参数条件下比nn based model结果好。因为tree based model就是可以更好地利用参数，然而上限也很快会到来。最后给大家罗列几个非常相似的idea和claim，最后都无法在大数据上取得令人信服结果的工作：</p>
</li>
</ol>
<ul>
<li><p>DSN：邓力老师的工作。基本完全一样的idea，除了是用NN不是forest。</p>
</li>
<li><p>ELM：这么多年了，仍然没有拿得出手的让人信服的结果。。。</p>
</li>
<li><p>PCANet：好在作者自己就认识到这是一个baseline的工作，尝试过大数据，并不work。</p>
</li>
<li><p>SARM：去年炒的沸沸扬扬的NIPS撤稿了的工作。其实单从方法本身来讲着paper并没啥太大问题。但是请大家注意，这个工作当初引起了诸多大牛的注意就是因为paper实验中讲在ImageNet上做出来很好的结果。不过最终也是证明是由于实验错误导致的。</p>
</li>
</ul>
<p>这里有一个三年前做的<a href="http://winsty.net/talks/nonNN.pptx" target="_blank" rel="external">survey</a>。综上，这个paper作为一个junior PhD练手的工作还好，但是要谈多大影响力实在差的还远。历史总是在重复上演，这个idea是属于那种如果有实习生来跟我讲这样一个idea，我绝对不会同意去做的工作。最后吐槽，一个paper的影响力长期来看是会均值回归的，不会因为某个媒体或者某个人爆炒一波成就一个经典工作。希望在这个浮躁的年代，每个人尤其是研究者保持独立思考，不要人云亦云。不忘初心，方得始终。</p>
<p>作者：<a href="https://www.zhihu.com/question/56474891/answer/149549752" target="_blank" rel="external">Naiyan Wang</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Clustering-Again/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Clustering-Again/" itemprop="url">
                  Clustering Again
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:13:43+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Clustering-Again/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Clustering-Again/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Mean-Shift-Clustering"><a href="#Mean-Shift-Clustering" class="headerlink" title="Mean-Shift-Clustering"></a>Mean-Shift-Clustering</h1><p><a href="http://efavdb.com/mean-shift/" target="_blank" rel="external">1</a><br><a href="https://en.wikipedia.org/wiki/Mean_shift" target="_blank" rel="external">2</a><br><a href="https://github.com/mattnedrich/MeanShift_py" target="_blank" rel="external">3</a></p>
<p>依然是介绍Alex和Alessandro于2014年发表在的Science上的一篇关于聚类的文章 <a href="http://science.sciencemag.org/content/344/6191/1492" target="_blank" rel="external">Clustering by fast search and find of density peak</a>s，该文章的基本思想很简单，但是其聚类效果却兼具了谱聚类(Spectral Clustering)[<a href="http://www.cs.cornell.edu/courses/cs6780/2010fa/materials/nips01-spectral.pdf" target="_blank" rel="external">On spectral clustering: Analysis and an algorithm</a>, <a href="https://www.cs.cmu.edu/~aarti/Class/10701/slides/Lecture21_2.pdf" target="_blank" rel="external">Spectral clustering</a>, <a href="http://www.cis.rit.edu/~cnspci/references/luxburg2007.pdf" target="_blank" rel="external">A tutorial on spectral clustering</a>]和K-Means的特点，着实激起了极大的兴趣，该聚类算法主要是基于两个基本点：</p>
<ol>
<li>聚类中心的密度高于其临近的样本点的密度</li>
<li>聚类中心与比其密度还高的聚类中心的距离相对较大</li>
</ol>
<p>基于这个思想，聚类过程中的聚类中心数目可以很直观的选取，离群点也能被自动检测出来并排除在聚类分析外。无论每个聚类的形状是什么样的，或者样本点的维度是多少，聚类分析的结果都能令人很满意。下面我会主要基于这篇文章来详述该聚类算法的来龙去脉，并简单回顾下相关的聚类算法。</p>
<h2 id="聚类算法回顾"><a href="#聚类算法回顾" class="headerlink" title="聚类算法回顾"></a>聚类算法回顾</h2><p>众所周知，聚类分析目的在于根据样本之间的相似性将样本划为不同的类簇，但聚类的科学定义貌似在学术界还未达成共识。论文[<a href="https://www.ncbi.nlm.nih.gov/pubmed/15940994" target="_blank" rel="external">Survey of clustering algorithms</a>]对聚类算法进行了综述，发现有好多聚类算法都未曾了解。在K-means和K-medoids中，每个类簇都由一组到各自的聚类中心距离最近的数据组成。两者的目标函数形式为各样本点到对应的聚类中心的距离之和，经过反复的更新聚类中心和重新为样本点分配聚类中心的过程直至收敛，如图1所示。两者的区别在于，K-means的聚类中心为<strong>属于该类簇的所有样本点的均值</strong>，而K-medoids的聚类中心为<strong>该类簇中离所有样本点的聚类之和最小的样本点</strong>。这两者聚类算法实现起来都非常简单，对于紧凑型的和呈超球体状分布的数据非常适用。但两者的缺陷也很明显：</p>
<ol>
<li>缺乏能确定类簇数目和进行初步划分的有效机制；</li>
<li>迭代优化的策略无法保证全局最优解；</li>
<li>对离群点和噪声非常敏感</li>
</ol>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-001.png" alt="l2_1"></center>


<p>在基于概率密度的聚类算法中，我们会假设<strong>各类簇由不同的概率密度函数产生</strong>(如图2)，而每个样本点则是以不同的权重服从这些概率分布的。<strong>很不幸的是，在这类算法中用最大似然估计求解参数往往不可行</strong>，只能用迭代求解的方式获得一个次优解，而<strong>期望最大化(Expectation Maximization,EM)</strong>是最常用的一个策略。在这类算法中，最典型的莫过于<strong><a href="http://www.researchgate.net/publication/303672489_Gaussian_Mixture_Models" target="_blank" rel="external">高斯混合模型(Gaussian Mixture Model</a>,GMM)</strong>。这类算法的准确度取决于<strong>预先定义的概率分布能否很好的拟合训练数据</strong>，但问题在于很多情况下我们无法知晓数据在整体上或者局部上到底近似于什么样的概率分布。  </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-002.png" alt="l2_1"></center>

<p>基于局部密度的聚类算法可以很容易地检测出任意形状的类簇。在<a href="https://www.researchgate.net/publication/221653977_A_Density-Based_Algorithm_for_Discovering_Clusters_in_Large_Spatial_Databases_with_Noise" target="_blank" rel="external">DBSCAN</a>中，需要用户给定<strong>密度阈值</strong>和<strong>领域半径</strong>作为参数，在领域半径内的密度小于该阈值的样本点被视为噪声点，剩下的密度较高的非连通区域则被分配到不同的类簇中，其伪代码如下所示。但是选择合适的密度阈值并不是那么容易的事情，有关的参数估计建议可参见<a href="http://en.wikipedia.org/wiki/DBSCAN" target="_blank" rel="external">wiki</a>。DBSCAN的优点总结如下：</p>
<ol>
<li>无需预先指定类簇的数目；</li>
<li>可以发现任意形状的类簇，如图3所示；</li>
<li>可以检测出噪声点，且对噪声点鲁棒性较强；</li>
<li>除了边界点外，聚类结果(核心点与噪声点)与样本点的遍历顺序无关。</li>
</ol>
<p>DBSCAN的缺点总结如下：</p>
<ol>
<li>针对边界点而言，DBSCAN的聚类结果并非完全确定的。幸运的是这种情况并非频繁出现，而且对聚类的结果影响很小。如果把边界点也当成噪声点处理，那么聚类结果就具有确定性。</li>
<li>聚类结果依赖于距离度量规则。最常用的<strong>欧式距离在高维空间里由于“维度灾难”</strong>几乎无法发挥有效作用，使得设定合适的搜寻半径更为困难。</li>
<li><p><strong>不适用于密度差异很大的数据集</strong>，因为此时各个类簇的搜寻半径和密度阈值都不相同，使得参数的选取更为困难。</p>
<pre><code>DBSCAN(D, eps, minPts)
//eps:search radius
//minPts:density threshold
   C = 0
   for each unvisited point P in dataset D
      mark P as visited
      NeighborPts = regionQuery(P, eps)
      if sizeof(NeighborPts) &lt; minPts
         mark P as NOISE
      else
         C = next cluster
         expandCluster(P, NeighborPts, C, eps, MinPts)

expandCluster(P, NeighborPts, C, eps, minPts)
   add P to cluster C
   for each point Q in NeighborPts 
      if Q is not visited
         mark Q as visited
         NeighborPts&apos; = regionQuery(Q, eps)
         if sizeof(NeighborPts&apos;) &gt;= minPts
            NeighborPts = NeighborPts joined with NeighborPts&apos;
      if Q is not yet member of any cluster
         add Q to cluster C

regionQuery(P, eps)
   return all points within P&apos;s eps-neighborhood (including P)
</code></pre></li>
</ol>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-003.png" alt="l2_1"></center>

<p>基于均值漂移(Mean-shift)[<a href="http://en.wikipedia.org/wiki/Mean-shift" target="_blank" rel="external">Mean-shift</a>, <a href="http://ieeexplore.ieee.org/document/1000236/" target="_blank" rel="external">Mean shift: A robust approach toward feature space analysis</a>, <a href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/mean_shift.pdf" target="_blank" rel="external">Mean shift clustering</a>]的聚类算法则无需为<strong>搜索半径</strong>和<strong>密度阈值</strong>的设定而烦恼，不过也面临bandwidth的选取问题，关于怎么设定bandwidth的研究可参见[<a href="http://ieeexplore.ieee.org/document/937550/" target="_blank" rel="external">The variable bandwidth mean shift and data-driven scale selection</a>, <a href="http://pdf.aminer.org/000/169/427/image_and_video_segmentation_by_anisotr**opic_kernel_mean_shift.pdf" target="_blank" rel="external">Image and video segmentation by anisotropic kernel mean shift</a>]。Mean-sift的基本思路就是从初始点出发，以梯度上升的方式不断寻找核密度估计函数的局部最大值直至收敛<strong>(如图4(a)所示)，这些驻点代表分布的模式。在基于mean-shift的聚类算法中，依次以每一个样本点作为mean-shift的起始点，然后将其移至核密度估计函数的某个局部驻点，最后近似收敛到同一个驻点的所有样本被划分至同一个类簇，如图4(b)所示。总体而言，在基于密度的聚类算法中，</strong>类簇可被定义为收敛到相同的密度分布函数局部极大值的样本点的集合**。 </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-005.png" alt="l2_1"></center>

<h2 id="基于密度峰值和距离的聚类算法"><a href="#基于密度峰值和距离的聚类算法" class="headerlink" title="基于密度峰值和距离的聚类算法"></a>基于密度峰值和距离的聚类算法</h2><p>该聚类算法的假设前提是聚类中心周围的样本点的局部密度低于聚类中心的局部密度，并且聚类中心与比其局部密度更高的点之间的距离相对较大。其聚类效果与DBSCAN和mean-shift类似，可以检测出非球体的类簇。作者号称可以<strong>自动</strong>找到类簇的数目，虽然文中给了一点相关的寻找聚类数目的思路，但是提供的Matlab代码中没有实现该思路，还是需要人工选择聚类中心，所以在相关评论[<a href="http://comments.sciencemag.org/content/10.1126/science.1242072" target="_blank" rel="external">Comments on clustering by fast search and find of density peaks</a>]中“自动”一词遭到了质疑。与mean-shift类似，聚类中心定义为局部密度最大值点；与mean-shift不同的是，聚类中心是某个特定样本点，并且无需在核函数定义的空间内针对每个样本点显式求解局部密度最大的点。 </p>
<p>根据这篇文章的评论，发现还有两个密度的度量方法也是很有价值的。第一个是用样本点与最近的M个邻居的距离的均值的负数来描述，另一个就是高斯核函数来度量，会比用截断距离度量鲁棒性更强一些。</p>
<p>对于密度值为局部或全局最大的样本点而言，它们的δi会比其他样本点的δj值要大很多(如图5所示)，因为前者代表局部密度最大的样本点之间的距离，而后者代表样本点与其对应的局部密度最大的样本点之间的距离。因此，那些δ值很大的样本点也很有可能就是聚类中心。 </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-006.png" alt="l2_1"></center>

<p>在找出聚类中心后，接下来就是将所有剩下的点划分到比其密度更高且最近的样本点所属的类簇中，当然经过这一步之后暂时会为噪声点也分配到类簇中。在聚类分析中，经常还会<strong>进一步分析类簇分配的可靠性</strong>。在<strong>DBSCAN</strong>中，只考虑了密度高于密度阈值的可靠性高一些的样本点，但是会出现较低密度的类簇被误认为噪声的情况。文中取而代之的是为每个类簇引入<strong>边界区域</strong>的概念。边界区域的密度值ρb会根据属于这个类簇并且与属于其他类簇的样本点之间的距离小于dc的成员计算出来。对于每个类簇中的所有样本点，密度值高于ρb的被视为类簇的核心组成部分(cluster core)，剩下的则被视为该类簇的<strong>光晕(cluster halo)</strong>，类簇光晕中则包含噪声点。论文中给出了一个聚类的结果，如图7所示。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-008.png" alt="l2_1"></center>

<p>邻域搜索半径dc到底如何取值呢？dc显然是对聚类结果又影响的，这一点我们仅需要考虑两个最极端的情形就明白了。如果dc太大，那么每个数据点的密度值都近似相等，导致所有数据点被划分至同一个类簇中；如果dc太小，每个类簇包含的样本点会很少，很有可能出现同一个类簇被分割成好几部分的情况。另一方面，不同的数据集中数据点之间的密集程度不同，那么想给出一个适合所有数据集的dcdc是不可能的。作者在文中提出，合适的dc应该使数据点的平均近邻数目占整个数据集规模的比例为τ,<strong>(τ=1%∼2%)</strong>。如此一来，参数τ就独立于特定数据集了。针对每个数据集，我们都可以寻找一个比较合适的dc。结合作者给出的Matlab代码，分析后可知具体的计算方法如下：取出对称的距离矩阵的上三角所有的<strong>M=N(N−1)/2</strong>个元素，然后对其进行升序排列<strong>d1≤d2≤⋯≤dMd1≤d2≤⋯≤dM</strong>。为了保证平均每个数据点的近邻点数目所占比例为τ，那么只要保证小于dcdc的距离数目所占比例也为ττ即可，因此取dc=dround(τM)dc=dround(τM)。 </p>
<p>类簇的数目该如何确定呢？作者给Matlab代码中，聚类中心是需要人工选定的，很多读者因此质疑文中的”it is able to detect nonspherical clusters and to automatically find the correct number of clusters”，是不是有种被欺骗的感觉。不过作者在文中也给出了一个简单选择类簇的数目，虽然我也觉得该方法存在一些问题，但总归还是给出了解决方案的。由前面解释的论文的两个基本立足点可知，聚类中心对应的ρρ和δδ都是比较大的。作者为每个样本点xi引入γi=ρiδi，然后将所有的γi降序排列后显示在图9(a)。如果分别对ρ和δ先做<strong>归一化处理</strong>后会更合理一些，这样也会使得两者参与决策的权重相当。因为如果ρ和δ的不在一个数量级，那么必然数量级小带来的的影响会很小。</p>
<p>接下来怎么办呢？作者依然没有给出具体的解决方案。因为整体而言，γ的值在大多数情况下还是很相近的，差异比较大的就是那几个聚类中心，我觉得可以从异常检查(Anomaly Detection)的角度去寻找这个跳跃点。最简单方法，可以根据相邻γ的值构建一个高斯分布N(μ,σ2)，根据最大似然参数估计法，该高斯分布的参数只需扫描两遍γ的值即可，所以模型还是很效率还是很高的。有了这个模型后，我们从后往前扫描γ的值，如果发现某个值的左边或右边的累积概率(如图8的左右两侧蓝色区域)小于阈值(比如0.005)时就判定找到了异常的跳跃点，此时就能大致确定类簇的数目了。若想进一步学习如何利用高斯分布进行异常检测可参见[<a href="http://www.holehouse.org/mlclass/15_Anomaly_Detection.html" target="_blank" rel="external">Anomaly detection</a>]。 我们都知道高斯分布的概率密度函数,可是高斯分布的累积分布函数(Cumulative Distribution Function)不存在初等函数的表达形式,那该如何是好?查找了半天资料,也没找到如何数值逼近的原理说明,不过搜到了一段用java编写的基于Hart Algorithm近似计算标准正态分布的累积分布函数的代码[<a href="http://www.onedigit.org/Home/quantitative-finance/hart-algorithm-for-normal-cdf" target="_blank" rel="external">Hart algorithm for normal cdf</a>]。寥寥数行java代码就搞定了,但是我暂时没理解为什么这么做是可行的。将输出结果和维基百科上的Q函数表[<a href="http://en.wikipedia.org/wiki/Q-function" target="_blank" rel="external">Q-function</a>]中的数据对比分析(注意1−Q(x)=Φ(x)),发现结果和预期的一模一样,简直惊呆。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-009.png" alt="l2_1"></center>


<pre><code>double CDFofNormalDistribution(double x)
{
    const double PI=3.1415926;
    double p0=220.2068679123761;
    double p1=221.2135961699311;
    double p2=112.0792914978709;
    double p3=33.91286607838300;
    double p4=6.373962203531650;
    double p5=.7003830644436881;
    double p6=.03326249659989109;

    double q0=440.4137358247552;
    double q1=793.8265125199484;
    double q2=637.3336333788311;
    double q3=296.5642487796737;
    double q4=86.78073220294608;
    double q5=16.06417757920695;
    double q6=1.755667163182642;
    double q7=0.08838834764831844;

    double cutoff=7.071;//10/sqrt(2)
    double root2pi=2.506628274631001;//sqrt(2*PI)

    double xabs=abs(x);

    double res=0;
    if(x&gt;37.0) 
        res=1.0;
    else if(x&lt;-37.0)
        res=0.0;
    else
    {
        double expntl=exp(-.5*xabs*xabs);
        double pdf=expntl/root2pi;
        if(xabs&lt;cutoff)
            res=expntl*((((((p6*xabs + p5)*xabs + p4)*xabs + p3)*xabs+ \
                p2)*xabs + p1)*xabs + p0)/(((((((q7*xabs + q6)*xabs + \
                q5)*xabs + q4)*xabs + q3)*xabs + q2)*xabs + q1)*xabs+q0);
        else
            res=pdf/(xabs+1.0/(xabs+2.0/(xabs+3.0/(xabs+4.0/(xabs+0.65)))));
    }
    if(x&gt;=0.0)
        res=1.0-res;
    return res;
}
</code></pre><p>此外，作者声称根据随机均匀分布生成的数据对应的γ服从幂律分布(Power laws)，但是真正具备聚类中心的数据集是不存在这种情况的。很多现象其实都是近似服从幂律分布的，尤其适用于大多数事件的规模很小但少数事件规模很大的场合，不过作者在此并未给出该定论的出处，所以同样这一点遭到了很多读者的质疑。我猜目前只是作者根据一些实验数归纳出来的，只能说是靠不完全统计得到的经验，没有实质性的理论依据。也就是γ≈cr−k+ϵ，其中r为γ的排名序号，那么log⁡γ和log⁡r之间应该近似呈现线性关系，如图9(b)所示。如果作者的猜测正确的话，我们不妨在聚类前汇出如log⁡γ和log⁡r的关系图，借此判断聚类的复杂性，或者说在该数据集上进行聚类的结果可靠性如何。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-010.png" alt="l2_1"></center>

<p>注：代码有两处需要更改：</p>
<ol>
<li>计算radius时Num换成Num*(Num-1)；</li>
<li>求聚类个数时，求几个聚类中心点（N个值的前k个），有句code应该在for循环外。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/02/Summary-of-Clustering/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/02/Summary-of-Clustering/" itemprop="url">
                  Summary-of-Clustering
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-02T22:12:19+08:00">
                2017-03-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/02/Summary-of-Clustering/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/02/Summary-of-Clustering/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近看了下聚类算法，在此记个笔记。</p>
<p>cousera上不错的clustering公开课 <a href="http://hanj.cs.illinois.edu/" target="_blank" rel="external">jiawei han</a></p>
<ul>
<li>为什么基于距离的聚类算法只能发现类圆形？</li>
</ul>
<p>这和你选择的范数有关，因为是在欧式空间内求的距离，对应的就是周围点到中心点的距离，只管看起来就是画圆圈啊，确定了半径，圆圈内的都是这个类了。但是这只是在欧式空间内对欧氏距离的应用，如果你对流行数据做聚类，就会发现这个聚类对距离进行了重新的定义，看起来就不是你所谓的与圆圈之类的。</p>
<ul>
<li><a href="https://www.zhihu.com/question/20977382" target="_blank" rel="external">哪种聚类算法可以不需要指定聚类的个数，而且可以生成聚类的规则？</a></li>
</ul>
<p><a href="https://www.zhihu.com/question/20759409" target="_blank" rel="external"><strong>聚类算法的经典综述：</strong></a></p>
<ol>
<li><a href="https://link.springer.com/chapter/10.1007%2F978-3-540-87479-9_3" target="_blank" rel="external">Data Clustering</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.318.2219&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Survey of Clustering Algorithms</a></li>
<li><a href="https://link.springer.com/article/10.1007%2Fs40745-015-0040-1" target="_blank" rel="external">A Comprehensive Survey of Clustering Algorithms. Annals of Data Science</a></li>
</ol>
<h2 id="k-means聚类算法优缺点"><a href="#k-means聚类算法优缺点" class="headerlink" title="k-means聚类算法优缺点"></a>k-means聚类算法优缺点</h2><p>优点：</p>
<ol>
<li>计算速度快</li>
<li>已解释</li>
<li>效果还不错</li>
<li>相对稳定，谱聚类效果好，层次聚类快</li>
</ol>
<p>缺点：</p>
<ol>
<li>对异常值相当敏感</li>
<li>需要提前知道k值</li>
<li>收敛慢</li>
<li>不一定全局最优</li>
</ol>
<hr>
<p>主要读了文章：<a href="http://science.sciencemag.org/content/344/6191/1492" target="_blank" rel="external">Clustering by fast search and find of density peaks</a> Alex Rodriguez, <a href="http://people.sissa.it/~laio/Research/Res_clustering.php" target="_blank" rel="external">Alessandro Laio</a></p>
<h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p>该算法的<strong>两个重要假设</strong>：类簇的中心由一些局部密度比较低的点围绕, 并且这些点距离其他有高局部密度的点的距离都比较大. </p>
<p>首先定义两个值: 局部密度以及到高局部密度点的距离delta。</p>
<p>样本点局部密度p：</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-001.jpg" alt="l2_1"></center><br><img src="/2017/03/02/Summary-of-Clustering/2017-0302-010.jpg" alt="l2_1"><br><br>dc是一个截断距离, 是一个参数. 所以相当于距离点di的距离小于的点的个数。文章的实验表明，dc的选择比较鲁棒, 文中dc的推荐值是使得平均每个点的邻居数为样本总数的1%-2%。如果样本点的数量过小即分布过散，可参照mean-shift，采用核密度估计的方法计算每点的局部密度。<br><br>样本点到高局部密度点的距离：<br><center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-002.jpg" alt="l2_1"></center><br>由公式可知，为密度高于样本点的样本点到样本点的最近距离。对于密度最大的点<img src="/2017/03/02/Summary-of-Clustering/2017-0302-003.jpg" alt="l2_1">,。由定义可知，局部密度最大的点肯定是一个中心点。<br><br>## 聚类过程<br><br>计算出所有样本点的局部密度值和到高局部密度点的距离后，可以得到一张决策图。在决策图上挑选出具有较大以及较大的样本点作为类簇中心。<strong>在确定了类簇中心之后, 其它样本点依据局部密度从高到低依先后顺序确定所属的类别，每个人非中心的样本点的类别为邻域内最近的高于该点样本点的点的样本点所属的类别（重要，如此可满足流形）。</strong>图例如下:<br><br><center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-004.png" alt="l2_1"></center>

<center><strong>聚类过程说明</strong></center>

<p>如图所示，总共有28个样本点，样本点按密度高低从小到大给以标号，即1～28号点局部密度递减。通过图1右侧的决策图，我们筛选出具有较大以及较大的1号和10号点作为类簇中心，其余点按密度从高到低依次赋予所属类簇标号。如首先为2号点赋值，离2号最近的密度高于2号点的为1，因此将1号点所属标号赋予2号；对于3号点，离3号最近的密度高于3号点的为1，因此将1号点所属标号赋予3号；对于4号点，离4号最近的密度高于4号点的为1，因此将1号点所属标号赋予4号；<em>对于5号点，离5号最近的密度高于4号点的为4，因此将4号点所属标号赋予5号……</em>，如此直至标完所有样本点标号。此外，26, 27, 28三个点的也比较大, 但是较小, 所以是异常点.</p>
<h2 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h2><p>聚类分析主要是评估本文算法对参数以及样本分布的鲁棒性。</p>
<p> <strong>首先评估样本分布对聚类结果的影响。</strong>在聚类分析中, 通常需要确定每个点划分给某个类簇的可靠性. 在该算法中, 可以首先为每个类簇定义一个边界区域(border region), 亦即划分给该类簇但是距离其他类簇的点的距离小于的点. 然后为每个类簇找到其边界区域的局部密度最大的点, 令其局部密度为. 该类簇中所有局部密度大于的点被认为是类簇核心的一部分(亦即将该点划分给该类簇的可靠性很大), 其余的点被认为是该类簇的光晕(halo), 亦即可以认为是噪音。图例如下：</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-005.png" alt="l2_1"></center>

<center><strong>样本疏密对聚类结果的影响</strong></center>

<p>A图为生成数据的概率分布, B, C二图为分别从该分布中生成了4000, 1000个点. D, E分别是B, C两组数据的决策图, 可以看到两组数据都只有五个点有具有较大以及较大 这些点作为类簇的中心, 在确定了类簇的中心之后, 每个点被划分到各个类簇(彩色点), 或者是划分到类簇光晕(黑色点)。F图展示的是随着抽样点数量的增多, 聚类的错误率在逐渐下降。由图可知当样本数处于1000～10000时，聚类错误率均为1%以下， 说明该算法对数据疏密具有一定的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-006.jpg" alt="l2_1"></center><br><center><strong>阈值dc对算法的影响</strong></center>

<p><strong>其次评估参数对聚类结果的影响。</strong>如图所示，分别设置的值为0.005、0.001，0.005和0.1。由以上4个不同的值，得到4种聚类结果。观察图3可发现，当的值从0.005变化值0.1时，虽然的值变化了20倍，但是聚类结果在感官上并无大的差异。以上说明，本文算法对阈值具有良好的鲁棒性。</p>
<p><strong>接着评估不同的数据分布对聚类结果的影响。</strong> 图4中的4幅子图中的数据都具有较大的聚类难度。其中，图A的难点在于，类的大小不均衡；图B的难度在于类的数量繁多，且高度重合；图C和图D的难度在于各类在特征空间上分布为非球形。一般来讲，在涉及到利用流形分类的算法中，图C和图D都会作为经典的测试数据。由4幅子图的聚类结果容易看出本文算法对数据分布的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-007.png" alt="l2_1"></center><br><center><strong>不同的数据分布下的聚类效果展示</strong></center>

<p><strong>最后评估不同度量对聚类结果的影响。</strong>如图5所示，对图A中的数据做3种非线性映射分别得到B、C和D三种新的数据分布。由A、B、C和D的聚类结果可以看出，本文算法对度量具有好的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-008.jpg" alt="l2_1"></center><br><center><strong>不同的度量对聚类结果的影响</strong></center>

<h2 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a>算法总结</h2><p>本文提出的算法在本质上是基于流形的做法。本文的算法的过程可以总结为：首先搜索合适的局部密度最大点作为类簇中心，然后再将类簇标签从高密度点向低密度点依次传播。</p>
<p>参考资料：一个很用心的<a href="http://www.cnblogs.com/jeromeblog/p/4141902.html" target="_blank" rel="external">blog</a>，想大神致敬。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/02/Optimization/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/02/Optimization/" itemprop="url">
                  Optimization
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-02T12:11:19+08:00">
                2017-03-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/02/Optimization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/02/Optimization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="最优化-Optimization"><a href="#最优化-Optimization" class="headerlink" title="最优化 Optimization"></a>最优化 Optimization</h2><p>在之前介绍了图像分类任务中的两个关键部分：</p>
<ol>
<li><p>基于参数的<strong>评分函数</strong>。该函数将原始图像像素映射为分类评分值（例如：一个线性函数）。</p>
</li>
<li><p><strong>损失函数</strong>。该函数能够根据分类评分和训练集图像数据实际分类的一致性，衡量某个具体参数集的质量好坏。损失函数有多种版本和不同的实现方式（例如：Softmax或SVM）。</p>
</li>
</ol>
<p>上节中，线性函数的形式是<img src="/2017/03/02/Optimization/2017-03-02-001.png" alt="Optimization">，而SVM实现的公式是：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-002.png" alt="Optimization"></center>

<p>对于图像数据x_i，如果基于参数集W做出的分类预测与真实情况比较一致，那么计算出来的损失值L就很低。现在介绍第三个，也是最后一个关键部分：<strong>最优化Optimization</strong>。最优化是寻找能使得损失函数值最小化的参数W的过程。</p>
<p>铺垫：一旦理解了这三个部分是如何相互运作的，我们将会回到第一个部分（基于参数的函数映射），然后将其拓展为一个远比线性函数复杂的函数：首先是神经网络，然后是卷积神经网络。而损失函数和最优化过程这两个部分将会保持相对稳定。</p>
<h2 id="损失函数可视化"><a href="#损失函数可视化" class="headerlink" title="损失函数可视化"></a>损失函数可视化</h2><p>本课中讨论的损失函数一般都是定义在高维度的空间中（比如，在CIFAR-10中一个线性分类器的权重矩阵大小是[10x3073]，就有30730个参数），这样要将其可视化就很困难。然而办法还是有的，在1个维度或者2个维度的方向上对高维空间进行切片，就能得到一些直观感受。例如，随机生成一个权重矩阵W，该矩阵就与高维空间中的一个点对应。然后沿着某个维度方向前进的同时记录损失函数值的变化。换句话说，就是生成一个随机的方向W_1并且沿着此方向计算损失值，计算方法是根据不同的a值来计算L(W+aW_1)。这个过程将生成一个图表，其x轴是a值，y轴是损失函数值。同样的方法还可以用在两个维度上，通过改变a,b来计算损失值L(W+aW_1+bW_2)，从而给出二维的图像。在图像中，a,b可以分别用x和y轴表示，而损失函数的值可以用颜色变化表示：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-003.png" alt="Optimization"></center>

<p>一个无正则化的多类SVM的损失函数的图示。左边和中间只有一个样本数据，右边是CIFAR-10中的100个数据。<strong>左</strong>：a值变化在某个维度方向上对应的的损失值变化。<strong>中和右</strong>：两个维度方向上的损失值切片图，蓝色部分是低损失值区域，红色部分是高损失值区域。注意损失函数的分段线性结构。多个样本的损失值是总体的平均值，所以右边的碗状结构是很多的分段线性结构的平均（比如中间这个就是其中之一）。</p>
<hr>
<p>我们可以通过数学公式来解释损失函数的分段线性结构。对于一个单独的数据，有损失函数的计算公式如下：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-004.png" alt="Optimization"></center><br>通过公式可见，每个样本的数据损失值是以W为参数的线性函数的总和（零阈值来源于max(0,-)函数）。W的每一行（即w_j），有时候它前面是一个正号（比如当它对应错误分类的时候），有时候它前面是一个负号（比如当它是是正确分类的时候）。为进一步阐明，假设有一个简单的数据集，其中包含有3个只有1个维度的点，数据集数据点有3个类别。那么完整的无正则化SVM的损失值计算如下：<br><br><center><img src="/2017/03/02/Optimization/2017-03-02-005.png" alt="Optimization"></center><br>因为这些例子都是一维的，所以数据x_i和权重w_j都是数字。观察w_0，可以看到上面的式子中一些项是w_0的线性函数，且每一项都会与0比较，取两者的最大值。可作图如下：<br><br><center><img src="/2017/03/02/Optimization/2017-03-02-006.png" alt="Optimization"></center>

<p>从一个维度方向上对数据损失值的展示。x轴方向就是一个权重，y轴就是损失值。数据损失是多个部分组合而成。其中每个部分要么是某个权重的独立部分，要么是该权重的线性函数与0阈值的比较。完整的SVM数据损失就是这个形状的30730维版本。</p>
<hr>
<p>需要多说一句的是，你可能根据SVM的损失函数的碗状外观猜出它是一个凸函数。关于如何高效地最小化凸函数的论文有很多，你也可以学习斯坦福大学关于（凸函数最优化）的课程。但是一旦我们将f函数扩展到神经网络，目标函数就就不再是凸函数了，图像也不会像上面那样是个碗状，而是凹凸不平的复杂地形形状。</p>
<p>不可导的损失函数。作为一个技术笔记，你要注意到：由于max操作，损失函数中存在一些不可导点（kinks），这些点使得损失函数不可微，因为在这些不可导点，梯度是没有定义的。但是次梯度（subgradient）依然存在且常常被使用。在本课中，我们将交换使用次梯度和梯度两个术语。</p>
<h2 id="最优化-Optimization-1"><a href="#最优化-Optimization-1" class="headerlink" title="最优化 Optimization"></a>最优化 Optimization</h2><p>重申一下：损失函数可以量化某个具体权重集W的质量。而最优化的目标就是找到能够最小化损失函数值的W 。我们现在就朝着这个目标前进，实现一个能够最优化损失函数的方法。对于有一些经验的同学，这节课看起来有点奇怪，因为使用的例子（SVM 损失函数）是一个凸函数问题。但是要记得，最终的目标是不仅仅对凸函数做最优化，而是能够最优化一个神经网络，而对于神经网络是不能简单的使用凸函数的最优化技巧的。</p>
<h3 id="策略-1：一个差劲的初始方案：随机搜索"><a href="#策略-1：一个差劲的初始方案：随机搜索" class="headerlink" title="策略#1：一个差劲的初始方案：随机搜索"></a>策略#1：一个差劲的初始方案：随机搜索</h3><p>既然确认参数集<strong>W</strong>的好坏蛮简单的，那第一个想到的（差劲）方法，就是可以随机尝试很多不同的权重，然后看其中哪个最好。过程如下：</p>
<pre><code># 假设X_train的每一列都是一个数据样本（比如3073 x 50000）
# 假设Y_train是数据样本的类别标签（比如一个长50000的一维数组）
# 假设函数L对损失函数进行评价

bestloss = float(&quot;inf&quot;) # Python assigns the highest possible float value
for num in xrange(1000):
  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters
  loss = L(X_train, Y_train, W) # get the loss over the entire training set
  if loss &lt; bestloss: # keep track of the best solution
    bestloss = loss
    bestW = W
  print &apos;in attempt %d the loss was %f, best %f&apos; % (num, loss, bestloss)

# 输出:
# in attempt 0 the loss was 9.401632, best 9.401632
# in attempt 1 the loss was 8.959668, best 8.959668
# in attempt 2 the loss was 9.044034, best 8.959668
# in attempt 3 the loss was 9.278948, best 8.959668
# in attempt 4 the loss was 8.857370, best 8.857370
# in attempt 5 the loss was 8.943151, best 8.857370
# in attempt 6 the loss was 8.605604, best 8.605604
# ... (trunctated: continues for 1000 lines)
</code></pre><p>在上面的代码中，我们尝试了若干随机生成的权重矩阵<strong>W</strong>，其中某些的损失值较小，而另一些的损失值大些。我们可以把这次随机搜索中找到的最好的权重<strong>W</strong>取出，然后去跑测试集：</p>
<pre><code># 假设X_test尺寸是[3073 x 10000], Y_test尺寸是[10000 x 1]
scores = Wbest.dot(Xte_cols) # 10 x 10000, the class scores for all test examples
# 找到在每列中评分值最大的索引（即预测的分类）
Yte_predict = np.argmax(scores, axis = 0)
# 以及计算准确率
np.mean(Yte_predict == Yte)
# 返回 0.1555
</code></pre><p>验证集上表现最好的权重W跑测试集的准确率是<strong>15.5%</strong>，而完全随机猜的准确率是10%，如此看来，这个准确率对于这样一个不经过大脑的策略来说，还算不错嘛！</p>
<p><strong>核心思路：迭代优化</strong>。当然，我们肯定能做得更好些。核心思路是：虽然找到最优的权重W非常困难，甚至是不可能的（尤其当W中存的是整个神经网络的权重的时候），但如果问题转化为：对一个权重矩阵集W取优，使其损失值稍微减少。那么问题的难度就大大降低了。换句话说，我们的方法从一个随机的W开始，然后对其迭代取优，每次都让它的损失值变得更小一点。</p>
<p><em>我们的策略是从随机权重开始，然后迭代取优，从而获得更低的损失值。</em></p>
<p><strong>蒙眼徒步者的比喻：</strong>一个助于理解的比喻是把你自己想象成一个蒙着眼睛的徒步者，正走在山地地形上，目标是要慢慢走到山底。在CIFAR-10的例子中，这山是30730维的（因为W是3073x10）。我们在山上踩的每一点都对应一个的损失值，该损失值可以看做该点的海拔高度。</p>
<h3 id="策略-2：随机本地搜索"><a href="#策略-2：随机本地搜索" class="headerlink" title="策略#2：随机本地搜索"></a>策略#2：随机本地搜索</h3><p>第一个策略可以看做是每走一步都尝试几个随机方向，如果某个方向是向山下的，就向该方向走一步。这次我们从一个随机W开始，然后生成一个随机的扰动\delta W ，只有当W+\delta W的损失值变低，我们才会更新。这个过程的具体代码如下：</p>
<pre><code>W = np.random.randn(10, 3073) * 0.001 # 生成随机初始W
bestloss = float(&quot;inf&quot;)
for i in xrange(1000):
  step_size = 0.0001
  Wtry = W + np.random.randn(10, 3073) * step_size
  loss = L(Xtr_cols, Ytr, Wtry)
  if loss &lt; bestloss:
    W = Wtry
    bestloss = loss
  print &apos;iter %d loss is %f&apos; % (i, bestloss)
</code></pre><p>使用同样的数据（1000），这个方法可以得到21.4%的分类准确率。这个比策略一好，但是依然过于浪费计算资源。</p>
<h3 id="策略-3：跟随梯度"><a href="#策略-3：跟随梯度" class="headerlink" title="策略#3：跟随梯度"></a>策略#3：跟随梯度</h3><p>前两个策略中，我们是尝试在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的<strong>梯度（gradient）</strong>。在蒙眼徒步者的比喻中，这个方法就好比是感受我们脚下山体的倾斜程度，然后向着最陡峭的下降方向下山。</p>
<p>在一维函数中，斜率是函数在某一点的瞬时变化率。梯度是函数的斜率的一般化表达，它不是一个值，而是一个向量。在输入空间中，梯度是各个维度的斜率组成的向量（或者称为<strong>导数derivatives</strong>）。对一维函数的求导公式如下：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-007.png" alt="Optimization"></center>

<p>当函数有多个参数的时候，我们称导数为偏导数。而梯度就是在每个维度上偏导数所形成的向量。</p>
<h2 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h2><p>计算梯度有两种方法：一个是缓慢的近似方法（<strong>数值梯度法</strong>），但实现相对简单。另一个方法（<strong>分析梯度法</strong>）计算迅速，结果精确，但是实现时容易出错，且需要使用微分。现在对两种方法进行介绍：</p>
<h3 id="利用有限差值计算梯度"><a href="#利用有限差值计算梯度" class="headerlink" title="利用有限差值计算梯度"></a>利用有限差值计算梯度</h3><p>上节中的公式已经给出数值计算梯度的方法。下面代码是一个输入为函数f和向量x，计算f的梯度的通用函数，它返回函数f在点x处的梯度：</p>
<pre><code>def eval_numerical_gradient(f, x):
  &quot;&quot;&quot;  
  一个f在x处的数值梯度法的简单实现
  - f是只有一个参数的函数
  - x是计算梯度的点
  &quot;&quot;&quot; 

  fx = f(x) # 在原点计算函数值
  grad = np.zeros(x.shape)
  h = 0.00001

  # 对x中所有的索引进行迭代
  it = np.nditer(x, flags=[&apos;multi_index&apos;], op_flags=[&apos;readwrite&apos;])
  while not it.finished:

    # 计算x+h处的函数值
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # 增加h
    fxh = f(x) # 计算f(x + h)
    x[ix] = old_value # 存到前一个值中 (非常重要)

    # 计算偏导数
    grad[ix] = (fxh - fx) / h # 坡度
    it.iternext() # 到下个维度

  return grad
</code></pre><p>根据上面的梯度公式，代码对所有维度进行迭代，在每个维度上产生一个很小的变化h，通过观察函数值变化，计算函数在该维度上的偏导数。最后，所有的梯度存储在变量<strong>grad</strong>中。</p>
<p><strong>实践考量：</strong>注意在数学公式中，h的取值是趋近于0的，然而在实际中，用一个很小的数值（比如例子中的1e-5）就足够了。在不产生数值计算出错的理想前提下，你会使用尽可能小的h。还有，实际中用<strong>中心差值公式（centered difference formula）</strong>[f(x+h)-f(x-h)]/2h效果较好。细节可查看<a href="https://en.wikipedia.org/wiki/Numerical_differentiation" target="_blank" rel="external">wiki</a>。</p>
<p>可以使用上面这个公式来计算任意函数在任意点上的梯度。下面计算权重空间中的某些随机点上，CIFAR-10损失函数的梯度：</p>
<pre><code># 要使用上面的代码我们需要一个只有一个参数的函数
# (在这里参数就是权重)所以也包含了X_train和Y_train
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # 随机权重向量
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # 得到梯度
</code></pre><p>梯度告诉我们损失函数在每个维度上的斜率，以此来进行更新：</p>
<pre><code>loss_original = CIFAR10_loss_fun(W) # 初始损失值
print &apos;original loss: %f&apos; % (loss_original, )

# 查看不同步长的效果
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # 权重空间中的新位置
  loss_new = CIFAR10_loss_fun(W_new)
  print &apos;for step size %f new loss: %f&apos; % (step_size, loss_new)

# 输出:
# original loss: 2.200718
# for step size 1.000000e-10 new loss: 2.200652
# for step size 1.000000e-09 new loss: 2.200057
# for step size 1.000000e-08 new loss: 2.194116
# for step size 1.000000e-07 new loss: 2.135493
# for step size 1.000000e-06 new loss: 1.647802
# for step size 1.000000e-05 new loss: 2.844355
# for step size 1.000000e-04 new loss: 25.558142
# for step size 1.000000e-03 new loss: 254.086573
# for step size 1.000000e-02 new loss: 2539.370888
# for step size 1.000000e-01 new loss: 25392.214036
</code></pre><p><strong>在梯度负方向上更新：</strong>在上面的代码中，为了计算<strong>W_new</strong>，要注意我们是向着梯度df的负方向去更新，这是因为我们希望损失函数值是降低而不是升高。</p>
<p><strong>步长的影响：</strong>梯度指明了函数在哪个方向是变化率最大的，但是没有指明在这个方向上应该走多远。在后续的课程中可以看到，选择步长（也叫作学习率）将会是神经网络训练中最重要（也是最头痛）的超参数设定之一。还是用蒙眼徒步者下山的比喻，这就好比我们可以感觉到脚朝向的不同方向上，地形的倾斜程度不同。但是该跨出多长的步长呢？不确定。如果谨慎地小步走，情况可能比较稳定但是进展较慢（这就是步长较小的情况）。相反，如果想尽快下山，那就大步走吧，但结果也不一定尽如人意。在上面的代码中就能看见反例，在某些点如果步长过大，反而可能越过最低点导致更高的损失值。</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-007.jpg" alt="Optimization"></center>

<p>将步长效果视觉化的图例。从某个具体的点W开始计算梯度（白箭头方向是负梯度方向），梯度告诉了我们损失函数下降最陡峭的方向。小步长下降稳定但进度慢，大步长进展快但是风险更大。采取大步长可能导致错过最优点，让损失值上升。步长（后面会称其为<strong>学习率</strong>）将会是我们在调参中最重要的超参数之一。</p>
<hr>
<p><strong>效率问题</strong>：你可能已经注意到，计算数值梯度的复杂性和参数的量线性相关。在本例中有30730个参数，所以损失函数每走一步就需要计算30731次损失函数的梯度。现代神经网络很容易就有上千万的参数，因此这个问题只会越发严峻。显然这个策略不适合大规模数据，我们需要更好的策略。</p>
<h2 id="微分分析计算梯度"><a href="#微分分析计算梯度" class="headerlink" title="微分分析计算梯度"></a>微分分析计算梯度</h2><p>使用有限差值近似计算梯度比较简单，但缺点在于终究只是近似（因为我们对于h值是选取了一个很小的数值，但真正的梯度定义中h趋向0的极限），且耗费计算资源太多。第二个梯度计算方法是利用微分来分析，能得到计算梯度的公式（不是近似），用公式计算梯度速度很快，唯一不好的就是实现的时候容易出错。为了解决这个问题，在实际操作时常常将分析梯度法的结果和数值梯度法的结果作比较，以此来检查其实现的正确性，这个步骤叫做<strong>梯度检查</strong>。</p>
<p>用SVM的损失函数在某个数据点上的计算来举例：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-009.png" alt="Optimization"></center>

<p>可以对函数进行微分。比如，对w_{y_i}进行微分得到：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-010.png" alt="Optimization"></center>

<p><em>译者注：原公式中1为空心字体</em></p>
<p>其中1是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。虽然上述公式看起来复杂，但在代码实现的时候比较简单：只需要计算没有满足边界值的分类的数量（因此对损失函数产生了贡献），然后乘以x_i就是梯度了。注意，这个梯度只是对应正确分类的W的行向量的梯度，那些j\not =y_i行的梯度是：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-011.png" alt="Optimization"></center>

<p>一旦将梯度的公式微分出来，代码实现公式并用于梯度更新就比较顺畅了。</p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>现在可以计算损失函数的梯度了，程序重复地计算梯度然后对参数进行更新，这一过程称为梯度下降，他的<strong>普通</strong>版本是这样的：</p>
<h1 id="普通的梯度下降"><a href="#普通的梯度下降" class="headerlink" title="普通的梯度下降"></a>普通的梯度下降</h1><pre><code>while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # 进行梯度更新
</code></pre><p>这个简单的循环在所有的神经网络核心库中都有。虽然也有其他实现最优化的方法（比如LBFGS），但是到目前为止，梯度下降是对神经网络的损失函数最优化中最常用的方法。课程中，我们会在它的循环细节增加一些新的东西（比如更新的具体公式），但是核心思想不变，那就是我们一直跟着梯度走，直到结果不再变化。</p>
<p><strong>小批量数据梯度下降（Mini-batch gradient descent）</strong>：在大规模的应用中（比如ILSVRC挑战赛），训练数据可以达到百万级量级。如果像这样计算整个训练集，来获得仅仅一个参数的更新就太浪费了。一个常用的方法是计算训练集中的<strong>小批量（batches）</strong>数据。例如，在目前最高水平的卷积神经网络中，一个典型的小批量包含256个例子，而整个训练集是多少呢？一百二十万个。这个小批量数据就用来实现一个参数更新：</p>
<pre><code># 普通的小批量数据梯度下降

while True:
  data_batch = sample_training_data(data, 256) # 256个数据
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # 参数更新
</code></pre><p>这个方法之所以效果不错，是因为训练集中的数据都是相关的。要理解这一点，可以想象一个极端情况：在ILSVRC中的120万个图像是1000张不同图片的复制（每个类别1张图片，每张图片有1200张复制）。那么显然计算这1200张复制图像的梯度就应该是一样的。对比120万张图片的数据损失的均值与只计算1000张的子集的数据损失均值时，结果应该是一样的。实际情况中，数据集肯定不会包含重复图像，那么小批量数据的梯度就是对整个数据集梯度的一个近似。因此，在实践中通过计算小批量数据的梯度可以实现更快速地收敛，并以此来进行更频繁的参数更新。</p>
<p>小批量数据策略有个极端情况，那就是每个批量中只有1个数据样本，这种策略被称为<strong>随机梯度下降（Stochastic Gradient Descent 简称SGD）</strong>，有时候也被称为在线梯度下降。这种策略在实际情况中相对少见，因为向量化操作的代码一次计算100个数据 比100次计算1个数据要高效很多。即使SGD在技术上是指每次使用1个数据来计算梯度，你还是会听到人们使用SGD来指代小批量数据梯度下降（或者用MGD来指代小批量数据梯度下降，而BGD来指代则相对少见）。小批量数据的大小是一个超参数，但是一般并不需要通过交叉验证来调参。它一般由存储器的限制来决定的，或者干脆设置为同样大小，比如32，64，128等。之所以使用2的指数，是因为在实际中许多向量化操作实现的时候，如果输入数据量是2的倍数，那么运算更快。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>信息流的总结图例：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-008.png" alt="Optimization"></center>

<p>数据集中的(x,y)是给定的。权重从一个随机数字开始，且可以改变。在前向传播时，评分函数计算出类别的分类评分并存储在向量f中。损失函数包含两个部分：数据损失和正则化损失。其中，数据损失计算的是分类评分f和实际标签y之间的差异，正则化损失只是一个关于权重的函数。在梯度下降过程中，我们计算权重的梯度（如果愿意的话，也可以计算数据上的梯度），然后使用它们来实现参数的更新。</p>
<hr>
<p>在本节课中：</p>
<ul>
<li><p>将损失函数比作了一个<strong>高维度的最优化地形</strong>，并尝试到达它的最底部。最优化的工作过程可以看做一个蒙着眼睛的徒步者希望摸索着走到山的底部。在例子中，可见SVM的损失函数是分段线性的，并且是碗状的。</p>
</li>
<li><p>提出了迭代优化的思想，从一个随机的权重开始，然后一步步地让损失值变小，直到最小。</p>
</li>
<li><p>函数的<strong>梯度</strong>给出了该函数最陡峭的上升方向。介绍了利用有限的差值来近似计算梯度的方法，该方法实现简单但是效率较低（有限差值就是h，用来计算数值梯度）。</p>
</li>
<li><p>参数更新需要有技巧地设置<strong>步长</strong>。也叫学习率。如果步长太小，进度稳定但是缓慢，如果步长太大，进度快但是可能有风险。</p>
</li>
<li><p>讨论权衡了数值梯度法和分析梯度法。数值梯度法计算简单，但结果只是近似且耗费计算资源。分析梯度法计算准确迅速但是实现容易出错，而且需要对梯度公式进行推导的数学基本功。因此，在实际中使用分析梯度法，然后使用<strong>梯度检查</strong>来检查其实现正确与否，其本质就是将分析梯度法的结果与数值梯度法的计算结果对比。</p>
</li>
<li><p>介绍了<strong>梯度下降</strong>算法，它在循环中迭代地计算梯度并更新参数。</p>
</li>
</ul>
<p><strong>预告：</strong>这节课的核心内容是：理解并能计算损失函数关于权重的梯度，是设计、训练和理解神经网络的核心能力。下节中，将介绍如何使用链式法则来高效地计算梯度，也就是通常所说的反向<strong>传播（backpropagation）机制</strong>。该机制能够对包含卷积神经网络在内的几乎所有类型的神经网络的损失函数进行高效的最优化。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/01/Linear-Classification/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/01/Linear-Classification/" itemprop="url">
                  Linear-Classification
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-01T21:07:57+08:00">
                2017-03-01
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/01/Linear-Classification/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/01/Linear-Classification/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h2><p>之前笔记介绍了图像分类问题。图像分类的任务，就是从已有的固定分类标签集合中选择一个并分配给一张图像。我们还介绍了k-Nearest Neighbor（k-NN）分类器，该分类器的基本思想是通过将测试图像与训练集带标签的图像进行比较，来给测试图像打上分类标签。k-Nearest Neighbor分类器存在以下不足：</p>
<ul>
<li><p>分类器必须记住所有训练数据并将其存储起来，以便于未来测试数据用于比较。这在存储空间上是低效的，数据集的大小很容易就以GB计。</p>
</li>
<li><p>对一个测试图像进行分类需要和所有训练图像作比较，算法计算资源耗费高。</p>
</li>
</ul>
<p><strong>概述</strong>：我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是<strong>评分函数（score function）</strong>，它是原始图像数据到类别分值的映射。另一个是<strong>损失函数（loss function）</strong>，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。</p>
<h2 id="从图像到标签分值的参数化映射"><a href="#从图像到标签分值的参数化映射" class="headerlink" title="从图像到标签分值的参数化映射"></a>从图像到标签分值的参数化映射</h2><p>该方法的第一部分就是定义一个评分函数，这个函数将图像的像素值映射为各个分类类别的得分，得分高低代表图像属于该类别的可能性高低。下面会利用一个具体例子来展示该方法。现在假设有一个包含很多图像的训练集xi\in R^D，每个图像都有一个对应的分类标签yi。这里i=1,2…N并且yi\in 1…K。这就是说，我们有<strong>N</strong>个图像样例，每个图像的维度是<strong>D</strong>，共有<strong>K</strong>种不同的分类。</p>
<p>举例来说，在CIFAR-10中，我们有一个<strong>N</strong>=50000的训练集，每个图像有<strong>D</strong>=32x32x3=3072个像素，而<strong>K</strong>=10，这是因为图片被分为10个不同的类别（狗，猫，汽车等）。我们现在定义评分函数为：<img src="/2017/03/01/Linear-Classification/2017-03-01-001.png" alt="l2_1">，该函数是原始图像像素到分类分值的映射。</p>
<p><strong>线性分类器</strong>：在本模型中，我们从最简单的概率函数开始，一个线性映射：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-002.png" alt="l2_2"></center>

<p>在上面的公式中，假设每个图像数据都被拉长为一个长度为<strong>D</strong>的列向量，大小为[D x 1]。其中大小为[K x D]的矩阵<br><strong>W</strong>和大小为[K x 1]列向量<strong>b</strong>为该函数的参数（parameters）。还是以CIFAR-10为例，x_i就包含了第i个图像的所有像素信息，这些信息被拉成为一个[3072 x 1]的列向量，W大小为[10x3072]，b的大小为[10x1]。因此，3072个数字（原始像素数值）输入函数，函数输出10个数字（不同分类得到的分值）。参数<strong>W</strong>被称为<strong>权重（weights）</strong>。<strong>b</strong>被称为<strong>偏差向量（bias vector）</strong>，这是因为它影响输出数值，但是并不和原始数据x_i产生关联。在实际情况中，人们常常混用<strong>权重</strong>和<strong>参数</strong>这两个术语。</p>
<p>需要注意的几点：</p>
<ul>
<li>首先，一个单独的矩阵乘法Wx_i就高效地并行评估10个不同的分类器（每个分类器针对一个分类），其中每个类的分类器就是W的一个行向量。</li>
<li>注意我们认为输入数据(x_i,y_i)是给定且不可改变的，但参数W和b是可控制改变的。我们的目标就是通过设置这些参数，使得计算出来的分类分值情况和训练集中图像数据的真实类别标签相符。在接下来的课程中，我们将详细介绍如何做到这一点，但是目前只需要直观地让正确分类的分值比错误分类的分值高即可。</li>
<li>该方法的一个优势是训练数据是用来学习到参数W和b的，一旦训练完成，训练数据就可以丢弃，留下学习到的参数即可。这是因为一个测试图像可以简单地输入函数，并基于计算出的分类分值来进行分类。</li>
<li>最后，注意只需要做一个矩阵乘法和一个矩阵加法就能对一个测试数据分类，这比k-NN中将测试图像和所有训练数据做比较的方法快多了。</li>
</ul>
<p><em>预告：卷积神经网络映射图像像素值到分类分值的方法和上面一样，但是映射(f)就要复杂多了，其包含的参数也更多。</em></p>
<h2 id="理解线性分类器"><a href="#理解线性分类器" class="headerlink" title="理解线性分类器"></a>理解线性分类器</h2><p>线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出喜好或者厌恶（根据每个权重的符号而定）。举个例子，可以想象“船”分类就是被大量的蓝色所包围（对应的就是水）。那么“船”分类器在蓝色通道上的权重就有很多的正权重（它们的出现提高了“船”分类的分值），而在绿色和红色通道上的权重为负的就比较多（它们的出现降低了“船”分类的分值）。</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-003.jpg" alt="l2_2"></center>

<p>一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。</p>
<hr>
<p>将图像看做高维度的点：既然图像被伸展成为了一个高维度的列向量，那么我们可以把图像看做这个高维度空间中的一个点（即每张图像是3072维空间中的一个点）。整个数据集就是一个点的集合，每个点都带有1个分类标签。</p>
<p>既然定义每个分类类别的分值是权重和图像的矩阵乘，那么每个分类类别的分数就是这个空间中的一个线性函数的函数值。我们没办法可视化3072维空间中的线性函数，但假设把这些维度挤压到二维，那么就可以看看这些分类器在做什么了：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-004.jpg" alt="l2_2"></center>

<p>图像空间的示意图。其中每个图像是一个点，有3个分类器。以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低。</p>
<hr>
<p>从上面可以看到，W的每一行都是一个分类类别的分类器。对于这些数字的几何解释是：如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转。而偏差b，则允许分类器对应的直线平移。需要注意的是，如果没有偏差，无论权重如何，在x_i=0时分类分值始终为0。这样所有分类器的线都不得不穿过原点。</p>
<p><strong>将线性分类器看做模板匹配</strong>：关于权重W的另一个解释是它的每一行对应着一个分类的模板（有时候也叫作原型）。一张图像对应不同分类的得分，是通过使用内积（也叫点积）来比较图像和模板，然后找到和哪个模板最相似。从这个角度来看，线性分类器就是在利用学习到的模板，针对图像做模板匹配。从另一个角度来看，可以认为还是在高效地使用k-NN，不同的是我们没有使用所有的训练集的图像来比较，而是每个类别只用了一张图片（这张图片是我们学习到的，而不是训练集中的某一张），而且我们会使用（负）内积来计算向量间的距离，而不是使用L1或者L2距离。</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-005.jpg" alt="l2_2"></center>

<p>将课程进度快进一点。这里展示的是以CIFAR-10为训练集，学习结束后的权重的例子。注意，船的模板如期望的那样有很多蓝色像素。如果图像是一艘船行驶在大海上，那么这个模板利用内积计算图像将给出很高的分数。</p>
<hr>
<p>可以看到马的模板看起来似乎是两个头的马，这是因为训练集中的马的图像中马头朝向各有左右造成的。线性分类器将这两种情况融合到一起了。类似的，汽车的模板看起来也是将几个不同的模型融合到了一个模板中，并以此来分辨不同方向不同颜色的汽车。这个模板上的车是红色的，这是因为CIFAR-10中训练集的车大多是红色的。线性分类器对于不同颜色的车的分类能力是很弱的，但是后面可以看到神经网络是可以完成这一任务的。神经网络可以在它的隐藏层中实现中间神经元来探测不同种类的车（比如绿色车头向左，蓝色车头向前等）。而下一层的神经元通过计算不同的汽车探测器的权重和，将这些合并为一个更精确的汽车分类分值。</p>
<p><strong>偏差和权重的合并技巧</strong>：在进一步学习前，要提一下这个经常使用的技巧。它能够将我们常用的参数W和b合二为一。回忆一下，分类评分函数定义为：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-009.png" alt="l2_2"></center>

<p>分开处理这两个参数（权重参数W和偏差参数b）有点笨拙，一般常用的方法是把两个参数放到同一个矩阵中，同时x_i向量就要增加一个维度，这个维度的数值是常量1，这就是默认的偏差维度。这样新的公式就简化成下面这样：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-010.png" alt="l2_2"></center>

<p>还是以CIFAR-10为例，那么xi的大小就变成[3073x1]，而不是[3072x1]了，多出了包含常量1的1个维度）。W大小就是[10x3073]了。W中多出来的这一列对应的就是偏差值b，具体见下图：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-006.jpg" alt="l2_2"></center><br>偏差技巧的示意图。左边是先做矩阵乘法然后做加法，右边是将所有输入向量的维度增加1个含常量1的维度，并且在权重矩阵中增加一个偏差列，最后做一个矩阵乘法即可。左右是等价的。通过右边这样做，我们就只需要学习一个权重矩阵，而不用去学习两个分别装着权重和偏差的矩阵了。<br><br>———-<br><br><strong>图像数据预处理</strong>：在上面的例子中，所有图像都是使用的原始像素值（从0到255）。在机器学习中，对于输入的特征做归一化（normalization）处理是常见的套路。而在图像分类的例子中，图像上的每个像素可以看做一个特征。在实践中，对每个特征减去平均值来<strong>中心化</strong>数据是非常重要的。在这些图片的例子中，该步骤意味着根据训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了。下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。<strong>零均值的中心化</strong>是很重要的，等我们理解了梯度下降后再来详细解释。<br><br>## 损失函数 Loss function<br><br>在上一节定义了从图像像素值到所属类别的评分函数（score function），该函数的参数是权重矩阵W。在函数中，数据(x_i,y_i)是给定的，不能修改。但是我们可以调整权重矩阵这个参数，使得评分函数的结果与训练数据集中图像的真实类别一致，即评分函数在正确的分类的位置应当得到最高的评分（score）。<br><br>回到之前那张猫的图像分类例子，它有针对“猫”，“狗”，“船”三个类别的分数。我们看到例子中权重值非常差，因为猫分类的得分非常低（-96.8），而狗（437.9）和船（61.95）比较高。我们将使用<strong>损失函数（Loss Function）</strong>（有时也叫<strong>代价函数Cost Function</strong>或<strong>目标函数Objective）</strong>来衡量我们对结果的不满意程度。直观地讲，当评分函数输出结果与真实结果之间差异越大，损失函数输出越大，反之越小。<br><br>## 多类支持向量机损失 Multiclass Support Vector Machine Loss<br><br>损失函数的具体形式多种多样。首先，介绍常用的多类支持向量机（SVM）损失函数。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值Delta。我们可以把损失函数想象成一个人，这位SVM先生（或者女士）对于结果有自己的品位，如果某个结果能使得损失值更低，那么SVM就更加喜欢它。<br><br>让我们更精确一些。回忆一下，第i个数据中包含图像xi的像素和代表正确类别的标签yi。评分函数输入像素数据，然后通过公式f(xi,W)来计算不同分类类别的分值。这里我们将分值简写为s。比如，针对第j个类别的得分就是第j个元素：s_j=f(x_i,W)_j。针对第i个数据的多类SVM的损失函数定义如下：<br><center><img src="/2017/03/01/Linear-Classification/2017-03-01-011.png" alt="l2_2"></center>

<p><strong>举例</strong>：用一个例子演示公式是如何计算的。假设有3个分类，并且得到了分值s=[13,-7,11]。其中第一个类别是正确类别，即y_i=0。同时假设Delta是10（后面会详细介绍该超参数）。上面的公式是将所有不正确分类（jnot=y_i）加起来，所以我们得到两个部分：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-012.png" alt="l2_2"></center>

<p>可以看到第一个部分结果是0，这是因为[-7-13+10]得到的是负数，经过max(0,-)函数处理后得到0。这一对类别分数和标签的损失值是0，这是因为正确分类的得分13与错误分类的得分-7的差为20，高于边界值10。而SVM只关心差距至少要大于10，更大的差值还是算作损失值为0。第二个部分计算[11-13+10]得到8。虽然正确分类的得分比不正确分类的得分要高（13&gt;11），但是比10的边界值还是小了，分差只有2，这就是为什么损失值等于8。简而言之，SVM的损失函数想要正确分类类别y_i的分数比不正确类别分数高，而且至少要高\Delta。如果不满足这点，就开始计算损失值。</p>
<p>那么在这次的模型中，我们面对的是线性评分函数（f(x_i,W)=Wx_i），所以我们可以将损失函数的公式稍微改写一下：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-013.png" alt="l2_2"></center>

<p>其中w_j是权重W的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数f公式，这样做就不是必须的了。</p>
<p>在结束这一小节前，还必须提一下的属于是关于0的阀值：max(0,-)函数，它常被称为<strong>折叶损失（hinge loss）</strong>。有时候会听到人们使用平方折叶损失SVM（即L2-SVM），它使用的是max(0,-)^2，将更强烈（平方地而不是线性地）地惩罚过界的边界值。不使用平方是更标准的版本，但是在某些数据集中，平方折叶损失会工作得更好。可以通过交叉验证来决定到底使用哪个。</p>
<p><em>我们对于预测训练集数据分类标签的情况总有一些不满意的，而损失函数就能将这些不满意的程度量化。</em></p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-014.jpg" alt="l2_2"></center>

<p>多类SVM“想要”正确类别的分类分数比其他不正确分类类别的分数要高，而且至少高出delta的边界值。如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。</p>
<hr>
<p><strong>正则化（Regularization）</strong>：上面损失函数有一个问题。假设有一个数据集和一个权重集W能够正确地分类每个数据（即所有的边界都满足，对于所有的i都有L_i=0）。问题在于这个W并不唯一：可能有很多相似的W都能正确地分类所有的数据。一个简单的例子：如果W能够正确分类所有数据，即对于每个数据，损失值都是0。那么当\lambda&gt;1时，任何数乘\lambda W都能使得损失值为0，因为这个变化将所有分值的大小都均等地扩大了，所以它们之间的绝对差值也扩大了。举个例子，如果一个正确分类的分值和举例它最近的错误分类的分值的差距是15，对W乘以2将使得差距变成30。</p>
<p>换句话说，我们希望能向某些特定的权重W添加一些偏好，对其他权重则不添加，以此来消除模糊性。这一点是能够实现的，方法是向损失函数增加一个<strong>正则化惩罚（regularization penalty）</strong>R(W)部分。最常用的正则化惩罚是L2范式，L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-015.png" alt="l2_2"></center><br>上面的表达式中，将W中所有元素平方后求和。注意正则化函数不是数据的函数，仅基于权重。包含正则化惩罚后，就能够给出完整的多类SVM损失函数了，它由两个部分组成：<strong>数据损失（data loss）</strong>，即所有样例的的平均损失L_i，以及<strong>正则化损失（regularization loss）</strong>。完整公式如下所示：<br><center><img src="/2017/03/01/Linear-Classification/2017-03-01-016.png" alt="l2_2"></center><br>将其展开完整公式是：<br><br><center><img src="/2017/03/01/Linear-Classification/2017-03-01-017.png" alt="l2_2"></center>

<p>其中，N是训练集的数据量。现在正则化惩罚添加到了损失函数里面，并用超参数\lambda来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取。</p>
<p>除了上述理由外，引入正则化惩罚还带来很多良好的性质，这些性质大多会在后续章节介绍。比如引入了L2惩罚后，SVM们就有了<strong>最大边界（max margin）</strong>这一良好性质。（如果感兴趣，可以查看<a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="external">CS229</a>课程）。</p>
<p>其中最好的性质就是对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。举个例子，假设输入向量x=[1,1,1,1]，两个权重向量w_1=[1,0,0,0]，w_2=[0.25,0.25,0.25,0.25]。那么w^T_1x=w^T_2=1，两个权重向量都得到同样的内积，但是w_1的L2惩罚是1.0，而w_2的L2惩罚是0.25。因此，根据L2惩罚来看，w_2更好，因为它的正则化损失更小。从直观上来看，这是因为w_2的权重值更小且更分散。既然L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。在后面的课程中可以看到，这一效果将会提升分类器的泛化能力，并避免过拟合。</p>
<p>需要注意的是，和权重不同，偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常只对权重W正则化，而不正则化偏差b。在实际操作中，可发现这一操作的影响可忽略不计。最后，因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当W=0的特殊情况下，才能得到损失值为0。</p>
<p><strong>代码</strong>：下面是一个无正则化部分的损失函数的Python实现，有非向量化和半向量化两个形式：</p>
<pre><code>def L_i(x, y, W):
  &quot;&quot;&quot;
  unvectorized version. Compute the multiclass svm loss for a single example (x,y)
  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)
    with an appended bias dimension in the 3073-rd position (i.e. bias trick)
  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)
  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)
  &quot;&quot;&quot;
  delta = 1.0 # see notes about delta later in this section
  scores = W.dot(x) # scores becomes of size 10 x 1, the scores for each class
  correct_class_score = scores[y]
  D = W.shape[0] # number of classes, e.g. 10
  loss_i = 0.0
  for j in xrange(D): # iterate over all wrong classes
    if j == y:
      # skip for the true class to only loop over incorrect classes
      continue
    # accumulate loss for the i-th example
    loss_i += max(0, scores[j] - correct_class_score + delta)
  return loss_i

def L_i_vectorized(x, y, W):
  &quot;&quot;&quot;
  A faster half-vectorized implementation. half-vectorized
  refers to the fact that for a single example the implementation contains
  no for loops, but there is still one loop over the examples (outside this function)
  &quot;&quot;&quot;
  delta = 1.0
  scores = W.dot(x)
  # compute the margins for all classes in one vector operation
  margins = np.maximum(0, scores - scores[y] + delta)
  # on y-th position scores[y] - scores[y] canceled and gave delta. We want
  # to ignore the y-th position and only consider margin on max wrong class
  margins[y] = 0
  loss_i = np.sum(margins)
  return loss_i

def L(X, y, W):
  &quot;&quot;&quot;
  fully-vectorized implementation :
  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)
  - y is array of integers specifying correct class (e.g. 50,000-D array)
  - W are weights (e.g. 10 x 3073)
  &quot;&quot;&quot;
  # evaluate loss over all examples in X without using any for loops
  # left as exercise to reader in the assignment
</code></pre><p>在本小节的学习中，一定要记得SVM损失采取了一种特殊的方法，使得能够衡量对于训练数据预测分类和实际分类标签的一致性。还有，对训练集中数据做出准确分类预测和让损失值最小化这两件事是等价的。</p>
<p><em>接下来要做的，就是找到能够使损失值最小化的权重了。</em></p>
<h2 id="实际考虑"><a href="#实际考虑" class="headerlink" title="实际考虑"></a>实际考虑</h2><p><strong>设置Delta</strong>：你可能注意到上面的内容对超参数Delta及其设置是一笔带过，那么它应该被设置成什么值？需要通过交叉验证来求得吗？现在看来，该超参数在绝大多数情况下设为Delta=1.0都是安全的。超参数Delta和lambda看起来是两个不同的超参数，但实际上他们一起控制同一个权衡：即损失函数中的数据损失和正则化损失之间的权衡。理解这一点的关键是要知道，权重W的大小对于分类分值有直接影响（当然对他们的差异也有直接影响）：当我们将W中值缩小，分类分值之间的差异也变小，反之亦然。因此，不同分类分值之间的边界的具体值（比如Delta=1或Delta=100）从某些角度来看是没意义的，因为权重自己就可以控制差异变大和缩小。也就是说，真正的权衡是我们允许权重能够变大到何种程度（通过正则化强度lambda来控制）。</p>
<p><strong>与二元支持向量机（Binary Support Vector Machine）的关系</strong>：在学习本课程前，你可能对于二元支持向量机有些经验，它对于第i个数据的损失计算公式是：</p>
<center><img src="/2017/03/01/Linear-Classification/2017-03-01-018.png" alt="l2_2"></center>

<p>其中，C是一个超参数，并且<img src="/2017/03/01/Linear-Classification/2017-03-01-020.png" alt="l2_2">。可以认为本章节介绍的SVM公式包含了上述公式，上述公式是多类支持向量机公式只有两个分类类别的特例。也就是说，如果我们要分类的类别只有两个，那么公式就化为二元SVM公式。这个公式中的C和多类SVM公式中的\lambda都控制着同样的权衡，而且它们之间的关系是:<center><img src="/2017/03/01/Linear-Classification/2017-03-01-019.png" alt="l2_2"></center></p>
<p><strong>备注：在初始形式中进行最优化。</strong>如果在本课程之前学习过SVM，那么对kernels，duals，SMO算法等将有所耳闻。在本课程（主要是神经网络相关）中，损失函数的最优化的始终在非限制初始形式下进行。很多这些损失函数从技术上来说是不可微的（比如当x=y时，max(x,y)函数就不可微分），但是在实际操作中并不存在问题，因为通常可以使用次梯度。</p>
<p><strong>备注：其他多类SVM公式。</strong>需要指出的是，本课中展示的多类SVM只是多种SVM公式中的一种。另一种常用的公式是One-Vs-All（OVA）SVM，它针对每个类和其他类训练一个独立的二元分类器。还有另一种更少用的叫做All-Vs-All（AVA）策略。我们的公式是按照Weston and Watkins 1999 (pdf)版本，比OVA性能更强（在构建有一个多类数据集的情况下，这个版本可以在损失值上取到0，而OVA就不行。感兴趣的话在论文中查阅细节）。最后一个需要知道的公式是Structured SVM，它将正确分类的分类分值和非正确分类中的最高分值的边界最大化。理解这些公式的差异超出了本课程的范围。本课程笔记介绍的版本可以在实践中安全使用，而被论证为最简单的OVA策略在实践中看起来也能工作的同样出色（在 Rikin等人2004年的论文In Defense of One-Vs-All Classification (pdf)中可查）。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/01/L3-Loss-Functions-and-Optimization/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/01/L3-Loss-Functions-and-Optimization/" itemprop="url">
                  L3-Loss-Functions-and-Optimization
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-01T20:58:33+08:00">
                2017-03-01
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/01/L3-Loss-Functions-and-Optimization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/01/L3-Loss-Functions-and-Optimization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="L3-Loss-Functions-and-Optimization"><a href="#L3-Loss-Functions-and-Optimization" class="headerlink" title="L3: Loss Functions and Optimization"></a>L3: Loss Functions and Optimization</h1><h2 id="1-SVM-loss"><a href="#1-SVM-loss" class="headerlink" title="1. SVM loss"></a>1. SVM loss</h2><p>svm loss function:</p>
<p><img src="/2017/03/01/L3-Loss-Functions-and-Optimization/l3_svm_loss.png" alt="svm_loss"></p>
<p>with regularization:</p>
<p><img src="/2017/03/01/L3-Loss-Functions-and-Optimization/l3_svm_loss_with_regularization.png" alt="l3_svm_loss_with_regularization"></p>
<p>加入regularization后，可以防止模型过于复杂，从而防止过拟合。因为过于复杂的参数在loss function中会受到惩罚。</p>
<h2 id="2-Softmax-loss"><a href="#2-Softmax-loss" class="headerlink" title="2. Softmax loss"></a>2. Softmax loss</h2><p>softmax function:</p>
<p><img src="/2017/03/01/L3-Loss-Functions-and-Optimization/l3_softmax_function.png" alt="l3_softmax_function"></p>
<p>softmax loss function (cross-entropy loss):</p>
<p><img src="/2017/03/01/L3-Loss-Functions-and-Optimization/l3_softmax_loss_function.png" alt="l3_softmax_loss_function"></p>
<h2 id="3-Optimization-Mini-batch-Gradient-Descent"><a href="#3-Optimization-Mini-batch-Gradient-Descent" class="headerlink" title="3. Optimization: Mini-batch Gradient Descent"></a>3. Optimization: Mini-batch Gradient Descent</h2><p>vanilla minibatch gradient descent:</p>
<pre><code>while True:
    data_batch = sample_training_data(data, batch_size)
    weights_grad = evaluate_gradient(loss_function, data_batch, weights)
    weights += - step_size * weights_grad  # update formula
</code></pre><p>we will look at more fancy update formulas (momentum, Adagrad, RMSProp, Adam, …)</p>
<h2 id="4-Image-Features"><a href="#4-Image-Features" class="headerlink" title="4. Image Features"></a>4. Image Features</h2><p>Color Histogram</p>
<p>HOG/SIFT features</p>
<p>Bag of Words</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/02/28/A-beautiful-picture/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/28/A-beautiful-picture/" itemprop="url">
                  A-beautiful-picture
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-02-28T23:32:30+08:00">
                2017-02-28
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/02/28/A-beautiful-picture/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/02/28/A-beautiful-picture/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Just-like-a-Picture"><a href="#Just-like-a-Picture" class="headerlink" title="Just like a Picture"></a>Just like a Picture</h1><hr>
<p><center><br><img src="/2017/02/28/A-beautiful-picture/2017-02-28-001.JPG" width="25%" height="25%"></center></p>
<p>如诗如画</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/" itemprop="url">
                  L2_Image_Classification_k-Nearest_Neighbor
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-02-27T21:42:24+08:00">
                2017-02-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="L2-Image-Classification-k-Nearest-Neighbor"><a href="#L2-Image-Classification-k-Nearest-Neighbor" class="headerlink" title="L2: Image Classification: k-Nearest Neighbor"></a>L2: Image Classification: k-Nearest Neighbor</h1><h2 id="0-Image-Classification-图像分类"><a href="#0-Image-Classification-图像分类" class="headerlink" title="0. Image Classification 图像分类"></a>0. Image Classification 图像分类</h2><p>目标：这一节我们将介绍图像分类问题。所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。</p>
<p>例子：以下图为例，图像分类模型读取该图片，并生成该图片属于集合 {cat, dog, hat, mug}中各个标签的概率。需要注意的是，对于计算机来说，图像是一个由数字组成的巨大的3维数组。在这个例子中，猫的图像大小是宽248像素，高400像素，有3个颜色通道，分别是红、绿和蓝（简称RGB）。如此，该图像就包含了248X400X3=297600个数字，每个数字都是在范围0-255之间的整型，其中0表示全黑，255表示全白。我们的任务就是把这些上百万的数字变成一个简单的标签，比如“猫”。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_1.png" alt="l2_1"></center>

<p>图像分类的任务，就是对于一个给定的图像，预测它属于的那个分类标签（或者给出属于一系列不同标签的可能性）。图像是3维数组，数组元素是取值范围从0到255的整数。数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。</p>
<hr>
<p><strong>困难和挑战：</strong>对于人来说，识别出一个像“猫”一样视觉概念是简单至极的，然而从计算机视觉算法的角度来看就值得深思了。我们在下面列举了计算机视觉算法在图像识别方面遇到的一些困难，要记住图像是以3维数组来表示的，数组中的元素是亮度值。</p>
<ul>
<li><strong>视角变化（Viewpoint variation）：</strong>同一个物体，摄像机可以从多个角度来展现。</li>
<li><strong>大小变化（Scale variation）：</strong>物体可视的大小通常是会变化的（不仅是在图片中，在真实世界中大小也是变化的）。</li>
<li><strong>形变（Deformation）：</strong>很多东西的形状并非一成不变，会有很大变化。</li>
<li><strong>遮挡（Occlusion）：</strong>目标物体可能被挡住。有时候只有物体的一小部分（可以小到几个像素）是可见的。</li>
<li><strong>光照条件（Illumination conditions）：</strong>在像素层面上，光照的影响非常大。</li>
<li><strong>背景干扰（Background clutter）：</strong>物体可能混入背景之中，使之难以被辨认。</li>
<li><strong>类内差异（Intra-class variation）：</strong>一类物体的个体之间的外形差异很大，比如椅子。这一类物体有许多不同的对象，每个都有自己的外形。</li>
</ul>
<p>面对以上所有变化及其组合，好的图像分类模型能够在维持分类结论稳定的同时，保持对类间差异足够敏感。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-2.jpg" alt="l2_2"></center>

<p><strong>数据驱动方法：</strong>如何写一个图像分类的算法呢？这和写个排序算法可是大不一样。怎么写一个从图像中认出猫的算法？搞不清楚。因此，与其在代码中直接写明各类物体到底看起来是什么样的，倒不如说我们采取的方法和教小孩儿看图识物类似：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是数据驱动方法。既然该方法的第一步就是收集已经做好分类标注的图片来作为训练集，那么下面就看看数据库到底长什么样：</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-3.jpg" alt="l2_3"></center>

<p>一个有4个视觉分类的训练集。在实际中，我们可能有上千的分类，每个分类都有成千上万的图像。</p>
<hr>
<p><strong>图像分类流程：</strong>在课程视频中已经学习过，<strong>图像分类</strong>就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：</p>
<ul>
<li><strong>输入：</strong>输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为训练集。</li>
<li><strong>学习：</strong>这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做训练分类器或者学习一个模型。</li>
<li><strong>评价：</strong>让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。</li>
</ul>
<h2 id="1-First-Classifier-Nearest-Neighbor-Classifier"><a href="#1-First-Classifier-Nearest-Neighbor-Classifier" class="headerlink" title="1. First Classifier: Nearest Neighbor Classifier"></a>1. First Classifier: Nearest Neighbor Classifier</h2><p>作为课程介绍的第一个方法，我们来实现一个<strong>Nearest Neighbor分类器</strong>。虽然这个分类器和卷积神经网络没有任何关系，实际中也极少使用，但通过实现它，可以让读者对于解决图像分类问题的方法有个基本的认识。</p>
<p><strong>图像分类数据集：CIFAR-10</strong>。一个非常流行的图像分类数据集是<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="external">CIFAR-10</a>。这个数据集包含了60000张32X32的小图像。每张图像都有10种分类标签中的一种。这60000张图像被分为包含50000张图像的训练集和包含10000张图像的测试集。在下图中你可以看见10个类的10张随机图片。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-4.jpg" alt="l2_4"></center>

<p><strong>左边：</strong>从<a href="http://www.cs.toronto.edu/~kriz/cifar.html" target="_blank" rel="external">CIFAR-10</a>数据库来的样本图像。<strong>右边：</strong>第一列是测试图像，然后第一列的每个测试图像右边是使用Nearest Neighbor算法，根据像素差异，从训练集中选出的10张最类似的图片。</p>
<hr>
<p>假设现在我们有CIFAR-10的50000张图片（每种分类5000张）作为训练集，我们希望将余下的10000作为测试集并给他们打上标签。Nearest Neighbor算法将会拿着测试图片和训练集中每一张图片去比较，然后将它认为最相似的那个训练集图片的标签赋给这张测试图片。上面右边的图片就展示了这样的结果。请注意上面10个分类中，只有3个是准确的。比如第8行中，马头被分类为一个红色的跑车，原因在于红色跑车的黑色背景非常强烈，所以这匹马就被错误分类为跑车了。</p>
<p>那么具体如何比较两张图片呢？在本例中，就是比较32x32x3的像素块。最简单的方法就是逐个像素比较，最后将差异值全部加起来。换句话说，就是将两张图片先转化为两个向量I_1和I_2，然后计算他们的<strong>L1距离：</strong></p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_5.png" alt="l2_5"></center>

<p>这里的求和是针对所有的像素。下面是整个比较流程的图例：</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-6.jpg" alt="l2_6"></center>

<p>以图片中的一个颜色通道为例来进行说明。两张图片使用L1距离来进行比较。逐个像素求差值，然后将所有差值加起来得到一个数值。如果两张图片一模一样，那么L1距离为0，但是如果两张图片很是不同，那L1值将会非常大。</p>
<hr>
<p>下面，让我们看看如何用代码来实现这个分类器。首先，我们将CIFAR-10的数据加载到内存中，并分成4个数组：训练数据和标签，测试数据和标签。在下面的代码中，<strong>Xtr</strong>（大小是50000x32x32x3）存有训练集中所有的图像，<strong>Ytr</strong>是对应的长度为50000的1维数组，存有图像对应的分类标签（从0到9）：</p>
<pre><code>Xtr, Ytr, Xte, Yte = load_CIFAR10(&apos;data/cifar10/&apos;) # a magic function we provide
# flatten out all images to be one-dimensional
Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072
Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072        
</code></pre><p>现在我们得到所有的图像数据，并且把他们拉长成为行向量了。接下来展示如何训练并评价一个分类器：</p>
<pre><code>nn = NearestNeighbor() # create a Nearest Neighbor classifier class
nn.train(Xtr_rows, Ytr) # train the classifier on the training images and labels
Yte_predict = nn.predict(Xte_rows) # predict labels on the test images
# and now print the classification accuracy, which is the average number
# of examples that are correctly predicted (i.e. label matches)
print &apos;accuracy: %f&apos; % ( np.mean(Yte_predict == Yte))
</code></pre><p>作为评价标准，我们常常使用准确率，它描述了我们预测正确的得分。请注意以后我们实现的所有分类器都需要有这个API：train(X, y)函数。该函数使用训练集的数据和标签来进行训练。从其内部来看，类应该实现一些关于标签和标签如何被预测的模型。这里还有个predict(X)函数，它的作用是预测输入的新数据的分类标签。现在还没介绍分类器的实现，下面就是使用L1距离的Nearest Neighbor分类器的实现套路：</p>
<pre><code>import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    &quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot;
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    &quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot;
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in xrange(num_test):
      # find the nearest training image to the i&apos;th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
</code></pre><p>如果你用这段代码跑CIFAR-10，你会发现准确率能达到38.6%。这比随机猜测的10%要好，但是比人类识别的水平（据研究推测是94%）和卷积神经网络能达到的95%还是差多了。点击查看基于CIFAR-10数据的Kaggle算法竞赛排行榜。</p>
<p>距离选择：计算向量间的距离有很多种方法，另一个常用的方法是L2距离，从几何学的角度，可以理解为它在计算两个向量间的欧式距离。L2距离的公式如下：</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_7.png" alt="l2_7"></center>

<p>换句话说，我们依旧是在计算像素间的差值，只是先求其平方，然后把这些平方全部加起来，最后对这个和开方。在Numpy中，我们只需要替换上面代码中的1行代码就行：</p>
<pre><code>distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))
</code></pre><p>注意在这里使用了np.sqrt，但是在实际中可能不用。因为求平方根函数是一个单调函数，它对不同距离的绝对值求平方根虽然改变了数值大小，但依然保持了不同距离大小的顺序。所以用不用它，都能够对像素差异的大小进行正确比较。如果你在CIFAR-10上面跑这个模型，正确率是35.4%，比刚才低了一点。</p>
<p>L1和L2比较。比较这两个度量方式是挺有意思的。在面对两个向量之间的差异时，L2比L1更加不能容忍这些差异。也就是说，相对于1个巨大的差异，L2距离更倾向于接受多个中等程度的差异。L1和L2都是在p-norm常用的特殊形式。</p>
<p><strong>k-Nearest Neighbor分类器</strong></p>
<p>你可能注意到了，为什么只用最相似的1张图片的标签来作为测试图像的标签呢？这不是很奇怪吗！是的，使用k-Nearest Neighbor分类器就能做得更好。它的思想很简单：与其只找最相近的那1个图片的标签，我们找最相似的k个图片的标签，然后让他们针对测试图片进行投票，最后把票数最高的标签作为对测试图片的预测。所以当k=1的时候，k-Nearest Neighbor分类器就是Nearest Neighbor分类器。从直观感受上就可以看到，更高的k值可以让分类的效果更平滑，使得分类器对于异常值更有抵抗力。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-8.jpg" alt="l2_8"></center>

<p>上面示例展示了Nearest Neighbor分类器和5-Nearest Neighbor分类器的区别。例子使用了2维的点来表示，分成3类（红、蓝和绿）。不同颜色区域代表的是使用L2距离的分类器的决策边界。白色的区域是分类模糊的例子（即图像与两个以上的分类标签绑定）。需要注意的是，在NN分类器中，异常的数据点（比如：在蓝色区域中的绿点）制造出一个不正确预测的孤岛。5-NN分类器将这些不规则都平滑了，使得它针对测试数据的泛化（generalization）能力更好（例子中未展示）。注意，5-NN中也存在一些灰色区域，这些区域是因为近邻标签的最高票数相同导致的（比如：2个邻居是红色，2个邻居是蓝色，还有1个是绿色）。</p>
<hr>
<p>在实际中，大多使用k-NN分类器。但是k值如何确定呢？接下来就讨论这个问题。</p>
<p>用于超参数调优的验证集</p>
<p>k-NN分类器需要设定k值，那么选择哪个k值最合适的呢？我们可以选择不同的距离函数，比如L1范数和L2范数等，那么选哪个好？还有不少选择我们甚至连考虑都没有考虑到（比如：点积）。所有这些选择，被称为超参数（hyperparameter）。在基于数据进行学习的机器学习算法设计中，超参数是很常见的。一般说来，这些超参数具体怎么设置或取值并不是显而易见的。</p>
<p>你可能会建议尝试不同的值，看哪个值表现最好就选哪个。好主意！我们就是这么做的，但这样做的时候要非常细心。特别注意：决不能使用测试集来进行调优。当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合。从另一个角度来说，如果使用测试集来调优，实际上就是把测试集当做训练集，由测试集训练出来的算法再跑测试集，自然性能看起来会很好。这其实是过于乐观了，实际部署起来效果就会差很多。所以，最终测试的时候再使用测试集，可以很好地近似度量你所设计的分类器的泛化性能（在接下来的课程中会有很多关于泛化性能的讨论）。</p>
<p>测试数据集只使用一次，即在训练完成后评价最终的模型时使用。<br>好在我们有不用测试集调优的方法。其思路是：从训练集中取出一部分数据用来调优，我们称之为验证集（validation set）。以CIFAR-10为例，我们可以用49000个图像作为训练集，用1000个图像作为验证集。验证集其实就是作为假的测试集来调优。下面就是代码：</p>
<pre><code># assume we have Xtr_rows, Ytr, Xte_rows, Yte as before
# recall Xtr_rows is 50,000 x 3072 matrix
Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation
Yval = Ytr[:1000]
Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train
Ytr = Ytr[1000:]

# find hyperparameters that work best on the validation set
validation_accuracies = []
for k in [1, 3, 5, 10, 20, 50, 100]:

  # use a particular value of k and evaluation on validation data
  nn = NearestNeighbor()
  nn.train(Xtr_rows, Ytr)
  # here we assume a modified NearestNeighbor class that can take a k as input
  Yval_predict = nn.predict(Xval_rows, k = k)
  acc = np.mean(Yval_predict == Yval)
  print &apos;accuracy: %f&apos; % (acc,)

  # keep track of what works on the validation set
  validation_accuracies.append((k, acc))
</code></pre><p>程序结束后，我们会作图分析出哪个k值表现最好，然后用这个k值来跑真正的测试集，并作出对算法的评价。</p>
<p><em>把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。</em></p>
<p><strong>交叉验证:</strong>有时候，训练集数量较小（因此验证集的数量更小），人们会使用一种被称为交叉验证的方法，这种方法更加复杂些。还是用刚才的例子，如果是交叉验证集，我们就不是取1000个图像，而是将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_9.png" alt="l2_9"></center>

<p>这就是5份交叉验证对k值调优的例子。针对每个k值，得到5个准确率结果，取其平均值，然后对不同k值的平均表现画线连接。本例中，当k=7的时算法表现最好（对应图中的准确率峰值）。如果我们将训练集分成更多份数，直线一般会更加平滑（噪音更少）。</p>
<hr>
<p>实际应用。在实际情况下，人们不是很喜欢用交叉验证，主要是因为它会耗费较多的计算资源。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-10.jpg" alt="l2_10"></center>

<p>常用的数据分割模式。给出训练集和测试集后，训练集一般会被均分。这里是分成5份。前面4份用来训练，黄色那份用作验证集调优。如果采取交叉验证，那就各份轮流作为验证集。最后模型训练完毕，超参数都定好了，让模型跑一次（而且只跑一次）测试集，以此测试结果评价算法。</p>
<hr>
<p><strong>Nearest Neighbor分类器的优劣</strong></p>
<p>现在对Nearest Neighbor分类器的优缺点进行思考。首先，Nearest Neighbor分类器易于理解，实现简单。其次，算法的训练不需要花时间，因为其训练过程只是将训练集数据存储起来。然而测试要花费大量时间计算，因为每个测试图像需要和所有存储的训练图像进行比较，这显然是一个缺点。在实际应用中，我们关注测试效率远远高于训练效率。其实，我们后续要学习的卷积神经网络在这个权衡上走到了另一个极端：虽然训练花费很多时间，但是一旦训练完成，对新的测试数据进行分类非常快。这样的模式就符合实际使用需求。</p>
<p>Nearest Neighbor分类器的计算复杂度研究是一个活跃的研究领域，若干<strong>Approximate Nearest Neighbor</strong>(ANN)算法和库的使用可以提升Nearest Neighbor分类器在数据上的计算速度（比如：<a href="http://www.cs.ubc.ca/research/flann/" target="_blank" rel="external">FLANN</a>）。这些算法可以在准确率和时空复杂度之间进行权衡，并通常依赖一个预处理/索引过程，这个过程中一般包含kd树的创建和k-means算法的运用。</p>
<p>Nearest Neighbor分类器在某些特定情况（比如数据维度较低）下，可能是不错的选择。但是在实际的图像分类工作中，很少使用。因为图像都是高维度数据（他们通常包含很多像素），而高维度向量之间的距离通常是反直觉的。下面的图片展示了基于像素的相似和基于感官的相似是有很大不同的：</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_11.png" alt="l2_11"></center>

<p>在高维度数据上，基于像素的的距离和感官上的非常不同。上图中，右边3张图片和左边第1张原始图片的L2距离是一样的。很显然，基于像素比较的相似和感官上以及语义上的相似是不同的。</p>
<hr>
<p>这里还有个视觉化证据，可以证明使用像素差异来比较图像是不够的。z这是一个叫做t-SNE的可视化技术，它将CIFAR-10中的图片按照二维方式排布，这样能很好展示图片之间的像素差异值。在这张图片中，排列相邻的图片L2距离就小。</p>
<center><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2-12.jpg" alt="l2_12"></center>

<p>上图使用t-SNE的可视化技术将CIFAR-10的图片进行了二维排列。排列相近的图片L2距离小。可以看出，图片的排列是被背景主导而不是图片语义内容本身主导。</p>
<hr>
<p>具体说来，这些图片的排布更像是一种颜色分布函数，或者说是基于背景的，而不是图片的语义主体。比如，狗的图片可能和青蛙的图片非常接近，这是因为两张图片都是白色背景。从理想效果上来说，我们肯定是希望同类的图片能够聚集在一起，而不被背景或其他不相关因素干扰。为了达到这个目的，我们不能止步于原始像素比较，得继续前进。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>简要说来：</p>
<ul>
<li><p>介绍了<strong>图像分类</strong>问题。在该问题中，给出一个由被标注了分类标签的图像组成的集合，要求算法能预测没有标签的图像的分类标签，并根据算法预测准确率进行评价。</p>
</li>
<li><p>介绍了一个简单的图像分类器：<strong>最近邻分类器(Nearest Neighbor classifier)</strong>。分类器中存在不同的超参数(比如k值或距离类型的选取)，要想选取好的超参数不是一件轻而易举的事。</p>
</li>
<li><p>选取超参数的正确方法是：将原始训练集分为训练集和验证集，我们在验证集上尝试不同的超参数，最后保留表现最好那个。</p>
</li>
<li><p>如果训练数据量不够，使用<strong>交叉验证</strong>方法，它能帮助我们在选取最优超参数的时候减少噪音。</p>
</li>
<li><p>一旦找到最优的超参数，就让算法以该参数在测试集跑且只跑一次，并根据测试结果评价算法。</p>
</li>
<li><p>最近邻分类器能够在CIFAR-10上得到将近40%的准确率。该算法简单易实现，但需要存储所有训练数据，并且在测试的时候过于耗费计算能力。</p>
</li>
<li><p>最后，我们知道了仅仅使用L1和L2范数来进行像素比较是不够的，图像更多的是按照背景和颜色被分类，而不是语义主体分身。</p>
</li>
</ul>
<p>在接下来的课程中，我们将专注于解决这些问题和挑战，并最终能够得到超过90%准确率的解决方案。该方案能够在完成学习就丢掉训练集，并在一毫秒之内就完成一张图片的分类。</p>
<p><strong>小结：实际应用k-NN</strong></p>
<p>如果你希望将k-NN分类器用到实处（最好别用到图像上，若是仅仅作为练手还可以接受），那么可以按照以下流程：</p>
<ol>
<li>预处理你的数据：对你数据中的特征进行归一化（normalize），让其具有零平均值（zero mean）和单位方差（unit variance）。在后面的小节我们会讨论这些细节。本小节不讨论，是因为图像中的像素都是同质的，不会表现出较大的差异分布，也就不需要标准化处理了。</li>
<li>如果数据是高维数据，考虑使用降维方法，比如PCA(<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="external">wiki ref</a>)。</li>
<li>将数据随机分入训练集和验证集。按照一般规律，70%-90% 数据作为训练集。这个比例根据算法中有多少超参数，以及这些超参数对于算法的预期影响来决定。如果需要预测的超参数很多，那么就应该使用更大的验证集来有效地估计它们。如果担心验证集数量不够，那么就尝试交叉验证方法。如果计算资源足够，使用交叉验证总是更加安全的（份数越多，效果越好，也更耗费计算资源）。</li>
<li>在验证集上调优，尝试足够多的k值，尝试L1和L2两种范数计算方式。</li>
<li>如果分类器跑得太慢，尝试使用Approximate Nearest Neighbor库（比如FLANN）来加速这个过程，其代价是降低一些准确率。</li>
<li>对最优的超参数做记录。记录最优参数后，是否应该让使用最优参数的算法在完整的训练集上运行并再次训练呢？因为如果把验证集重新放回到训练集中（自然训练集的数据量就又变大了），有可能最优参数又会有所变化。在实践中，<strong>不要这样做</strong>。千万不要在最终的分类器中使用验证集数据，这样做会破坏对于最优参数的估计。<strong>直接使用测试集来测试用最优参数设置好的最优模型</strong>，得到测试集数据的分类准确率，并以此作为你的kNN分类器在该数据上的性能表现。</li>
</ol>
<h2 id="Image-Classfication-Pipeline"><a href="#Image-Classfication-Pipeline" class="headerlink" title="Image Classfication Pipeline"></a>Image Classfication Pipeline</h2><p>traditional pipeline</p>
<p><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_traditional_pipeline.png" alt="l2_traditional_pipeline"></p>
<p>deep learning pipeline</p>
<p><img src="/2017/02/27/L2-Image-Classification-k-Nearest-Neighbor/l2_deep_learning_pipline.png" alt="l2_deep_learning_pipline"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Verdin" />
          <p class="site-author-name" itemprop="name">Verdin</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Verdin</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<span id="busuanzi_container_site_pv">
  . . . . . . . . . 访问量<span id="busuanzi_value_site_pv"></span>次
</span>

<span id="busuanzi_container_site_uv">
  _______~欢迎第<span id="busuanzi_value_site_uv"></span>位访客~
</span>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"verdin"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  













  
  

  

  

  

  


  

</body>
</html>
