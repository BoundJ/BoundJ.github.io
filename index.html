<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="Verdin小站">
<meta property="og:url" content="http://verdin.cn/index.html">
<meta property="og:site_name" content="Verdin小站">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Verdin小站">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://verdin.cn/"/>





  <title> Verdin小站 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?de255985a34f4b5d76b6cd2f11b8b565";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Verdin小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/07/Batch-Normalization/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/07/Batch-Normalization/" itemprop="url">
                  Batch Normalization
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-07T22:56:19+08:00">
                2017-03-07
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/07/Batch-Normalization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/Batch-Normalization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/06/I-like-ROILayer/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/06/I-like-ROILayer/" itemprop="url">
                  I like ROILayer
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-06T23:50:33+08:00">
                2017-03-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/06/I-like-ROILayer/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/06/I-like-ROILayer/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="ROI-Pooling的意义"><a href="#ROI-Pooling的意义" class="headerlink" title="ROI Pooling的意义"></a>ROI Pooling的意义</h3><p><strong>ROIs Pooling</strong>顾名思义，是<strong>pooling层</strong>的一种，而且是针对<strong>ROIs</strong>的pooling；</p>
<p><strong>什么是ROI呢？</strong></p>
<p>ROI是Region of interest的简写，指的是faster rcnn结构中，经过rpn层后，产生的proposal对应的box框。</p>
<p>所以ROI就是指矩形框，往往经过rpn后输出的不止一个矩形框，所以这里我们是对<strong>多个ROI进行Pooling</strong>。</p>
<h3 id="ROI-Pooling的输入"><a href="#ROI-Pooling的输入" class="headerlink" title="ROI Pooling的输入"></a>ROI Pooling的输入</h3><p>输入有两部分组成：</p>
<ol>
<li><p><strong>data：</strong>指的是进入RPN层之前的那个<strong>Conv层的Feature Map</strong>，通常我们称之为<strong>“share_conv”</strong>； </p>
</li>
<li><p><strong>rois：</strong>指的是<strong>RPN层的输出</strong>，一堆矩形框，形状为1x5x1x1（<strong>4个坐标+索引index</strong>），其中值得注意的是：<strong>坐标的参考系</strong>不是针对feature map这张图的，而是针对原图的（神经网络最开始的输入）。</p>
</li>
</ol>
<h3 id="ROI-Pooling的输出"><a href="#ROI-Pooling的输出" class="headerlink" title="ROI Pooling的输出"></a>ROI Pooling的输出</h3><p>输出是batch个vector，其中batch的值等于roi的个数，vector的大小为channelxwxh；<strong>ROI Pooling的过程</strong>就是将一个个大小不同的box矩形框，都映射成<strong>大小为wxh的矩形框</strong>；</p>
<center><img src="/2017/03/06/I-like-ROILayer/2017-0307-001.jpg" alt="l2_1"></center>

<ul>
<li><p>如图所示，我们先把roi中的坐标映射到feature map上，映射规则比较简单，就是把各个坐标除以输入图片与feature map的大小的比值。</p>
</li>
<li><p>得到了feature map上的box坐标后，我们使用pooling得到输出；由于输入的图片大小不一，所以这里我们使用的spp pooling，spp pooling在pooling的过程中需要计算pooling后的结果对应的两个像素点反映社到feature map上所占的范围，然后在那个范围中进行取max或者取average。</p>
</li>
</ul>
<h3 id="Caffe-ROI-Pooling的源码解析"><a href="#Caffe-ROI-Pooling的源码解析" class="headerlink" title="Caffe ROI Pooling的源码解析"></a>Caffe ROI Pooling的源码解析</h3><p><strong>输入，b0 为卷积的feature map，b1 为rois。</strong></p>
<h4 id="1-LayerSetUp"><a href="#1-LayerSetUp" class="headerlink" title="1. LayerSetUp"></a>1. LayerSetUp</h4><p>将参数赋值。</p>
<pre><code>template &lt;typename Dtype&gt;
void ROIPoolingLayer&lt;Dtype&gt;::LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  ROIPoolingParameter roi_pool_param = this-&gt;layer_param_.roi_pooling_param();
  //经过Pooling后的feature map的高
  pooled_height_ = roi_pool_param.pooled_h();
  //经过Pooling后的feature map的宽
  pooled_width_ = roi_pool_param.pooled_w();
  //输入图片与feature map之前的比值，这个feature map指roi pooling层的输入
  spatial_scale_ = roi_pool_param.spatial_scale();
}
</code></pre><h4 id="2-Reshape"><a href="#2-Reshape" class="headerlink" title="2. Reshape"></a>2. Reshape</h4><p>将top reshape成num_b1(num of rois) c_b0 pooled_height pooled_width，将max<em>idx</em> reshape与top一样。</p>
<pre><code>template &lt;typename Dtype&gt;
void ROIPoolingLayer&lt;Dtype&gt;::Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  //输入的feature map的channel数
  channels_ = bottom[0]-&gt;channels();
  //输入的feature map的高
  height_ = bottom[0]-&gt;height();
  //输入的feature map的宽
  width_ = bottom[0]-&gt;width();
  //设置输出的形状NCHW，N=ROI的个数，C=channels_，H=pooled_height_，W=pooled_width_
  top[0]-&gt;Reshape(bottom[1]-&gt;num(), channels_, pooled_height_,
      pooled_width_);
  //max_idx_的形状与top一致
  max_idx_.Reshape(bottom[1]-&gt;num(), channels_, pooled_height_,
      pooled_width_);
}
</code></pre><h4 id="3-Forward"><a href="#3-Forward" class="headerlink" title="3. Forward"></a>3. Forward</h4><p>首先计算rois映射到feature map的坐标，即原始坐标乘spacial-scale(大小为所有stride的乘积分之一)，然后针对每个输出来进行计算，即每个输出点都代表原先的一块区域，这个区域大小为bin_h= roi<em>height / pooled</em> height, bin_w=roi_width / pooled_width.遍历所有top的点所映射回feature map的区域，并找到最大值，记录最大值所在的位置。</p>
<pre><code>template &lt;typename Dtype&gt;
void ROIPoolingLayer&lt;Dtype&gt;::Forward_cpu(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
      const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  //输入有两部分组成，data和rois
  const Dtype* bottom_data = bottom[0]-&gt;cpu_data();
  const Dtype* bottom_rois = bottom[1]-&gt;cpu_data();
  // Number of ROIs
  int num_rois = bottom[1]-&gt;num();
  int batch_size = bottom[0]-&gt;num();
  int top_count = top[0]-&gt;count();
  Dtype* top_data = top[0]-&gt;mutable_cpu_data();
  caffe_set(top_count, Dtype(-FLT_MAX), top_data);
  int* argmax_data = max_idx_.mutable_cpu_data();
  caffe_set(top_count, -1, argmax_data);

  // For each ROI R = [batch_index x1 y1 x2 y2]: max pool over R
  for (int n = 0; n &lt; num_rois; ++n) {
    int roi_batch_ind = bottom_rois[0];
    //把原图的坐标映射到feature map上面
    int roi_start_w = round(bottom_rois[1] * spatial_scale_);
    int roi_start_h = round(bottom_rois[2] * spatial_scale_);
    int roi_end_w = round(bottom_rois[3] * spatial_scale_);
    int roi_end_h = round(bottom_rois[4] * spatial_scale_);
    //计算每个roi在feature map上面的大小
    int roi_height = max(roi_end_h - roi_start_h + 1, 1);
    int roi_width = max(roi_end_w - roi_start_w + 1, 1);
    //pooling之后的feature map的一个值对应于pooling之前的feature map上的大小
    //注：由于roi的大小不一致，所以每次都需要计算一次
    const Dtype bin_size_h = static_cast&lt;Dtype&gt;(roi_height)
                             / static_cast&lt;Dtype&gt;(pooled_height_);
    const Dtype bin_size_w = static_cast&lt;Dtype&gt;(roi_width)
                             / static_cast&lt;Dtype&gt;(pooled_width_);
    //找到对应的roi的feature map，如果input data的batch size为1
    //那么roi_batch_ind=0
    const Dtype* batch_data = bottom_data + bottom[0]-&gt;offset(roi_batch_ind);
    //pooling的过程是针对每一个channel的，所以需要循环遍历
    for (int c = 0; c &lt; channels_; ++c) {
      //计算output的每一个值，所以需要遍历一遍output，然后求出所有值
      for (int ph = 0; ph &lt; pooled_height_; ++ph) {
        for (int pw = 0; pw &lt; pooled_width_; ++pw) {
          // Compute pooling region for this output unit:
          //  start (included) = floor(ph * roi_height / pooled_height_)
          //  end (excluded) = ceil((ph + 1) * roi_height / pooled_height_)
          // 计算output上的一点对应于input上面区域的大小[hstart, wstart, hend, wend]
          int hstart = static_cast&lt;int&gt;(floor(static_cast&lt;Dtype&gt;(ph)
                                              * bin_size_h));
          int hend = static_cast&lt;int&gt;(ceil(static_cast&lt;Dtype&gt;(ph + 1)
                                           * bin_size_h));
          int wstart = static_cast&lt;int&gt;(floor(static_cast&lt;Dtype&gt;(pw)
                                              * bin_size_w));
          int wend = static_cast&lt;int&gt;(ceil(static_cast&lt;Dtype&gt;(pw + 1)
                                           * bin_size_w));
          //将映射后的区域平动到对应的位置[hstart, wstart, hend, wend]
          hstart = min(max(hstart + roi_start_h, 0), height_);
          hend = min(max(hend + roi_start_h, 0), height_);
          wstart = min(max(wstart + roi_start_w, 0), width_);
          wend = min(max(wend + roi_start_w, 0), width_);
          //如果映射后的矩形框不符合
          bool is_empty = (hend &lt;= hstart) || (wend &lt;= wstart);
          //pool_index指的是此时计算的output的值对应于output的位置
          const int pool_index = ph * pooled_width_ + pw;
          //如果矩形不符合，此处output的值设为0，此处的对应于输入区域的最大值为-1
          if (is_empty) {
            top_data[pool_index] = 0;
            argmax_data[pool_index] = -1;
          }
          //遍历output的值对应于input的区域块
          for (int h = hstart; h &lt; hend; ++h) {
            for (int w = wstart; w &lt; wend; ++w) {
             // 对应于input上的位置
              const int index = h * width_ + w;
              //计算区域块的最大值，保存在output对应的位置上
              //同时记录最大值的索引
              if (batch_data[index] &gt; top_data[pool_index]) {
                top_data[pool_index] = batch_data[index];
                argmax_data[pool_index] = index;
              }
            }
          }
        }
      }
      // Increment all data pointers by one channel
      batch_data += bottom[0]-&gt;offset(0, 1);
      top_data += top[0]-&gt;offset(0, 1);
      argmax_data += max_idx_.offset(0, 1);
    }
    // Increment ROI data pointer
    bottom_rois += bottom[1]-&gt;offset(1);
  }
}
</code></pre><h4 id="4-Backward"><a href="#4-Backward" class="headerlink" title="4. Backward"></a>4. Backward</h4><p>backward直接写成gpu的形式，不过开头可以看出是遍历feature map并记录n, c, h, w，为之后记录bottom_diff做准备，然后计算每个roi映射到feature map的坐标，接下来我就认为有个小问题了，作者的意思是表达如果h，w如果不在roi区域内的话，可以直接continue了，这点不难理解，某个点在roi中可能对这个roi所对应的top产生贡献（在某个bin中为最大），如果点不在那个区域中，一定不会对top产生贡献。而某一点可能对多个区域产生贡献，故loss返回来时，同一点的loss累加。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/06/Why-Gradient-Descent-is-so-Amazing/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/06/Why-Gradient-Descent-is-so-Amazing/" itemprop="url">
                  Why Gradient Descent is so Amazing
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-06T23:49:41+08:00">
                2017-03-06
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/06/Why-Gradient-Descent-is-so-Amazing/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/06/Why-Gradient-Descent-is-so-Amazing/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/05/MeanShift-Clustering/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/05/MeanShift-Clustering/" itemprop="url">
                  MeanShift Clustering
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-05T14:23:48+08:00">
                2017-03-05
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/05/MeanShift-Clustering/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/05/MeanShift-Clustering/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>Mean Shift</strong>，翻译为“<strong>均值飘移</strong>”。其在聚类，图像平滑。图像分割和跟踪方面得到了比较广泛的应用。</p>
<p><strong>Mean Shift</strong> 这个概念最早是由Fukunaga等人于1975年在一篇关于概率密度梯度函数的估计（<a href="http://ieeexplore.ieee.org/document/1055330/" target="_blank" rel="external">The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition</a>）中提出来的，其最初含义正如其名,就是<strong>偏移的均值向量</strong>，在这里Mean Shift是一个名词，它指代的是一个向量，但随着Mean Shift理论的发展，Mean Shift的含义也发生了变化，如果我们说<strong>Mean Shift算法</strong>，一般是指一个迭代的步骤，即先算出当前点的偏移均值，移动该点到其偏移均值，然后以此为新的起始点，继续移动，直到满足一定的条件结束。</p>
<p>然而在以后的很长一段时间内Mean Shift并没有引起人们的注意，直到20年以后，也就是1995年，另外一篇关于Mean Shift的重要文献（<a href="https://www.researchgate.net/publication/3192442_Mean_Shift_Mode_Seeking_and_Clustering" target="_blank" rel="external">Mean shift, mode seeking, and clustering</a>）才发表。在这篇重要的文献中，Yizong Cheng对基本的Mean Shift算法在以下两个方面做了推广，首先Yizong Cheng定义了一<strong>族核函数</strong>，使得随着样本与被偏移点的<strong>距离不同</strong>，其偏移量<strong>对均值偏移向量的贡献也不同</strong>，其次Yizong Cheng还设定了一个<strong>权重系数</strong>，使得不同的样本点重要性不一样，这大大扩大了Mean Shift的适用范围。另外Yizong Cheng指出了Mean Shift可能应用的领域，并给出了具体的例子。</p>
<p>Comaniciu等人在还（<a href="http://ieeexplore.ieee.org/document/1211475/" target="_blank" rel="external">Mean-shift Blob Tracking through Scale Space</a>）中把非刚体的跟踪问题近似为一个Mean Shift最优化问题，使得跟踪可以实时的进行。目前，利用Mean Shift进行跟踪已经相当成熟。</p>
<p>这篇文章什么都有了，<a href="http://blog.csdn.net/google19890102/article/details/51030884" target="_blank" rel="external">传送门</a>。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Why-FasterRCNN/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Why-FasterRCNN/" itemprop="url">
                  Why FasterRCNN !
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:16:33+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Why-FasterRCNN/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Why-FasterRCNN/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="1-计算机视觉任务"><a href="#1-计算机视觉任务" class="headerlink" title="1. 计算机视觉任务"></a>1. 计算机视觉任务</h1><center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-001.png" alt="l2_1"></center>

<h1 id="2-传统目标检测方法"><a href="#2-传统目标检测方法" class="headerlink" title="2. 传统目标检测方法"></a>2. 传统目标检测方法</h1><p><strong>传统目标检测流程：</strong></p>
<p>1）区域选择（穷举策略：采用滑动窗口，且设置不同的大小，不同的长宽比对图像进行遍历，时间复杂度高）</p>
<p>2）特征提取（SIFT、HOG等；形态多样性、光照变化多样性、背景多样性使得特征鲁棒性差）</p>
<p>3）分类器（主要有SVM、Adaboost等）</p>
<p><strong>传统目标检测的主要问题：</strong></p>
<p>1）基于滑动窗口的区域选择策略没有针对性，时间复杂度高，窗口冗余</p>
<p>2）手工设计的特征对于多样性的变化没有很好的鲁棒性</p>
<h1 id="3-基于侯选区域-Region-Proposal-的深度学习目标检测"><a href="#3-基于侯选区域-Region-Proposal-的深度学习目标检测" class="headerlink" title="3. 基于侯选区域(Region Proposal)的深度学习目标检测"></a>3. 基于侯选区域(Region Proposal)的深度学习目标检测</h1><h2 id="R-CNN-CVPR2014-TPAMI2015"><a href="#R-CNN-CVPR2014-TPAMI2015" class="headerlink" title="R-CNN (CVPR2014, TPAMI2015)"></a>R-CNN (CVPR2014, TPAMI2015)</h2><p>1）<strong>Region Proposal：</strong>可以解决滑动窗口的问题</p>
<p> 候选区域（Region Proposal）：是预先找出图中目标可能出现的位置。它利用了图像中的<strong>纹理、边缘、颜色</strong>等信息，可以保证在选取较少窗口(几千甚至几百）的情况下保持<strong>较高的召回率</strong>（Recall）。</p>
<p> 常用的Region Proposal有(详见”<a href="https://arxiv.org/abs/1502.05082" target="_blank" rel="external">What makes for effective detection proposals?</a>“)：</p>
<ul>
<li><p><strong>Selective Search</strong></p>
</li>
<li><p><strong>Edge Boxes</strong> </p>
</li>
</ul>
<p>2）<strong>R-CNN：</strong>可以解决特征鲁棒性的问题</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-002.png" alt="l2_1"></center>

<p> (1) 输入测试图像</p>
<p> (2) 利用selective search算法在图像中从下到上提取2000个左右的Region Proposal</p>
<p> (3) 将每个Region Proposal缩放（warp）成227x227的大小并输入到CNN，将CNN的fc7层的输出作为特征</p>
<p> (4) 将每个Region Proposal提取到的CNN特征输入到SVM进行分类</p>
<p> 注：1）对每个Region Proposal缩放到同一尺度是因为CNN全连接层输入需要保证维度固定。</p>
<p> 2）上图少画了一个过程——对于SVM分好类的Region Proposal做边框回归（bounding-box regression)，边框回归是对region proposal进行纠正的线性回归算法，为了让region proposal提取到的窗口跟目标真实窗口更吻合。因为region proposal提取到的窗口不可能跟人手工标记那么准，如果region proposal跟目标位置偏移较大，即便是分类正确了，但是由于IoU(region proposal与Ground Truth的窗口的交集比并集的比值)低于0.5，那么相当于目标还是没有检测到。</p>
<p>3）<strong>R-CNN缺点：</strong></p>
<p> (1) 训练分为多个阶段，步骤繁琐: 微调网络+训练SVM+训练边框回归器</p>
<p> (2) 训练耗时，占用磁盘空间大：5000张图像产生几百G的特征文件</p>
<p> (3) 速度慢: 使用GPU, VGG16模型处理一张图像需要47s。</p>
<p> (4) 测试速度慢：每个候选区域需要运行整个前向CNN计算</p>
<p> (5) SVM和回归是事后操作：在SVM和回归过程中CNN特征没有被学习更新</p>
<p> 针对速度慢的这个问题，SPP-NET给出了很好的解决方案。</p>
<h2 id="SPP-NET-ECCV2014-TPAMI2015"><a href="#SPP-NET-ECCV2014-TPAMI2015" class="headerlink" title="SPP-NET (ECCV2014, TPAMI2015)"></a>SPP-NET (ECCV2014, TPAMI2015)</h2><p><strong>SSP-Net：</strong>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</p>
<p> 先看一下R-CNN为什么检测速度这么慢，一张图都需要47s！仔细看下R-CNN框架发现，对图像提完Region Proposal（2000个左右）之后将每个Proposal当成一张图像进行后续处理(CNN提特征+SVM分类)，实际上对一张图像进行了2000次提特征和分类的过程！这2000个Region Proposal不都是图像的一部分吗，那么我们完全可以对图像提一次卷积层特征，然后只需要将Region Proposal在原图的位置映射到卷积层特征图上，这样对于一张图像我们只需要提一次卷积层特征，然后将每个Region Proposal的卷积层特征输入到全连接层做后续操作。（对于CNN来说，大部分运算都耗在卷积操作上，这样做可以节省大量时间）。</p>
<p> 现在的问题是每个Region Proposal的尺度不一样，直接这样输入全连接层肯定是不行的，因为全连接层输入必须是固定的长度。SPP-NET恰好可以解决这个问题。</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-003.png" alt="l2_1"></center>

<p>由于传统的CNN限制了输入必须固定大小（比如AlexNet是224x224），所以在实际使用中往往需要对原图片进行crop或者warp的操作：</p>
<ul>
<li>crop：截取原图片的一个固定大小的patch</li>
<li>warp：将原图片的ROI缩放到一个固定大小的patch</li>
</ul>
<p>无论是crop还是warp，都无法保证在不失真的情况下将图片传入到CNN当中：</p>
<ul>
<li>crop：物体可能会产生截断，尤其是长宽比大的图片。</li>
<li>warp：物体被拉伸，失去“原形”，尤其是长宽比大的图片</li>
</ul>
<p>SPP为的就是解决上述的问题，做到的效果为：不管输入的图片是什么尺度，都能够正确的传入网络。</p>
<p><strong>具体思路</strong>为：CNN的卷积层是可以处理任意尺度的输入的，只是在全连接层处有限制尺度。换句话说，如果找到一个方法，在全连接层之前将其输入限制到等长，那么就解决了这个问题。</p>
<p>具体方案如下图所示：</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-004.png" alt="l2_1"></center>

<p> 如果原图输入是224x224，对于conv5出来后的输出，是13x13x256的，可以理解成有256个这样的filter，每个filter对应一张13x13的activation map。如果像上图那样将activation map pooling成4x4 2x2 1x1三张子图，做max pooling后，出来的特征就是固定长度的(16+4+1)x256那么多的维度了。如果原图的输入不是224x224，出来的特征依然是(16+4+1)x256；直觉地说，可以理解成将原来固定大小为(3x3)窗口的pool5改成了自适应窗口大小，窗口的大小和activation map成比例，保证了经过pooling后出来的feature的长度是一致的。</p>
<hr>
<p>使用SPP-NET相比于R-CNN可以大大加快目标检测的速度，但是依然存在着很多问题：</p>
<p>(1) 训练分为多个阶段，步骤繁琐: 微调网络+训练SVM+训练训练边框回归器</p>
<p>(2) SPP-NET在微调网络的时候固定了卷积层，只对全连接层进行微调，而对于一个新的任务，有必要对卷积层也进行微调。（分类的模型提取的特征更注重高层语义，而目标检测任务除了语义信息还需要目标的位置信息）</p>
<p>针对这两个问题，RBG又提出Fast R-CNN, 一个精简而快速的目标检测框架。 </p>
<h2 id="Fast-R-CNN-ICCV2015"><a href="#Fast-R-CNN-ICCV2015" class="headerlink" title="Fast R-CNN(ICCV2015)"></a>Fast R-CNN(ICCV2015)</h2><p>有了前边R-CNN和SPP-NET的介绍，直接看Fast R-CNN的框架图：</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-005.png" alt="l2_1"></center>

<p>与R-CNN框架图对比，可以发现主要有两处不同：一是最后一个卷积层后加了一个ROI pooling layer，二是损失函数使用了多任务损失函数(multi-task loss)，将边框回归直接加入到CNN网络中训练。</p>
<ol>
<li><p>ROI pooling layer实际上是SPP-NET的一个精简版，SPP-NET对每个proposal使用了不同大小的金字塔映射，而ROI pooling layer只需要下采样到一个7x7的特征图。对于VGG16网络conv5_3有512个特征图，这样所有region proposal对应了一个7<em>7</em>512维度的特征向量作为全连接层的输入。</p>
</li>
<li><p>R-CNN训练过程分为了三个阶段，而Fast R-CNN直接使用softmax替代SVM分类，同时利用多任务损失函数边框回归也加入到了网络中，这样整个的训练过程是端到端的(除去region proposal提取阶段)。</p>
</li>
<li><p>Fast R-CNN在网络微调的过程中，将部分卷积层也进行了微调，取得了更好的检测效果。</p>
</li>
</ol>
<p><strong>性能对比数据：</strong></p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-006.png" alt="l2_1"></center>


<p><strong>1）Fast R-CNN优点：</strong></p>
<p>Fast R-CNN融合了R-CNN和SPP-NET的精髓，并且引入多任务损失函数，使整个网络的训练和测试变得十分方便。在Pascal VOC2007训练集上训练，在VOC2007测试的结果为66.9%(mAP)，如果使用VOC2007+2012训练集训练，在VOC2007上测试结果为70%（数据集的扩充能大幅提高目标检测性能）。使用VGG16每张图像总共需要3s左右。</p>
<p><strong>2）Fast R-CNN 缺点：</strong></p>
<p>Region Proposal的提取使用selective search，目标检测时间大多消耗在这上面（提Region Proposal 2~3s，而提特征分类只需0.32s），无法满足实时应用，而且并没有实现真正意义上的端到端训练测试（region proposal使用selective search先提取处来）。那么有没有可能直接使用CNN直接产生Region Proposal并对其分类？Faster R-CNN框架就是符合这样需要的目标检测框架。</p>
<h2 id="Faster-R-CNN-NIPS2015"><a href="#Faster-R-CNN-NIPS2015" class="headerlink" title="Faster R-CNN(NIPS2015)"></a>Faster R-CNN(NIPS2015)</h2><p><strong>Faster R-CNN:</strong> Towards Real-Time Object Detection with Region Proposal Networks</p>
<p>在Region Proposal + CNN分类的这种目标检测框架中，Region Proposal质量好坏直接影响到目标检测任务的精度。如果找到一种方法只提取几百个或者更少的高质量的假选窗口，而且召回率很高，这不但能加快目标检测速度，还能提高目标检测的性能（假阳例少）。RPN(Region Proposal Networks)网络应运而生。</p>
<p><strong>1）RPN的核心思想</strong></p>
<p>是使用卷积神经网络直接产生Region Proposal，使用的方法本质上就是滑动窗口。RPN的设计比较巧妙，RPN只需在最后的卷积层上滑动一遍，因为Anchor机制和边框回归可以得到多尺度多长宽比的Region Proposal。</p>
<p><strong>2）Faster R-CNN架构</strong></p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-008.png" alt="l2_1"></center>

<p><strong>3）RPN架构</strong></p>
<p>RPN采用任意大小的的图像作为输入，并输出一组候选的矩形，每个矩形都有一个对象分数。</p>
<p>RPN被用于训练直接产生候选区域，不需要外部的候选区域。</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-009.png" alt="l2_1"></center>

<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-010.png" alt="l2_1"></center>

<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-011.png" alt="l2_1"></center>

<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-012.png" alt="l2_1"></center>


<p>Anchor是滑动窗口的中心，它与尺度和长宽比相关，默认采3种尺度（128,256,512），3种长宽比（1:1,1:2,2:1)，则在每一个滑动位置k=9 anchors。</p>
<p>直接看上边的RPN网络结构图（使用了ZF<zeiler and="" fergus="" model="">模型），给定输入图像（假设分辨率为600<em>1000），经过卷积操作得到最后一层的卷积特征图（大小约为40</em>60）。在这个特征图上使用3<em>3的卷积核（滑动窗口）与特征图进行卷积，最后一层卷积层共有256个feature map，那么这个3</em>3的区域卷积后可以获得一个256维的特征向量，后边接cls layer(box-classification layer)和reg layer(box-regression layer)分别用于分类和边框回归（跟Fast R-CNN类似，只不过这里的类别只有目标和背景两个类别）。3<em>3滑窗对应的每个特征区域同时预测输入图像3种尺度（128,256,512），3种长宽比（1:1,1:2,2:1）的region proposal，这种映射的机制称为anchor。所以对于这个40</em>60的feature map，总共有约20000(40<em>60</em>9)个anchor，也就是预测20000个region proposal。</zeiler></p>
<p><strong>这样设计的好处是什么呢？</strong></p>
<p>虽然现在也是用的滑动窗口策略，但是：滑动窗口操作是在卷积层特征图上进行的，维度较原始图像降低了16<em>16倍（中间经过了4次2</em>2的pooling操作）；多尺度采用了9种anchor，对应了三种尺度和三种长宽比，加上后边接了边框回归，所以即便是这9种anchor外的窗口也能得到一个跟目标比较接近的region proposal。</p>
<p><strong>4）总结</strong><br>Faster R-CNN将一直以来分离的region proposal和CNN分类融合到了一起，使用端到端的网络进行目标检测，无论在速度上还是精度上都得到了不错的提高。然而Faster R-CNN还是达不到实时的目标检测，预先获取Region Proposal，然后在对每个Proposal分类计算量还是比较大。比较幸运的是YOLO这类目标检测方法的出现让实时性也变的成为可能。</p>
<p>总的来说，从R-CNN, SPP-NET, Fast R-CNN, Faster R-CNN一路走来，基于深度学习目标检测的流程变得越来越精简，精度越来越高，速度也越来越快。可以说基于Region Proposal的R-CNN系列目标检测方法是当前目标最主要的一个分支。       </p>
<h2 id="R-FCN（2016-5）"><a href="#R-FCN（2016-5）" class="headerlink" title="R-FCN（2016.5）"></a>R-FCN（2016.5）</h2><p>《<strong>R-FCN:</strong> Object Detection via Region-based Fully Convolutional Networks》</p>
<p>顾名思议：全卷积网络，就是全部是卷积层，而没有全连接层(fc)。</p>
<p>R-FCN(基于区域的检测器）的方法是：在整个图像上共享计算，通过移除最后的fc层实现(即删除了所有的子网络)。使用“位置敏感的得分图”来解决了图像分类平移不变性与对象检测平移变化之间的矛盾。</p>
<p>此矛盾为：物体分类要求平移不变性越大越好 (图像中物体的移动不用区分)，而物体检测要求有平移变化。所以，ImageNet 分类领先的结果证明尽可能有平移不变性的全卷积结构更受亲睐。另一方面，物体检测任务需要一些平移变化的定位表示。比如，物体的平移应该使网络产生响应，这些响应对描述候选框覆盖真实物体的好坏是有意义的。我们假设图像分类网络的卷积层越深，则该网络对平移越不敏感。</p>
<p>CNN随着网络深度的增加，网络对于位置（Position）的敏感度越来越低，也就是所谓的translation-invariance，但是在Detection的时候，需要对位置信息有很强的的敏感度。</p>
<p>那么ResNet-101的detection是怎么做的？</p>
<p>在R-FCN之前，很简单，把ROI-pooling层放到了前面的卷积层，然后后面的卷积层不共享计算，这样一可以避免过多的信息损失，二可以用后来的卷积层学习位置信息。</p>
<p>R-FCN：采用全卷积网络结构作为 FCN，为给 FCN 引入平移变化，用专门的卷积层构建位置敏感分数地图 (position-sensitive score maps)。每个空间敏感地图编码感兴趣区域的相对空间位置信息。 在FCN上面增加1个位置敏感 RoI 池化层来监管这些分数地图。</p>
<p>R-FCN思路就是利用最后一层网络通过FCN构成一个position-sensitive的feature map。具体而言，每一个proposal的位置信息都需要编码，那么先把proposal分成k<em>k个grid，然后对每一个grid进行编码。在最后一层map之后，再使用卷积计算产生一个k</em>k<em>(C+1)的map（k</em>k代表总共的grid数目，C代表class num，+1代表加入一个背景类）。</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-013.png" alt="l2_1"></center>

<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-014.png" alt="l2_1"></center>

<p> RPN 给出感兴趣区域，R-FCN 对该感兴趣区域分类。R-FCN 在与 RPN 共享的卷积层后多加1个卷积层。所以，R-FCN 与 RPN 一样，输入为整幅图像。但 R-FCN 最后1个卷积层的输出从整幅图像的卷积响应图像中分割出感兴趣区域的卷积响应图像。</p>
<p>R-FCN 最后1个卷积层在整幅图像上为每类生成k<em>k个位置敏感分数图，有C类物体外加1个背景，因此有k</em>k(C+1)个通道的输出层。k*k个分数图对应描述位置的空间网格。比如，k×k=3×3，则9个分数图编码单个物体类的 {top−left,top−center,top−right,…,bottom−right}。</p>
<p>R-FCN 最后用位置敏感 RoI 池化层，给每个 RoI 1个分数。选择性池化图解：看上图的橙色响应图像 (top−left)，抠出橙色方块 RoI，池化橙色方块 RoI 得到橙色小方块 (分数)；其它颜色的响应图像同理。对所有颜色的小方块投票 (或池化) 得到1类的响应结果。</p>
<hr>
<p>产生完了这张map之后，再根据proposal产生一个长宽各为k，channel数目为C+1的score map。具体产生score map的方法是，假如k=3，C=20，那么score map的20个类每个类都有3<em>3的feature，一共9个格子，每一个格子都记录了空间信息。而这每一个类的每一个格子都对应前面那个channel数为3</em>3*21的大map的其中一个channel的map。现在把score map中的格子对应的区域的map中的信息取平均，然后这个平均值就是score map格子中的值。最后把score map的值进行vote（avg pooling）来形成一个21维的向量来做分类即可。</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-015.png" alt="l2_1"></center>

<center><img src="/2017/03/04/Why-FasterRCNN/2017-0307-016.png" alt="l2_1"></center>


<p>当分类正确时，该类通道的位置敏感分数图 (中间) 的大多数橙色实线网格内的响应在整个 RoI 位置范围内最强。</p>
<p>对应的bbox regression只需要把C+1设成4就可以了。</p>
<p>R-FCN采用的一些方法比Faster R-CNN的baseline提高了3个点，并且比原来Faster R-CNN更快（因为全部计算都共享了）。但是和改进过的Faster R-CNN相比（ROI Pooling提前那种）提高了0.2个点，速度快了2.5倍。所以目前为止这个方法的结果应该是所有方法中速度和Performance结合的最好的。</p>
<h2 id="再谈Faster-RCNN思想"><a href="#再谈Faster-RCNN思想" class="headerlink" title="再谈Faster-RCNN思想"></a>再谈Faster-RCNN思想</h2><p>从RCNN到fast RCNN，再到faster RCNN，目标检测的四个基本步骤（<strong>候选区域生成</strong>，<strong>特征提取</strong>，<strong>分类</strong>，<strong>位置精修</strong>）终于被统一到一个深度网络框架之内。所有计算没有重复，<strong>完全在GPU中完成</strong>，大大提高了运行速度。 </p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-001.jpg" alt="l2_1"></center>

<p>faster RCNN可以简单地看做“<strong>区域生成网络+fast RCNN</strong>“的系统，用区域生成网络代替fast RCNN中的<strong>Selective Search</strong>方法。本篇论文着重解决了这个系统中的三个问题：</p>
<ol>
<li>如何设计区域生成网络 </li>
<li>如何训练区域生成网络 </li>
<li>如何让区域生成网络和fast RCNN网络共享特征提取网络</li>
</ol>
<h2 id="区域生成网络：结构"><a href="#区域生成网络：结构" class="headerlink" title="区域生成网络：结构"></a>区域生成网络：结构</h2><p>基本设想是：在提取好的特征图上，<strong>对所有可能的候选框进行判别</strong>。由于后续还有位置精修步骤，所以候选框实际比较稀疏。</p>
<center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-002.jpg" alt="l2_1"></center>

<h3 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h3><p>原始特征提取（上图灰色方框）包含若干层conv+relu，直接套用ImageNet上常见的分类网络即可。本文试验了两种网络：5层的ZF[3]，16层的VGG-16[4]，具体结构不再赘述。<br><strong>额外添加一个conv+relu层，输出51<em>39</em>256维特征（feature）。</strong></p>
<h3 id="Region-Proposal-Networks的设计和训练思路"><a href="#Region-Proposal-Networks的设计和训练思路" class="headerlink" title="Region Proposal Networks的设计和训练思路"></a>Region Proposal Networks的设计和训练思路</h3> <center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-003.png" alt="l2_1"></center>

<p>上图是<strong>RPN的网络流程图</strong>，即也是利用了SPP的映射机制，从<strong>conv5上进行滑窗</strong>来替代从原图滑窗。<br>不过，要如何训练出一个网络来替代<strong>selective search</strong>相类似的功能呢？<br>实际上思路很简单，就是先通过SPP根据一一对应的点从conv5映射回原图，根据设计不同的固定初始尺度训练一个网络，就是给它大小不同（但设计固定）的region图，然后根据与ground truth的覆盖率给它正负标签，让它学习里面是否有object即可。</p>
<p>这就又变成介绍RCNN之前提出的traditional method，训练出一个能检测物体的网络，然后对整张图片进行滑窗判断，不过这样子的话由于无法判断<strong>region尺度</strong>和<strong>scale ratio</strong>，故需要多次放缩，这样子测试，估计判断一张图片是否有物体就需要很久。(传统hog+svm-&gt;dpm)</p>
<hr>
<p>如何降低这一部分的复杂度？</p>
<p>要知道我们只需要找出大致的地方，无论是精确定位位置还是尺寸，后面的工作都可以完成，这样子的话，与其说用小网络，简单的学习（这样子估计和蒙差不多了，反正有无物体也就50%的概率），还不如用深的网络，固定尺度变化，固定scale ratio变化，固定采样方式（反正后面的工作能进行调整，更何况它本身就可以对box的位置进行调整）这样子来降低任务复杂度呢。</p>
<p>这里有个很不错的地方就是在前面可以共享卷积计算结果，这也算是用深度网络的另一个原因吧。而这三个固定，我估计也就是为什么文章叫这些proposal为anchor的原因了。这个网络的结果就是卷积层的每个点都有有关于k个achor boxes的输出，包括是不是物体，调整box相应的位置。这相当于给了比较死的初始位置（三个固定），然后来大致判断是否是物体以及所对应的位置.</p>
<p>这样子的话RPN所要做的也就完成了，这个网络也就完成了它应该完成的使命，剩下的交给其他部分完成。</p>
<h3 id="候选区域（anchor）"><a href="#候选区域（anchor）" class="headerlink" title="候选区域（anchor）"></a>候选区域（anchor）</h3><p>特征可以看做一个尺度51x39的256通道图像，对于该图像的每一个位置，考虑9个可能的候选窗口：三种面积{128,256,512}×    三种比例{1:1,1:2,2:1}。<br>这些候选窗口称为<strong>anchors</strong>。</p>
<p>下图示出51*39个anchor中心，以及9种anchor示例。 </p>
 <center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-005.png" alt="l2_1"></center>

<p><strong>关于anchor的问题：</strong></p>
<p>这里在详细解释一下:(1)首先按照尺度和长宽比生成9种anchor,这9个anchor的意思是conv5 feature map 3x3的滑窗对应原图区域的大小.这9个anchor对于任意输入的图像都是一样的，所以只需要计算一次. 既然大小对应关系有了，下一步就是中心点对应关系，接下来(2)对于每张输入图像，根据图像大小计算conv5 3x3滑窗对应原图的中心点.   有了中心点对应关系和大小对应关系，映射就显而易见了.</p>
<p>在整个faster RCNN算法中，有三种尺度。</p>
<ol>
<li><strong>原图尺度</strong>：原始输入的大小。不受任何限制，不影响性能。 </li>
<li><strong>归一化尺度</strong>：输入特征提取网络的大小，在测试时设置，源码中opts.test_scale=600。anchor在这个尺度上设定。这个参数和anchor的相对大小决定了想要检测的目标范围。 </li>
<li><strong>网络输入尺度</strong>：输入特征检测网络的大小，在训练时设置，源码中为224*224。</li>
</ol>
<h3 id="Region-Proposal-Networks"><a href="#Region-Proposal-Networks" class="headerlink" title="Region Proposal Networks"></a>Region Proposal Networks</h3><p>RPN的目的是实现”attention”机制,告诉后续的扮演检测\识别\分类角色的Fast-RCNN应该注意哪些区域,它从任意尺寸的图片中得到一系列的带有 objectness score 的 object proposals。<br>具体流程是：使用一个小的网络在已经进行通过卷积计算得到的feature map上进行滑动扫描，这个小的网络每次在一个feature map上的一个窗口进行滑动(这个窗口大小为n<em>n—-在这里,再次看到神经网络中用于缩减网络训练参数的局部感知策略receptive field,通常n=228在VGG-16,而作者论文使用n=3)，滑动操作后映射到一个低维向量(例如256D或512D,这里说256或512是低维,Q:n=3,n</em>n=9,为什么256是低维呢?那么解释一下:低维相对不是指窗口大小,窗口是用来滑动的!256相对的是a convolutional feature map of a size W × H (typically ∼2,400),而2400这个特征数很大,所以说256是低维.另外需要明白的是:这里的256维里的每一个数都是一个Anchor(由2400的特征数滑动后操作后,再进行压缩))最后将这个低维向量送入到两个独立\平行的全连接层:box回归层（a box-regression layer (reg)）和box分类层（a box-classification layer (cls)）<br>Translation-Invariant Anchors<br>   在计算机视觉中的一个挑战就是平移不变性:比如人脸识别任务中,小的人脸(24<em>24的分辨率)和大的人脸(1080</em>720)如何在同一个训练好权值的网络中都能正确识别. 传统有两种主流的解决方式：<br>第一:对图像或feature map层进行尺度\宽高的采样;<br>第二,对滤波器进行尺度\宽高的采样(或可以认为是滑动窗口).<br>但作者的解决该问题的具体实现是:通过卷积核中心(用来生成推荐窗口的Anchor)进行尺度、宽高比的采样。如上图右边，文中使用了3 scales and 3 aspect ratios （1:1,1:2,2:1）, 就产生了 k = 9 anchors at each sliding position. </p>
<h3 id="窗口分类和位置精修"><a href="#窗口分类和位置精修" class="headerlink" title="窗口分类和位置精修"></a>窗口分类和位置精修</h3><p>分类层（cls_score）输出每一个位置上，9个anchor属于前景和背景的概率；窗口回归层（bbox_pred）输出每一个位置上，9个anchor对应窗口应该平移缩放的参数。<br>对于每一个位置来说，分类层从256维特征中输出属于前景和背景的概率；窗口回归层从256维特征中输出4个平移缩放参数。</p>
<p>就局部来说，这两层是全连接网络；就全局来说，由于网络在所有位置（共51*39个）的参数相同，所以实际用尺寸为1×1的卷积网络实现。</p>
<p>需要注意的是：并没有显式地提取任何候选窗口，完全使用网络自身完成判断和修正。</p>
<h2 id="区域生成网络：训练"><a href="#区域生成网络：训练" class="headerlink" title="区域生成网络：训练"></a>区域生成网络：训练</h2><h3 id="样本"><a href="#样本" class="headerlink" title="样本"></a>样本</h3><p>考察训练集中的每张图像： </p>
<ol>
<li>对每个标定的真值候选区域，与其重叠比例最大的anchor记为前景样本 </li>
<li>对1)剩余的anchor，如果其与某个标定重叠比例大于0.7，记为前景样本；如果其与任意一个标定的重叠比例都小于0.3，记为背景样本 </li>
<li>对1),2)剩余的anchor，弃去不用。 </li>
<li>跨越图像边界的anchor弃去不用</li>
</ol>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>同时最小化两种代价：</p>
<ol>
<li>分类误差 </li>
<li>前景样本的窗口位置偏差 </li>
</ol>
<h3 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h3><p>原始特征提取网络使用ImageNet的分类样本初始化，其余新增层随机初始化。<br>每个mini-batch包含从一张图像中提取的256个anchor，前景背景样本1:1.<br>前60K迭代，学习率0.001，后20K迭代，学习率0.0001。<br>momentum设置为0.9，weight decay设置为0.0005。[5]</p>
<h3 id="共享特征"><a href="#共享特征" class="headerlink" title="共享特征"></a>共享特征</h3><p>区域生成网络（RPN）和fast RCNN都需要一个原始特征提取网络（下图灰色方框）。这个网络使用ImageNet的分类库得到初始参数W0，但要如何精调参数，使其同时满足两方的需求呢？本文讲解了三种方法。 </p>
 <center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-006.png" alt="l2_1"></center>

<h3 id="轮流训练"><a href="#轮流训练" class="headerlink" title="轮流训练"></a>轮流训练</h3><ol>
<li>从W0开始，训练RPN。用RPN提取训练集上的候选区域 </li>
<li>从W0开始，用候选区域训练Fast RCNN，参数记为W1 </li>
<li>从W1开始，训练RPN… </li>
<li>具体操作时，仅执行两次迭代，并在训练时冻结了部分层。论文中的实验使用此方法。<br>如Ross Girshick在ICCV 15年的讲座Training R-CNNs of various velocities中所述，采用此方法没有什么根本原因，主要是因为”实现问题，以及截稿日期“。</li>
</ol>
<h3 id="近似联合训练"><a href="#近似联合训练" class="headerlink" title="近似联合训练"></a>近似联合训练</h3><p>直接在上图结构上训练。在backward计算梯度时，把提取的ROI区域当做固定值看待；在backward更新参数时，来自RPN和来自Fast RCNN的增量合并输入原始特征提取层。<br>此方法和前方法效果类似，但能将训练时间减少20%-25%。公布的python代码中包含此方法。</p>
<h3 id="联合训练"><a href="#联合训练" class="headerlink" title="联合训练"></a>联合训练</h3><p>直接在上图结构上训练。但在backward计算梯度时，要考虑ROI区域的变化的影响。推导超出本文范畴，请参看15年NIP论文[6]。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>除了开篇提到的基本性能外，还有一些值得注意的结论:</p>
<p>与Selective Search方法（黑）相比，当每张图生成的候选区域从2000减少到300时，本文RPN方法（红蓝）的召回率下降不大。说明RPN方法的目的性更明确。 </p>
 <center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-007.png" alt="l2_1"></center>

<p>使用更大的Microsoft COCO库[7]训练，直接在PASCAL VOC上测试，准确率提升6%。说明faster RCNN迁移性良好，没有over fitting。</p>
 <center><img src="/2017/03/04/Why-FasterRCNN/2017-0306-008.png" alt="l2_1"></center>

<h2 id="提高目标检测方法"><a href="#提高目标检测方法" class="headerlink" title="提高目标检测方法"></a>提高目标检测方法</h2><p>R-CNN系列目标检测框架和YOLO目标检测框架给了我们进行目标检测的两个基本框架。除此之外，研究人员基于这些框架从其他方面入手提出了一系列提高目标检测性能的方法。</p>
<ol>
<li><p><strong>难分样本挖掘（hard negative mining）</strong><br>R-CNN在训练SVM分类器时使用了难分样本挖掘的思想，但Fast R-CNN和Faster R-CNN由于使用端到端的训练策略并没有使用难分样本挖掘（只是设置了正负样本的比例并随机抽取）。CVPR2016的Training Region-based Object Detectors with Online Hard Example Mining(oral)将难分样本挖掘(hard example mining)机制嵌入到SGD算法中，使得Fast R-CNN在训练的过程中根据region proposal的损失自动选取合适的Region Proposal作为正负例训练。实验结果表明使用OHEM（Online Hard Example Mining）机制可以使得Fast R-CNN算法在VOC2007和VOC2012上mAP提高 4%左右。</p>
</li>
<li><p><strong>多层特征融合</strong><br>Fast R-CNN和Faster R-CNN都是利用了最后卷积层的特征进行目标检测，而由于高层的卷积层特征已经损失了很多细节信息（pooling操作），所以在定位时不是很精准。HyperNet等一些方法则利用了CNN的多层特征融合进行目标检测，这不仅利用了高层特征的语义信息，还考虑了低层特征的细节纹理信息，使得目标检测定位更精准。</p>
</li>
<li><p><strong>使用上下文信息</strong><br>在提取Region Proposal特征进行目标检测时，结合Region Proposal上下文信息，检测效果往往会更好一些。（Object detection via a multi-region &amp; semantic segmentation-aware CNN model以及Inside-Outside Net等论文中都使用了上下文信息）</p>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Tallk-about-Caffe-Layers/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Tallk-about-Caffe-Layers/" itemprop="url">
                  Tallk about Caffe Layers
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:15:35+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Tallk-about-Caffe-Layers/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Tallk-about-Caffe-Layers/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/What-is-Deep-Forest/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/What-is-Deep-Forest/" itemprop="url">
                  What is Deep Forest
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:14:57+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/What-is-Deep-Forest/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/What-is-Deep-Forest/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>整个算法看起来不是很复杂。</p>
<ol>
<li>类似以前Stacking的做法，即每一层都用label进行训练，训练完了再叠一层继续训练。加了Complete Random Forest很有意思，个人理解是生成了一些看似无关，但对将来的预测有好处的特征。如果实验里面能做些ablation analysis就好了。</li>
<li>用了一些shortcut-connection，把几层前的数据拿过来连上上一层的输出一起作为这一层Forest的输入。</li>
<li>Multi-Grained Scanning这部分非常像1D和2D convolution。另外实验还只是在小规模数据集上做的，期待CIFAR甚至是ImageNet的结果。深度学习这里也有一直在提但是一直效果不怎么好的Layer-by-Layer训练的思路，如果这个思路能在大数据集上做好，那确实是大突破了。</li>
</ol>
<p>作者：<a href="https://www.zhihu.com/question/56474891/answer/149427631" target="_blank" rel="external">田渊栋</a></p>
<p>先说我的结论：相比前两天引起了广泛讨论的ICLR best paper，这个paper其实更没有什么讨论的意义。当然作为一个research来说，paper还是可以中的，尤其是对于IJCAI。但是我完全不看好这个paper会有什么长远的影响力，以及有人说的可以启发大量后续研究。下面分别从这个idea，实现方法，以及实验结果三个方面分析。</p>
<ol>
<li><strong>Idea：</strong>不用多说，通过stacking weak learner来提升模型性能的想法已经非常常见。然而这样一个idea一定不会work，原罪就在于<strong>tree based model无法进行fine-tune</strong>。这会带来两个非常严重的问题：</li>
</ol>
<ul>
<li><p>A. 无法进行end to end learning，这会极大程度上影响到模型最终的结果。会使depth完全发挥不出威力。</p>
</li>
<li><p>B. 无法进行feature transfer，CNN最最最重要成功的秘诀就在于可以在ImageNet这样海量的数据上进行pretrain，然后再把学习到的(approximately) general feature 通过finetune transfer到其他任务中去。如果BP都没法做，这个就完全无从谈起了。</p>
</li>
<li><p>换句话说，如果这样的Idea能在大数据上work，那么其实相当于否定了BP存在的意义。以后大家都一层一层加就是了嘛。当然这样的好事是不存在的。</p>
</li>
<li><p>如何把tree based model可以做到e2e训练，以及拓展开来如何更高效地把更高效的base learner引入神经网络这又是另外一个故事。我们在这方面也做了一些尝试，但是所有的这一切的基础都是可以bp。</p>
</li>
</ul>
<ol>
<li><p><strong>Method：</strong>这里使用了一个stacking random forest的方法来实现上述idea。从创新性上而言，在<strong>Kaggle</strong>比赛中不同种类模型之间的Stacking和Concatenation早就不是什么新想法。所以从实现层面上而言，仍旧乏善可陈。而且中间层只是把最终分类的结果concat在一起，都不是把每个tree生成的leaf对应的feature。个人觉得这样会严重影响stack的性能，好歹之前FB还是把GBDT的每个leaf当成一个feature才去train的logisitic regression。</p>
</li>
<li><p><strong>Experiment：</strong>这是本文槽点最多的部分。看到还在跑MNIST和ORL就知道这完全是做ML人的玩具。不熟悉别的应用，单就Vision而言，这个结果比ELM其实还没说服力，而且我相信会有更简单的模型同样可以达到类似的结果。比如随便开开脑洞train个SVM中间加个non-linear transformation什么的。现在在CVPR大家都知道Cifar都不能算是有信服力的数据集，更何况MNIST和ORL这种。</p>
</li>
</ol>
<p>另外，比较的网络结构也都是拍拍脑袋想出来的，唯一比了一个经典结构LeNet5还没比过。不过基于上述第一点的看法，我完全不相信这样的算法能在稍微大一些的数据集上取得还不错的结果。另外我觉得非常不合适的claim：</p>
<ol>
<li><p>Table1中画了很多问号，显得CNN要调整的参数有非常多。然而实际上，绝大部分参数都是有默认的设置的。剩下的参数也可以快速通过简单的试错得到一个还不错的初始值。对于这个问题，我的观点一直是每天在抱怨CNN调参困难，在用grid search的人，其实还没理解CNN。</p>
</li>
<li><p>作者不停在claim说gcForest在小数据好，无需调参。然而这只是在不停强调一个low capacity model的好处，这个事情的另外一面在于low capacity model会很快饱和，喂进去再多数据也不会有性能增长。更进一步说，我丝毫不会奇怪tree based model在同等参数条件下比nn based model结果好。因为tree based model就是可以更好地利用参数，然而上限也很快会到来。最后给大家罗列几个非常相似的idea和claim，最后都无法在大数据上取得令人信服结果的工作：</p>
</li>
</ol>
<ul>
<li><p>DSN：邓力老师的工作。基本完全一样的idea，除了是用NN不是forest。</p>
</li>
<li><p>ELM：这么多年了，仍然没有拿得出手的让人信服的结果。。。</p>
</li>
<li><p>PCANet：好在作者自己就认识到这是一个baseline的工作，尝试过大数据，并不work。</p>
</li>
<li><p>SARM：去年炒的沸沸扬扬的NIPS撤稿了的工作。其实单从方法本身来讲着paper并没啥太大问题。但是请大家注意，这个工作当初引起了诸多大牛的注意就是因为paper实验中讲在ImageNet上做出来很好的结果。不过最终也是证明是由于实验错误导致的。</p>
</li>
</ul>
<p>这里有一个三年前做的<a href="http://winsty.net/talks/nonNN.pptx" target="_blank" rel="external">survey</a>。综上，这个paper作为一个junior PhD练手的工作还好，但是要谈多大影响力实在差的还远。历史总是在重复上演，这个idea是属于那种如果有实习生来跟我讲这样一个idea，我绝对不会同意去做的工作。最后吐槽，一个paper的影响力长期来看是会均值回归的，不会因为某个媒体或者某个人爆炒一波成就一个经典工作。希望在这个浮躁的年代，每个人尤其是研究者保持独立思考，不要人云亦云。不忘初心，方得始终。</p>
<p>作者：<a href="https://www.zhihu.com/question/56474891/answer/149549752" target="_blank" rel="external">Naiyan Wang</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/04/Clustering-Again/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/04/Clustering-Again/" itemprop="url">
                  Clustering Again
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-04T22:13:43+08:00">
                2017-03-04
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/04/Clustering-Again/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/04/Clustering-Again/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Mean-Shift-Clustering"><a href="#Mean-Shift-Clustering" class="headerlink" title="Mean-Shift-Clustering"></a>Mean-Shift-Clustering</h1><p><a href="http://efavdb.com/mean-shift/" target="_blank" rel="external">1</a> ：The mean shift clustering algorithm</p>
<p><a href="https://en.wikipedia.org/wiki/Mean_shift" target="_blank" rel="external">2</a> ：Wiki</p>
<p><a href="https://github.com/mattnedrich/MeanShift_py" target="_blank" rel="external">3</a>  ：python_code</p>
<p><a href="https://www.researchgate.net/publication/271218863_Comment_on_Clustering_by_fast_search_and_find_of_density_peaks" target="_blank" rel="external">Comment on “Clustering by fast search and find of density peaks”</a></p>
<p>依然是介绍Alex和Alessandro于2014年发表在的Science上的一篇关于聚类的文章 <a href="http://science.sciencemag.org/content/344/6191/1492" target="_blank" rel="external">Clustering by fast search and find of density peaks</a>，该文章的基本思想很简单，但是其聚类效果却兼具了谱聚类(Spectral Clustering)[<a href="http://www.cs.cornell.edu/courses/cs6780/2010fa/materials/nips01-spectral.pdf" target="_blank" rel="external">On spectral clustering: Analysis and an algorithm</a>, <a href="https://www.cs.cmu.edu/~aarti/Class/10701/slides/Lecture21_2.pdf" target="_blank" rel="external">Spectral clustering</a>, <a href="http://www.cis.rit.edu/~cnspci/references/luxburg2007.pdf" target="_blank" rel="external">A tutorial on spectral clustering</a>]和K-Means的特点，着实激起了极大的兴趣，该聚类算法主要是基于两个基本点：</p>
<ol>
<li>聚类中心的密度高于其临近的样本点的密度</li>
<li>聚类中心与比其密度还高的聚类中心的距离相对较大</li>
</ol>
<p>基于这个思想，聚类过程中的聚类中心数目可以很直观的选取，离群点也能被自动检测出来并排除在聚类分析外。无论每个聚类的形状是什么样的，或者样本点的维度是多少，聚类分析的结果都能令人很满意。下面我会主要基于这篇文章来详述该聚类算法的来龙去脉，并简单回顾下相关的聚类算法。</p>
<h2 id="聚类算法回顾"><a href="#聚类算法回顾" class="headerlink" title="聚类算法回顾"></a>聚类算法回顾</h2><p>众所周知，聚类分析目的在于根据样本之间的相似性将样本划为不同的类簇，但聚类的科学定义貌似在学术界还未达成共识。论文[<a href="https://www.ncbi.nlm.nih.gov/pubmed/15940994" target="_blank" rel="external">Survey of clustering algorithms</a>]对聚类算法进行了综述，发现有好多聚类算法都未曾了解。在K-means和K-medoids中，每个类簇都由一组到各自的聚类中心距离最近的数据组成。两者的目标函数形式为各样本点到对应的聚类中心的距离之和，经过反复的更新聚类中心和重新为样本点分配聚类中心的过程直至收敛，如图1所示。两者的区别在于，K-means的聚类中心为<strong>属于该类簇的所有样本点的均值</strong>，而K-medoids的聚类中心为<strong>该类簇中离所有样本点的聚类之和最小的样本点</strong>。这两者聚类算法实现起来都非常简单，对于紧凑型的和呈超球体状分布的数据非常适用。但两者的缺陷也很明显：</p>
<ol>
<li>缺乏能确定类簇数目和进行初步划分的有效机制；</li>
<li>迭代优化的策略无法保证全局最优解；</li>
<li>对离群点和噪声非常敏感</li>
</ol>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-001.png" alt="l2_1"></center>


<p>在基于概率密度的聚类算法中，我们会假设<strong>各类簇由不同的概率密度函数产生</strong>(如图2)，而每个样本点则是以不同的权重服从这些概率分布的。<strong>很不幸的是，在这类算法中用最大似然估计求解参数往往不可行</strong>，只能用迭代求解的方式获得一个次优解，而<strong>期望最大化(Expectation Maximization,EM)</strong>是最常用的一个策略。在这类算法中，最典型的莫过于<strong><a href="http://www.researchgate.net/publication/303672489_Gaussian_Mixture_Models" target="_blank" rel="external">高斯混合模型(Gaussian Mixture Model</a>,GMM)</strong>。这类算法的准确度取决于<strong>预先定义的概率分布能否很好的拟合训练数据</strong>，但问题在于很多情况下我们无法知晓数据在整体上或者局部上到底近似于什么样的概率分布。  </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-002.png" alt="l2_1"></center>

<p>基于局部密度的聚类算法可以很容易地检测出任意形状的类簇。在<a href="https://www.researchgate.net/publication/221653977_A_Density-Based_Algorithm_for_Discovering_Clusters_in_Large_Spatial_Databases_with_Noise" target="_blank" rel="external">DBSCAN</a>中，需要用户给定<strong>密度阈值</strong>和<strong>领域半径</strong>作为参数，在领域半径内的密度小于该阈值的样本点被视为噪声点，剩下的密度较高的非连通区域则被分配到不同的类簇中，其伪代码如下所示。但是选择合适的密度阈值并不是那么容易的事情，有关的参数估计建议可参见<a href="http://en.wikipedia.org/wiki/DBSCAN" target="_blank" rel="external">wiki</a>。DBSCAN的优点总结如下：</p>
<ol>
<li>无需预先指定类簇的数目；</li>
<li>可以发现任意形状的类簇，如图3所示；</li>
<li>可以检测出噪声点，且对噪声点鲁棒性较强；</li>
<li>除了边界点外，聚类结果(核心点与噪声点)与样本点的遍历顺序无关。</li>
</ol>
<p>DBSCAN的缺点总结如下：</p>
<ol>
<li>针对边界点而言，DBSCAN的聚类结果并非完全确定的。幸运的是这种情况并非频繁出现，而且对聚类的结果影响很小。如果把边界点也当成噪声点处理，那么聚类结果就具有确定性。</li>
<li>聚类结果依赖于距离度量规则。最常用的<strong>欧式距离在高维空间里由于“维度灾难”</strong>几乎无法发挥有效作用，使得设定合适的搜寻半径更为困难。</li>
<li><p><strong>不适用于密度差异很大的数据集</strong>，因为此时各个类簇的搜寻半径和密度阈值都不相同，使得参数的选取更为困难。</p>
<pre><code>DBSCAN(D, eps, minPts)
//eps:search radius
//minPts:density threshold
   C = 0
   for each unvisited point P in dataset D
      mark P as visited
      NeighborPts = regionQuery(P, eps)
      if sizeof(NeighborPts) &lt; minPts
         mark P as NOISE
      else
         C = next cluster
         expandCluster(P, NeighborPts, C, eps, MinPts)

expandCluster(P, NeighborPts, C, eps, minPts)
   add P to cluster C
   for each point Q in NeighborPts 
      if Q is not visited
         mark Q as visited
         NeighborPts&apos; = regionQuery(Q, eps)
         if sizeof(NeighborPts&apos;) &gt;= minPts
            NeighborPts = NeighborPts joined with NeighborPts&apos;
      if Q is not yet member of any cluster
         add Q to cluster C

regionQuery(P, eps)
   return all points within P&apos;s eps-neighborhood (including P)
</code></pre></li>
</ol>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-003.png" alt="l2_1"></center>

<p>基于均值漂移(Mean-shift)[<a href="http://en.wikipedia.org/wiki/Mean-shift" target="_blank" rel="external">Mean-shift</a>, <a href="http://ieeexplore.ieee.org/document/1000236/" target="_blank" rel="external">Mean shift: A robust approach toward feature space analysis</a>, <a href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/mean_shift.pdf" target="_blank" rel="external">Mean shift clustering</a>]的聚类算法则无需为<strong>搜索半径</strong>和<strong>密度阈值</strong>的设定而烦恼，不过也面临bandwidth的选取问题，关于怎么设定bandwidth的研究可参见[<a href="http://ieeexplore.ieee.org/document/937550/" target="_blank" rel="external">The variable bandwidth mean shift and data-driven scale selection</a>, <a href="http://pdf.aminer.org/000/169/427/image_and_video_segmentation_by_anisotr**opic_kernel_mean_shift.pdf" target="_blank" rel="external">Image and video segmentation by anisotropic kernel mean shift</a>]。Mean-sift的基本思路就是从初始点出发，以梯度上升的方式不断寻找核密度估计函数的局部最大值直至收敛<strong>(如图4(a)所示)，这些驻点代表分布的模式。在基于mean-shift的聚类算法中，依次以每一个样本点作为mean-shift的起始点，然后将其移至核密度估计函数的某个局部驻点，最后近似收敛到同一个驻点的所有样本被划分至同一个类簇，如图4(b)所示。总体而言，在基于密度的聚类算法中，</strong>类簇可被定义为收敛到相同的密度分布函数局部极大值的样本点的集合**。 </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-005.png" alt="l2_1"></center>

<h2 id="基于密度峰值和距离的聚类算法"><a href="#基于密度峰值和距离的聚类算法" class="headerlink" title="基于密度峰值和距离的聚类算法"></a>基于密度峰值和距离的聚类算法</h2><p>该聚类算法的假设前提是聚类中心周围的样本点的局部密度低于聚类中心的局部密度，并且聚类中心与比其局部密度更高的点之间的距离相对较大。其聚类效果与DBSCAN和mean-shift类似，可以检测出非球体的类簇。作者号称可以<strong>自动</strong>找到类簇的数目，虽然文中给了一点相关的寻找聚类数目的思路，但是提供的Matlab代码中没有实现该思路，还是需要人工选择聚类中心，所以在相关评论[<a href="http://comments.sciencemag.org/content/10.1126/science.1242072" target="_blank" rel="external">Comments on clustering by fast search and find of density peaks</a>]中“自动”一词遭到了质疑。与mean-shift类似，聚类中心定义为局部密度最大值点；与mean-shift不同的是，聚类中心是某个特定样本点，并且无需在核函数定义的空间内针对每个样本点显式求解局部密度最大的点。 </p>
<p>根据这篇文章的评论，发现还有两个密度的度量方法也是很有价值的。第一个是用样本点与最近的M个邻居的距离的均值的负数来描述，另一个就是高斯核函数来度量，会比用截断距离度量鲁棒性更强一些。</p>
<p>对于密度值为局部或全局最大的样本点而言，它们的δi会比其他样本点的δj值要大很多(如图5所示)，因为前者代表局部密度最大的样本点之间的距离，而后者代表样本点与其对应的局部密度最大的样本点之间的距离。因此，那些δ值很大的样本点也很有可能就是聚类中心。 </p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-006.png" alt="l2_1"></center>

<p>在找出聚类中心后，接下来就是将所有剩下的点划分到比其密度更高且最近的样本点所属的类簇中，当然经过这一步之后暂时会为噪声点也分配到类簇中。在聚类分析中，经常还会<strong>进一步分析类簇分配的可靠性</strong>。在<strong>DBSCAN</strong>中，只考虑了密度高于密度阈值的可靠性高一些的样本点，但是会出现较低密度的类簇被误认为噪声的情况。文中取而代之的是为每个类簇引入<strong>边界区域</strong>的概念。边界区域的密度值ρb会根据属于这个类簇并且与属于其他类簇的样本点之间的距离小于dc的成员计算出来。对于每个类簇中的所有样本点，密度值高于ρb的被视为类簇的核心组成部分(cluster core)，剩下的则被视为该类簇的<strong>光晕(cluster halo)</strong>，类簇光晕中则包含噪声点。论文中给出了一个聚类的结果，如图7所示。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-008.png" alt="l2_1"></center>

<p>邻域搜索半径dc到底如何取值呢？dc显然是对聚类结果又影响的，这一点我们仅需要考虑两个最极端的情形就明白了。如果dc太大，那么每个数据点的密度值都近似相等，导致所有数据点被划分至同一个类簇中；如果dc太小，每个类簇包含的样本点会很少，很有可能出现同一个类簇被分割成好几部分的情况。另一方面，不同的数据集中数据点之间的密集程度不同，那么想给出一个适合所有数据集的dcdc是不可能的。作者在文中提出，合适的dc应该使数据点的平均近邻数目占整个数据集规模的比例为τ,<strong>(τ=1%∼2%)</strong>。如此一来，参数τ就独立于特定数据集了。针对每个数据集，我们都可以寻找一个比较合适的dc。结合作者给出的Matlab代码，分析后可知具体的计算方法如下：取出对称的距离矩阵的上三角所有的<strong>M=N(N−1)/2</strong>个元素，然后对其进行升序排列<strong>d1≤d2≤⋯≤dMd1≤d2≤⋯≤dM</strong>。为了保证平均每个数据点的近邻点数目所占比例为τ，那么只要保证小于dcdc的距离数目所占比例也为ττ即可，因此取dc=dround(τM)dc=dround(τM)。 </p>
<p>类簇的数目该如何确定呢？作者给Matlab代码中，聚类中心是需要人工选定的，很多读者因此质疑文中的”it is able to detect nonspherical clusters and to automatically find the correct number of clusters”，是不是有种被欺骗的感觉。不过作者在文中也给出了一个简单选择类簇的数目，虽然我也觉得该方法存在一些问题，但总归还是给出了解决方案的。由前面解释的论文的两个基本立足点可知，聚类中心对应的ρρ和δδ都是比较大的。作者为每个样本点xi引入γi=ρiδi，然后将所有的γi降序排列后显示在图9(a)。如果分别对ρ和δ先做<strong>归一化处理</strong>后会更合理一些，这样也会使得两者参与决策的权重相当。因为如果ρ和δ的不在一个数量级，那么必然数量级小带来的的影响会很小。</p>
<p>接下来怎么办呢？作者依然没有给出具体的解决方案。因为整体而言，γ的值在大多数情况下还是很相近的，差异比较大的就是那几个聚类中心，我觉得可以从异常检查(Anomaly Detection)的角度去寻找这个跳跃点。最简单方法，可以根据相邻γ的值构建一个高斯分布N(μ,σ2)，根据最大似然参数估计法，该高斯分布的参数只需扫描两遍γ的值即可，所以模型还是很效率还是很高的。有了这个模型后，我们从后往前扫描γ的值，如果发现某个值的左边或右边的累积概率(如图8的左右两侧蓝色区域)小于阈值(比如0.005)时就判定找到了异常的跳跃点，此时就能大致确定类簇的数目了。若想进一步学习如何利用高斯分布进行异常检测可参见[<a href="http://www.holehouse.org/mlclass/15_Anomaly_Detection.html" target="_blank" rel="external">Anomaly detection</a>]。 我们都知道高斯分布的概率密度函数,可是高斯分布的累积分布函数(Cumulative Distribution Function)不存在初等函数的表达形式,那该如何是好?查找了半天资料,也没找到如何数值逼近的原理说明,不过搜到了一段用java编写的基于Hart Algorithm近似计算标准正态分布的累积分布函数的代码[<a href="http://www.onedigit.org/Home/quantitative-finance/hart-algorithm-for-normal-cdf" target="_blank" rel="external">Hart algorithm for normal cdf</a>]。寥寥数行java代码就搞定了,但是我暂时没理解为什么这么做是可行的。将输出结果和维基百科上的Q函数表[<a href="http://en.wikipedia.org/wiki/Q-function" target="_blank" rel="external">Q-function</a>]中的数据对比分析(注意1−Q(x)=Φ(x)),发现结果和预期的一模一样,简直惊呆。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-009.png" alt="l2_1"></center>


<pre><code>double CDFofNormalDistribution(double x)
{
    const double PI=3.1415926;
    double p0=220.2068679123761;
    double p1=221.2135961699311;
    double p2=112.0792914978709;
    double p3=33.91286607838300;
    double p4=6.373962203531650;
    double p5=.7003830644436881;
    double p6=.03326249659989109;

    double q0=440.4137358247552;
    double q1=793.8265125199484;
    double q2=637.3336333788311;
    double q3=296.5642487796737;
    double q4=86.78073220294608;
    double q5=16.06417757920695;
    double q6=1.755667163182642;
    double q7=0.08838834764831844;

    double cutoff=7.071;//10/sqrt(2)
    double root2pi=2.506628274631001;//sqrt(2*PI)

    double xabs=abs(x);

    double res=0;
    if(x&gt;37.0) 
        res=1.0;
    else if(x&lt;-37.0)
        res=0.0;
    else
    {
        double expntl=exp(-.5*xabs*xabs);
        double pdf=expntl/root2pi;
        if(xabs&lt;cutoff)
            res=expntl*((((((p6*xabs + p5)*xabs + p4)*xabs + p3)*xabs+ \
                p2)*xabs + p1)*xabs + p0)/(((((((q7*xabs + q6)*xabs + \
                q5)*xabs + q4)*xabs + q3)*xabs + q2)*xabs + q1)*xabs+q0);
        else
            res=pdf/(xabs+1.0/(xabs+2.0/(xabs+3.0/(xabs+4.0/(xabs+0.65)))));
    }
    if(x&gt;=0.0)
        res=1.0-res;
    return res;
}
</code></pre><p>此外，作者声称根据随机均匀分布生成的数据对应的γ服从幂律分布(Power laws)，但是真正具备聚类中心的数据集是不存在这种情况的。很多现象其实都是近似服从幂律分布的，尤其适用于大多数事件的规模很小但少数事件规模很大的场合，不过作者在此并未给出该定论的出处，所以同样这一点遭到了很多读者的质疑。我猜目前只是作者根据一些实验数归纳出来的，只能说是靠不完全统计得到的经验，没有实质性的理论依据。也就是γ≈cr−k+ϵ，其中r为γ的排名序号，那么log⁡γ和log⁡r之间应该近似呈现线性关系，如图9(b)所示。如果作者的猜测正确的话，我们不妨在聚类前汇出如log⁡γ和log⁡r的关系图，借此判断聚类的复杂性，或者说在该数据集上进行聚类的结果可靠性如何。</p>
<center><img src="/2017/03/04/Clustering-Again/2017-0304-010.png" alt="l2_1"></center>

<p>注：代码有两处需要更改：</p>
<ol>
<li>计算radius时Num换成Num*(Num-1)；</li>
<li>求聚类个数时，求几个聚类中心点（N个值的前k个），有句code应该在for循环外。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/02/Summary-of-Clustering/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/02/Summary-of-Clustering/" itemprop="url">
                  Summary-of-Clustering
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-02T22:12:19+08:00">
                2017-03-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/02/Summary-of-Clustering/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/02/Summary-of-Clustering/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近看了下聚类算法，在此记个笔记。</p>
<p>cousera上不错的clustering公开课 <a href="http://hanj.cs.illinois.edu/" target="_blank" rel="external">jiawei han</a></p>
<ul>
<li>为什么基于距离的聚类算法只能发现类圆形？</li>
</ul>
<p>这和你选择的范数有关，因为是在欧式空间内求的距离，对应的就是周围点到中心点的距离，只管看起来就是画圆圈啊，确定了半径，圆圈内的都是这个类了。但是这只是在欧式空间内对欧氏距离的应用，如果你对流行数据做聚类，就会发现这个聚类对距离进行了重新的定义，看起来就不是你所谓的与圆圈之类的。</p>
<ul>
<li><a href="https://www.zhihu.com/question/20977382" target="_blank" rel="external">哪种聚类算法可以不需要指定聚类的个数，而且可以生成聚类的规则？</a></li>
</ul>
<p><a href="https://www.zhihu.com/question/20759409" target="_blank" rel="external"><strong>聚类算法的经典综述：</strong></a></p>
<ol>
<li><a href="https://link.springer.com/chapter/10.1007%2F978-3-540-87479-9_3" target="_blank" rel="external">Data Clustering</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.318.2219&amp;rep=rep1&amp;type=pdf" target="_blank" rel="external">Survey of Clustering Algorithms</a></li>
<li><a href="https://link.springer.com/article/10.1007%2Fs40745-015-0040-1" target="_blank" rel="external">A Comprehensive Survey of Clustering Algorithms. Annals of Data Science</a></li>
</ol>
<h2 id="k-means聚类算法优缺点"><a href="#k-means聚类算法优缺点" class="headerlink" title="k-means聚类算法优缺点"></a>k-means聚类算法优缺点</h2><p>优点：</p>
<ol>
<li>计算速度快</li>
<li>已解释</li>
<li>效果还不错</li>
<li>相对稳定，谱聚类效果好，层次聚类快</li>
</ol>
<p>缺点：</p>
<ol>
<li>对异常值相当敏感</li>
<li>需要提前知道k值</li>
<li>收敛慢</li>
<li>不一定全局最优</li>
</ol>
<hr>
<p>主要读了文章：<a href="http://science.sciencemag.org/content/344/6191/1492" target="_blank" rel="external">Clustering by fast search and find of density peaks</a> Alex Rodriguez, <a href="http://people.sissa.it/~laio/Research/Res_clustering.php" target="_blank" rel="external">Alessandro Laio</a></p>
<h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p>该算法的<strong>两个重要假设</strong>：类簇的中心由一些局部密度比较低的点围绕, 并且这些点距离其他有高局部密度的点的距离都比较大. </p>
<p>首先定义两个值: 局部密度以及到高局部密度点的距离delta。</p>
<p>样本点局部密度p：</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-001.jpg" alt="l2_1"></center><br><img src="/2017/03/02/Summary-of-Clustering/2017-0302-010.jpg" alt="l2_1"><br><br>dc是一个截断距离, 是一个参数. 所以相当于距离点di的距离小于的点的个数。文章的实验表明，dc的选择比较鲁棒, 文中dc的推荐值是使得平均每个点的邻居数为样本总数的1%-2%。如果样本点的数量过小即分布过散，可参照mean-shift，采用核密度估计的方法计算每点的局部密度。<br><br>样本点到高局部密度点的距离：<br><center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-002.jpg" alt="l2_1"></center><br>由公式可知，为密度高于样本点的样本点到样本点的最近距离。对于密度最大的点<img src="/2017/03/02/Summary-of-Clustering/2017-0302-003.jpg" alt="l2_1">,。由定义可知，局部密度最大的点肯定是一个中心点。<br><br>## 聚类过程<br><br>计算出所有样本点的局部密度值和到高局部密度点的距离后，可以得到一张决策图。在决策图上挑选出具有较大以及较大的样本点作为类簇中心。<strong>在确定了类簇中心之后, 其它样本点依据局部密度从高到低依先后顺序确定所属的类别，每个人非中心的样本点的类别为邻域内最近的高于该点样本点的点的样本点所属的类别（重要，如此可满足流形）。</strong>图例如下:<br><br><center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-004.png" alt="l2_1"></center>

<center><strong>聚类过程说明</strong></center>

<p>如图所示，总共有28个样本点，样本点按密度高低从小到大给以标号，即1～28号点局部密度递减。通过图1右侧的决策图，我们筛选出具有较大以及较大的1号和10号点作为类簇中心，其余点按密度从高到低依次赋予所属类簇标号。如首先为2号点赋值，离2号最近的密度高于2号点的为1，因此将1号点所属标号赋予2号；对于3号点，离3号最近的密度高于3号点的为1，因此将1号点所属标号赋予3号；对于4号点，离4号最近的密度高于4号点的为1，因此将1号点所属标号赋予4号；<em>对于5号点，离5号最近的密度高于4号点的为4，因此将4号点所属标号赋予5号……</em>，如此直至标完所有样本点标号。此外，26, 27, 28三个点的也比较大, 但是较小, 所以是异常点.</p>
<h2 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h2><p>聚类分析主要是评估本文算法对参数以及样本分布的鲁棒性。</p>
<p> <strong>首先评估样本分布对聚类结果的影响。</strong>在聚类分析中, 通常需要确定每个点划分给某个类簇的可靠性. 在该算法中, 可以首先为每个类簇定义一个边界区域(border region), 亦即划分给该类簇但是距离其他类簇的点的距离小于的点. 然后为每个类簇找到其边界区域的局部密度最大的点, 令其局部密度为. 该类簇中所有局部密度大于的点被认为是类簇核心的一部分(亦即将该点划分给该类簇的可靠性很大), 其余的点被认为是该类簇的光晕(halo), 亦即可以认为是噪音。图例如下：</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-005.png" alt="l2_1"></center>

<center><strong>样本疏密对聚类结果的影响</strong></center>

<p>A图为生成数据的概率分布, B, C二图为分别从该分布中生成了4000, 1000个点. D, E分别是B, C两组数据的决策图, 可以看到两组数据都只有五个点有具有较大以及较大 这些点作为类簇的中心, 在确定了类簇的中心之后, 每个点被划分到各个类簇(彩色点), 或者是划分到类簇光晕(黑色点)。F图展示的是随着抽样点数量的增多, 聚类的错误率在逐渐下降。由图可知当样本数处于1000～10000时，聚类错误率均为1%以下， 说明该算法对数据疏密具有一定的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-006.jpg" alt="l2_1"></center><br><center><strong>阈值dc对算法的影响</strong></center>

<p><strong>其次评估参数对聚类结果的影响。</strong>如图所示，分别设置的值为0.005、0.001，0.005和0.1。由以上4个不同的值，得到4种聚类结果。观察图3可发现，当的值从0.005变化值0.1时，虽然的值变化了20倍，但是聚类结果在感官上并无大的差异。以上说明，本文算法对阈值具有良好的鲁棒性。</p>
<p><strong>接着评估不同的数据分布对聚类结果的影响。</strong> 图4中的4幅子图中的数据都具有较大的聚类难度。其中，图A的难点在于，类的大小不均衡；图B的难度在于类的数量繁多，且高度重合；图C和图D的难度在于各类在特征空间上分布为非球形。一般来讲，在涉及到利用流形分类的算法中，图C和图D都会作为经典的测试数据。由4幅子图的聚类结果容易看出本文算法对数据分布的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-03-02-007.png" alt="l2_1"></center><br><center><strong>不同的数据分布下的聚类效果展示</strong></center>

<p><strong>最后评估不同度量对聚类结果的影响。</strong>如图5所示，对图A中的数据做3种非线性映射分别得到B、C和D三种新的数据分布。由A、B、C和D的聚类结果可以看出，本文算法对度量具有好的鲁棒性。</p>
<center><img src="/2017/03/02/Summary-of-Clustering/2017-0302-008.jpg" alt="l2_1"></center><br><center><strong>不同的度量对聚类结果的影响</strong></center>

<h2 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a>算法总结</h2><p>本文提出的算法在本质上是基于流形的做法。本文的算法的过程可以总结为：首先搜索合适的局部密度最大点作为类簇中心，然后再将类簇标签从高密度点向低密度点依次传播。</p>
<p>参考资料：一个很用心的<a href="http://www.cnblogs.com/jeromeblog/p/4141902.html" target="_blank" rel="external">blog</a>，想大神致敬。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://verdin.cn/2017/03/02/Optimization/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Verdin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Verdin小站">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Verdin小站" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/02/Optimization/" itemprop="url">
                  Optimization
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-02T12:11:19+08:00">
                2017-03-02
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/03/02/Optimization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/02/Optimization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="最优化-Optimization"><a href="#最优化-Optimization" class="headerlink" title="最优化 Optimization"></a>最优化 Optimization</h2><p>在之前介绍了图像分类任务中的两个关键部分：</p>
<ol>
<li><p>基于参数的<strong>评分函数</strong>。该函数将原始图像像素映射为分类评分值（例如：一个线性函数）。</p>
</li>
<li><p><strong>损失函数</strong>。该函数能够根据分类评分和训练集图像数据实际分类的一致性，衡量某个具体参数集的质量好坏。损失函数有多种版本和不同的实现方式（例如：Softmax或SVM）。</p>
</li>
</ol>
<p>上节中，线性函数的形式是<img src="/2017/03/02/Optimization/2017-03-02-001.png" alt="Optimization">，而SVM实现的公式是：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-002.png" alt="Optimization"></center>

<p>对于图像数据x_i，如果基于参数集W做出的分类预测与真实情况比较一致，那么计算出来的损失值L就很低。现在介绍第三个，也是最后一个关键部分：<strong>最优化Optimization</strong>。最优化是寻找能使得损失函数值最小化的参数W的过程。</p>
<p>铺垫：一旦理解了这三个部分是如何相互运作的，我们将会回到第一个部分（基于参数的函数映射），然后将其拓展为一个远比线性函数复杂的函数：首先是神经网络，然后是卷积神经网络。而损失函数和最优化过程这两个部分将会保持相对稳定。</p>
<h2 id="损失函数可视化"><a href="#损失函数可视化" class="headerlink" title="损失函数可视化"></a>损失函数可视化</h2><p>本课中讨论的损失函数一般都是定义在高维度的空间中（比如，在CIFAR-10中一个线性分类器的权重矩阵大小是[10x3073]，就有30730个参数），这样要将其可视化就很困难。然而办法还是有的，在1个维度或者2个维度的方向上对高维空间进行切片，就能得到一些直观感受。例如，随机生成一个权重矩阵W，该矩阵就与高维空间中的一个点对应。然后沿着某个维度方向前进的同时记录损失函数值的变化。换句话说，就是生成一个随机的方向W_1并且沿着此方向计算损失值，计算方法是根据不同的a值来计算L(W+aW_1)。这个过程将生成一个图表，其x轴是a值，y轴是损失函数值。同样的方法还可以用在两个维度上，通过改变a,b来计算损失值L(W+aW_1+bW_2)，从而给出二维的图像。在图像中，a,b可以分别用x和y轴表示，而损失函数的值可以用颜色变化表示：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-003.png" alt="Optimization"></center>

<p>一个无正则化的多类SVM的损失函数的图示。左边和中间只有一个样本数据，右边是CIFAR-10中的100个数据。<strong>左</strong>：a值变化在某个维度方向上对应的的损失值变化。<strong>中和右</strong>：两个维度方向上的损失值切片图，蓝色部分是低损失值区域，红色部分是高损失值区域。注意损失函数的分段线性结构。多个样本的损失值是总体的平均值，所以右边的碗状结构是很多的分段线性结构的平均（比如中间这个就是其中之一）。</p>
<hr>
<p>我们可以通过数学公式来解释损失函数的分段线性结构。对于一个单独的数据，有损失函数的计算公式如下：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-004.png" alt="Optimization"></center><br>通过公式可见，每个样本的数据损失值是以W为参数的线性函数的总和（零阈值来源于max(0,-)函数）。W的每一行（即w_j），有时候它前面是一个正号（比如当它对应错误分类的时候），有时候它前面是一个负号（比如当它是是正确分类的时候）。为进一步阐明，假设有一个简单的数据集，其中包含有3个只有1个维度的点，数据集数据点有3个类别。那么完整的无正则化SVM的损失值计算如下：<br><br><center><img src="/2017/03/02/Optimization/2017-03-02-005.png" alt="Optimization"></center><br>因为这些例子都是一维的，所以数据x_i和权重w_j都是数字。观察w_0，可以看到上面的式子中一些项是w_0的线性函数，且每一项都会与0比较，取两者的最大值。可作图如下：<br><br><center><img src="/2017/03/02/Optimization/2017-03-02-006.png" alt="Optimization"></center>

<p>从一个维度方向上对数据损失值的展示。x轴方向就是一个权重，y轴就是损失值。数据损失是多个部分组合而成。其中每个部分要么是某个权重的独立部分，要么是该权重的线性函数与0阈值的比较。完整的SVM数据损失就是这个形状的30730维版本。</p>
<hr>
<p>需要多说一句的是，你可能根据SVM的损失函数的碗状外观猜出它是一个凸函数。关于如何高效地最小化凸函数的论文有很多，你也可以学习斯坦福大学关于（凸函数最优化）的课程。但是一旦我们将f函数扩展到神经网络，目标函数就就不再是凸函数了，图像也不会像上面那样是个碗状，而是凹凸不平的复杂地形形状。</p>
<p>不可导的损失函数。作为一个技术笔记，你要注意到：由于max操作，损失函数中存在一些不可导点（kinks），这些点使得损失函数不可微，因为在这些不可导点，梯度是没有定义的。但是次梯度（subgradient）依然存在且常常被使用。在本课中，我们将交换使用次梯度和梯度两个术语。</p>
<h2 id="最优化-Optimization-1"><a href="#最优化-Optimization-1" class="headerlink" title="最优化 Optimization"></a>最优化 Optimization</h2><p>重申一下：损失函数可以量化某个具体权重集W的质量。而最优化的目标就是找到能够最小化损失函数值的W 。我们现在就朝着这个目标前进，实现一个能够最优化损失函数的方法。对于有一些经验的同学，这节课看起来有点奇怪，因为使用的例子（SVM 损失函数）是一个凸函数问题。但是要记得，最终的目标是不仅仅对凸函数做最优化，而是能够最优化一个神经网络，而对于神经网络是不能简单的使用凸函数的最优化技巧的。</p>
<h3 id="策略-1：一个差劲的初始方案：随机搜索"><a href="#策略-1：一个差劲的初始方案：随机搜索" class="headerlink" title="策略#1：一个差劲的初始方案：随机搜索"></a>策略#1：一个差劲的初始方案：随机搜索</h3><p>既然确认参数集<strong>W</strong>的好坏蛮简单的，那第一个想到的（差劲）方法，就是可以随机尝试很多不同的权重，然后看其中哪个最好。过程如下：</p>
<pre><code># 假设X_train的每一列都是一个数据样本（比如3073 x 50000）
# 假设Y_train是数据样本的类别标签（比如一个长50000的一维数组）
# 假设函数L对损失函数进行评价

bestloss = float(&quot;inf&quot;) # Python assigns the highest possible float value
for num in xrange(1000):
  W = np.random.randn(10, 3073) * 0.0001 # generate random parameters
  loss = L(X_train, Y_train, W) # get the loss over the entire training set
  if loss &lt; bestloss: # keep track of the best solution
    bestloss = loss
    bestW = W
  print &apos;in attempt %d the loss was %f, best %f&apos; % (num, loss, bestloss)

# 输出:
# in attempt 0 the loss was 9.401632, best 9.401632
# in attempt 1 the loss was 8.959668, best 8.959668
# in attempt 2 the loss was 9.044034, best 8.959668
# in attempt 3 the loss was 9.278948, best 8.959668
# in attempt 4 the loss was 8.857370, best 8.857370
# in attempt 5 the loss was 8.943151, best 8.857370
# in attempt 6 the loss was 8.605604, best 8.605604
# ... (trunctated: continues for 1000 lines)
</code></pre><p>在上面的代码中，我们尝试了若干随机生成的权重矩阵<strong>W</strong>，其中某些的损失值较小，而另一些的损失值大些。我们可以把这次随机搜索中找到的最好的权重<strong>W</strong>取出，然后去跑测试集：</p>
<pre><code># 假设X_test尺寸是[3073 x 10000], Y_test尺寸是[10000 x 1]
scores = Wbest.dot(Xte_cols) # 10 x 10000, the class scores for all test examples
# 找到在每列中评分值最大的索引（即预测的分类）
Yte_predict = np.argmax(scores, axis = 0)
# 以及计算准确率
np.mean(Yte_predict == Yte)
# 返回 0.1555
</code></pre><p>验证集上表现最好的权重W跑测试集的准确率是<strong>15.5%</strong>，而完全随机猜的准确率是10%，如此看来，这个准确率对于这样一个不经过大脑的策略来说，还算不错嘛！</p>
<p><strong>核心思路：迭代优化</strong>。当然，我们肯定能做得更好些。核心思路是：虽然找到最优的权重W非常困难，甚至是不可能的（尤其当W中存的是整个神经网络的权重的时候），但如果问题转化为：对一个权重矩阵集W取优，使其损失值稍微减少。那么问题的难度就大大降低了。换句话说，我们的方法从一个随机的W开始，然后对其迭代取优，每次都让它的损失值变得更小一点。</p>
<p><em>我们的策略是从随机权重开始，然后迭代取优，从而获得更低的损失值。</em></p>
<p><strong>蒙眼徒步者的比喻：</strong>一个助于理解的比喻是把你自己想象成一个蒙着眼睛的徒步者，正走在山地地形上，目标是要慢慢走到山底。在CIFAR-10的例子中，这山是30730维的（因为W是3073x10）。我们在山上踩的每一点都对应一个的损失值，该损失值可以看做该点的海拔高度。</p>
<h3 id="策略-2：随机本地搜索"><a href="#策略-2：随机本地搜索" class="headerlink" title="策略#2：随机本地搜索"></a>策略#2：随机本地搜索</h3><p>第一个策略可以看做是每走一步都尝试几个随机方向，如果某个方向是向山下的，就向该方向走一步。这次我们从一个随机W开始，然后生成一个随机的扰动\delta W ，只有当W+\delta W的损失值变低，我们才会更新。这个过程的具体代码如下：</p>
<pre><code>W = np.random.randn(10, 3073) * 0.001 # 生成随机初始W
bestloss = float(&quot;inf&quot;)
for i in xrange(1000):
  step_size = 0.0001
  Wtry = W + np.random.randn(10, 3073) * step_size
  loss = L(Xtr_cols, Ytr, Wtry)
  if loss &lt; bestloss:
    W = Wtry
    bestloss = loss
  print &apos;iter %d loss is %f&apos; % (i, bestloss)
</code></pre><p>使用同样的数据（1000），这个方法可以得到21.4%的分类准确率。这个比策略一好，但是依然过于浪费计算资源。</p>
<h3 id="策略-3：跟随梯度"><a href="#策略-3：跟随梯度" class="headerlink" title="策略#3：跟随梯度"></a>策略#3：跟随梯度</h3><p>前两个策略中，我们是尝试在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的<strong>梯度（gradient）</strong>。在蒙眼徒步者的比喻中，这个方法就好比是感受我们脚下山体的倾斜程度，然后向着最陡峭的下降方向下山。</p>
<p>在一维函数中，斜率是函数在某一点的瞬时变化率。梯度是函数的斜率的一般化表达，它不是一个值，而是一个向量。在输入空间中，梯度是各个维度的斜率组成的向量（或者称为<strong>导数derivatives</strong>）。对一维函数的求导公式如下：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-007.png" alt="Optimization"></center>

<p>当函数有多个参数的时候，我们称导数为偏导数。而梯度就是在每个维度上偏导数所形成的向量。</p>
<h2 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h2><p>计算梯度有两种方法：一个是缓慢的近似方法（<strong>数值梯度法</strong>），但实现相对简单。另一个方法（<strong>分析梯度法</strong>）计算迅速，结果精确，但是实现时容易出错，且需要使用微分。现在对两种方法进行介绍：</p>
<h3 id="利用有限差值计算梯度"><a href="#利用有限差值计算梯度" class="headerlink" title="利用有限差值计算梯度"></a>利用有限差值计算梯度</h3><p>上节中的公式已经给出数值计算梯度的方法。下面代码是一个输入为函数f和向量x，计算f的梯度的通用函数，它返回函数f在点x处的梯度：</p>
<pre><code>def eval_numerical_gradient(f, x):
  &quot;&quot;&quot;  
  一个f在x处的数值梯度法的简单实现
  - f是只有一个参数的函数
  - x是计算梯度的点
  &quot;&quot;&quot; 

  fx = f(x) # 在原点计算函数值
  grad = np.zeros(x.shape)
  h = 0.00001

  # 对x中所有的索引进行迭代
  it = np.nditer(x, flags=[&apos;multi_index&apos;], op_flags=[&apos;readwrite&apos;])
  while not it.finished:

    # 计算x+h处的函数值
    ix = it.multi_index
    old_value = x[ix]
    x[ix] = old_value + h # 增加h
    fxh = f(x) # 计算f(x + h)
    x[ix] = old_value # 存到前一个值中 (非常重要)

    # 计算偏导数
    grad[ix] = (fxh - fx) / h # 坡度
    it.iternext() # 到下个维度

  return grad
</code></pre><p>根据上面的梯度公式，代码对所有维度进行迭代，在每个维度上产生一个很小的变化h，通过观察函数值变化，计算函数在该维度上的偏导数。最后，所有的梯度存储在变量<strong>grad</strong>中。</p>
<p><strong>实践考量：</strong>注意在数学公式中，h的取值是趋近于0的，然而在实际中，用一个很小的数值（比如例子中的1e-5）就足够了。在不产生数值计算出错的理想前提下，你会使用尽可能小的h。还有，实际中用<strong>中心差值公式（centered difference formula）</strong>[f(x+h)-f(x-h)]/2h效果较好。细节可查看<a href="https://en.wikipedia.org/wiki/Numerical_differentiation" target="_blank" rel="external">wiki</a>。</p>
<p>可以使用上面这个公式来计算任意函数在任意点上的梯度。下面计算权重空间中的某些随机点上，CIFAR-10损失函数的梯度：</p>
<pre><code># 要使用上面的代码我们需要一个只有一个参数的函数
# (在这里参数就是权重)所以也包含了X_train和Y_train
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # 随机权重向量
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # 得到梯度
</code></pre><p>梯度告诉我们损失函数在每个维度上的斜率，以此来进行更新：</p>
<pre><code>loss_original = CIFAR10_loss_fun(W) # 初始损失值
print &apos;original loss: %f&apos; % (loss_original, )

# 查看不同步长的效果
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # 权重空间中的新位置
  loss_new = CIFAR10_loss_fun(W_new)
  print &apos;for step size %f new loss: %f&apos; % (step_size, loss_new)

# 输出:
# original loss: 2.200718
# for step size 1.000000e-10 new loss: 2.200652
# for step size 1.000000e-09 new loss: 2.200057
# for step size 1.000000e-08 new loss: 2.194116
# for step size 1.000000e-07 new loss: 2.135493
# for step size 1.000000e-06 new loss: 1.647802
# for step size 1.000000e-05 new loss: 2.844355
# for step size 1.000000e-04 new loss: 25.558142
# for step size 1.000000e-03 new loss: 254.086573
# for step size 1.000000e-02 new loss: 2539.370888
# for step size 1.000000e-01 new loss: 25392.214036
</code></pre><p><strong>在梯度负方向上更新：</strong>在上面的代码中，为了计算<strong>W_new</strong>，要注意我们是向着梯度df的负方向去更新，这是因为我们希望损失函数值是降低而不是升高。</p>
<p><strong>步长的影响：</strong>梯度指明了函数在哪个方向是变化率最大的，但是没有指明在这个方向上应该走多远。在后续的课程中可以看到，选择步长（也叫作学习率）将会是神经网络训练中最重要（也是最头痛）的超参数设定之一。还是用蒙眼徒步者下山的比喻，这就好比我们可以感觉到脚朝向的不同方向上，地形的倾斜程度不同。但是该跨出多长的步长呢？不确定。如果谨慎地小步走，情况可能比较稳定但是进展较慢（这就是步长较小的情况）。相反，如果想尽快下山，那就大步走吧，但结果也不一定尽如人意。在上面的代码中就能看见反例，在某些点如果步长过大，反而可能越过最低点导致更高的损失值。</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-007.jpg" alt="Optimization"></center>

<p>将步长效果视觉化的图例。从某个具体的点W开始计算梯度（白箭头方向是负梯度方向），梯度告诉了我们损失函数下降最陡峭的方向。小步长下降稳定但进度慢，大步长进展快但是风险更大。采取大步长可能导致错过最优点，让损失值上升。步长（后面会称其为<strong>学习率</strong>）将会是我们在调参中最重要的超参数之一。</p>
<hr>
<p><strong>效率问题</strong>：你可能已经注意到，计算数值梯度的复杂性和参数的量线性相关。在本例中有30730个参数，所以损失函数每走一步就需要计算30731次损失函数的梯度。现代神经网络很容易就有上千万的参数，因此这个问题只会越发严峻。显然这个策略不适合大规模数据，我们需要更好的策略。</p>
<h2 id="微分分析计算梯度"><a href="#微分分析计算梯度" class="headerlink" title="微分分析计算梯度"></a>微分分析计算梯度</h2><p>使用有限差值近似计算梯度比较简单，但缺点在于终究只是近似（因为我们对于h值是选取了一个很小的数值，但真正的梯度定义中h趋向0的极限），且耗费计算资源太多。第二个梯度计算方法是利用微分来分析，能得到计算梯度的公式（不是近似），用公式计算梯度速度很快，唯一不好的就是实现的时候容易出错。为了解决这个问题，在实际操作时常常将分析梯度法的结果和数值梯度法的结果作比较，以此来检查其实现的正确性，这个步骤叫做<strong>梯度检查</strong>。</p>
<p>用SVM的损失函数在某个数据点上的计算来举例：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-009.png" alt="Optimization"></center>

<p>可以对函数进行微分。比如，对w_{y_i}进行微分得到：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-010.png" alt="Optimization"></center>

<p><em>译者注：原公式中1为空心字体</em></p>
<p>其中1是一个示性函数，如果括号中的条件为真，那么函数值为1，如果为假，则函数值为0。虽然上述公式看起来复杂，但在代码实现的时候比较简单：只需要计算没有满足边界值的分类的数量（因此对损失函数产生了贡献），然后乘以x_i就是梯度了。注意，这个梯度只是对应正确分类的W的行向量的梯度，那些j\not =y_i行的梯度是：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-011.png" alt="Optimization"></center>

<p>一旦将梯度的公式微分出来，代码实现公式并用于梯度更新就比较顺畅了。</p>
<h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>现在可以计算损失函数的梯度了，程序重复地计算梯度然后对参数进行更新，这一过程称为梯度下降，他的<strong>普通</strong>版本是这样的：</p>
<h1 id="普通的梯度下降"><a href="#普通的梯度下降" class="headerlink" title="普通的梯度下降"></a>普通的梯度下降</h1><pre><code>while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # 进行梯度更新
</code></pre><p>这个简单的循环在所有的神经网络核心库中都有。虽然也有其他实现最优化的方法（比如LBFGS），但是到目前为止，梯度下降是对神经网络的损失函数最优化中最常用的方法。课程中，我们会在它的循环细节增加一些新的东西（比如更新的具体公式），但是核心思想不变，那就是我们一直跟着梯度走，直到结果不再变化。</p>
<p><strong>小批量数据梯度下降（Mini-batch gradient descent）</strong>：在大规模的应用中（比如ILSVRC挑战赛），训练数据可以达到百万级量级。如果像这样计算整个训练集，来获得仅仅一个参数的更新就太浪费了。一个常用的方法是计算训练集中的<strong>小批量（batches）</strong>数据。例如，在目前最高水平的卷积神经网络中，一个典型的小批量包含256个例子，而整个训练集是多少呢？一百二十万个。这个小批量数据就用来实现一个参数更新：</p>
<pre><code># 普通的小批量数据梯度下降

while True:
  data_batch = sample_training_data(data, 256) # 256个数据
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # 参数更新
</code></pre><p>这个方法之所以效果不错，是因为训练集中的数据都是相关的。要理解这一点，可以想象一个极端情况：在ILSVRC中的120万个图像是1000张不同图片的复制（每个类别1张图片，每张图片有1200张复制）。那么显然计算这1200张复制图像的梯度就应该是一样的。对比120万张图片的数据损失的均值与只计算1000张的子集的数据损失均值时，结果应该是一样的。实际情况中，数据集肯定不会包含重复图像，那么小批量数据的梯度就是对整个数据集梯度的一个近似。因此，在实践中通过计算小批量数据的梯度可以实现更快速地收敛，并以此来进行更频繁的参数更新。</p>
<p>小批量数据策略有个极端情况，那就是每个批量中只有1个数据样本，这种策略被称为<strong>随机梯度下降（Stochastic Gradient Descent 简称SGD）</strong>，有时候也被称为在线梯度下降。这种策略在实际情况中相对少见，因为向量化操作的代码一次计算100个数据 比100次计算1个数据要高效很多。即使SGD在技术上是指每次使用1个数据来计算梯度，你还是会听到人们使用SGD来指代小批量数据梯度下降（或者用MGD来指代小批量数据梯度下降，而BGD来指代则相对少见）。小批量数据的大小是一个超参数，但是一般并不需要通过交叉验证来调参。它一般由存储器的限制来决定的，或者干脆设置为同样大小，比如32，64，128等。之所以使用2的指数，是因为在实际中许多向量化操作实现的时候，如果输入数据量是2的倍数，那么运算更快。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>信息流的总结图例：</p>
<center><img src="/2017/03/02/Optimization/2017-03-02-008.png" alt="Optimization"></center>

<p>数据集中的(x,y)是给定的。权重从一个随机数字开始，且可以改变。在前向传播时，评分函数计算出类别的分类评分并存储在向量f中。损失函数包含两个部分：数据损失和正则化损失。其中，数据损失计算的是分类评分f和实际标签y之间的差异，正则化损失只是一个关于权重的函数。在梯度下降过程中，我们计算权重的梯度（如果愿意的话，也可以计算数据上的梯度），然后使用它们来实现参数的更新。</p>
<hr>
<p>在本节课中：</p>
<ul>
<li><p>将损失函数比作了一个<strong>高维度的最优化地形</strong>，并尝试到达它的最底部。最优化的工作过程可以看做一个蒙着眼睛的徒步者希望摸索着走到山的底部。在例子中，可见SVM的损失函数是分段线性的，并且是碗状的。</p>
</li>
<li><p>提出了迭代优化的思想，从一个随机的权重开始，然后一步步地让损失值变小，直到最小。</p>
</li>
<li><p>函数的<strong>梯度</strong>给出了该函数最陡峭的上升方向。介绍了利用有限的差值来近似计算梯度的方法，该方法实现简单但是效率较低（有限差值就是h，用来计算数值梯度）。</p>
</li>
<li><p>参数更新需要有技巧地设置<strong>步长</strong>。也叫学习率。如果步长太小，进度稳定但是缓慢，如果步长太大，进度快但是可能有风险。</p>
</li>
<li><p>讨论权衡了数值梯度法和分析梯度法。数值梯度法计算简单，但结果只是近似且耗费计算资源。分析梯度法计算准确迅速但是实现容易出错，而且需要对梯度公式进行推导的数学基本功。因此，在实际中使用分析梯度法，然后使用<strong>梯度检查</strong>来检查其实现正确与否，其本质就是将分析梯度法的结果与数值梯度法的计算结果对比。</p>
</li>
<li><p>介绍了<strong>梯度下降</strong>算法，它在循环中迭代地计算梯度并更新参数。</p>
</li>
</ul>
<p><strong>预告：</strong>这节课的核心内容是：理解并能计算损失函数关于权重的梯度，是设计、训练和理解神经网络的核心能力。下节中，将介绍如何使用链式法则来高效地计算梯度，也就是通常所说的反向<strong>传播（backpropagation）机制</strong>。该机制能够对包含卷积神经网络在内的几乎所有类型的神经网络的损失函数进行高效的最优化。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Verdin" />
          <p class="site-author-name" itemprop="name">Verdin</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Verdin</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

<span id="busuanzi_container_site_pv">
  . . . . . . . . . 访问量<span id="busuanzi_value_site_pv"></span>次
</span>

<span id="busuanzi_container_site_uv">
  _______~欢迎第<span id="busuanzi_value_site_uv"></span>位访客~
</span>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"verdin"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  













  
  

  

  

  

  


  

</body>
</html>
